{"status": {"elapsed": 10, "timestamp": "2022-04-13T06:58:54.503723138Z"}, "data": [{"id": "8a405491-a093-4035-a1d2-ba8eaeb579ba", "title": "State of Avalanche Q1 2022", "content": "Key Insights\n\nQ1 2022 consisted of continued growth and the stabilization of network usage, financial performance, and network infrastructure.\nQuarterly growth can be attributed to the continued deployment of Avalanche Rush, the Blizzard ecosystem fund, Ethereum Virtual Machine (EVM) subnet development, and the introduction of the Multiverse subnet incentive program and Culture Catalyst fund.\nWith further releases of Apricot and the launch of subnets anticipated, average transaction fees should continue to stabilize and trend downwards.\nAvalanche showed signs of capturing market share versus top EVM-compatible chains across several key metrics over Q1.\nThe user experience is expected to improve with the launching of a browser extension and a mobile wallet, set to be released in Q2.\nAlong with the continued development of subnets, the launch of the browser extension and a mobile wallet will enable native bridging between subnets.\n\nA Primer on Avalanche\n\nThe Avalanche network is a Proof-of-Stake (PoS) smart contract platform for decentralized applications. Whereas most competitors use consensus mechanisms in the Classical or Nakamoto families, Avalanche differentiates itself through its creation and implementation of a new consensus family known as \u201cAvalanche consensus.\u201d Following years of research, the Avalanche mainnet was launched in September 2020 and featured the release of a multichain framework utilizing three chains (the P, X, and C chains). Each chain plays a critical and unique role within the Avalanche ecosystem while providing the same capabilities of a single network.\n\nAs a follow-up to the <a href=\"https://messari.io/article/state-of-avalanche-q4-2021?referrer=asset:avalanche\">State of Avalanche Q4 2021</a> report, this report will revisit developments and events from the prior quarter, analyze the network\u2019s most recent quarterly performance, and give insight into the coming months. A full appendix of data tables is available at the end of the report.\n\nThe First Quarter Narrative\n\n<a href=\"https://messari.io/article/state-of-avalanche-q4-2021?referrer=asset:avalanche\">Q4 2021</a> was a period of high growth for the Avalanche network. With the Ethereum\u2013Avalanche bridge, major exchange listings, high-profile partnerships, and the Avalanche Rush liquidity program, the network was positioned to grow its user base and welcome new participants into its economy. As individuals and institutions piled in, Avalanche recorded all-time-highs in active addresses, daily transactions, total value locked (TVL), and market capitalization. As we moved into the new year, additional growth strategies and developments were on the horizon, but it was unknown whether the network would continue growing, experience a downturn, or show signs of stabilization.\n\nUltimately, Q1 2022 consisted of continued growth and the stabilization of network usage, financial performance, and network infrastructure. The outcomes were attributed to several key developments: the continued deployment of Avalanche Rush, the Blizzard ecosystem fund, Ethereum Virtual Machine (EVM) subnet development, and the introduction of the Multiverse subnet incentive program and Culture Catalyst fund. As existing enterprise partners such as Deloitte began to implement business solutions, new partnerships were formed over the quarter.\n\nNetwork Overview\n\nAcross the board, Avalanche experienced modest growth compared to the prior quarter, and its key metrics stabilized across the network. While the market cap was relatively flat (-5.4%), the network experienced continued uptrends in usage, revenue generation, and a move towards favorable fundamental valuation. Average daily transactions nearly doubled over the quarter (+82.8%), total revenue grew by 72.7%, and the price-to-sales (P/S) ratio continued to settle down, with the ratio of price relative to revenue moving from 160x to 91x.\n\nAs a result, daily active addresses did not reverse course, and instead, adoption continued as active addresses reached an all-time-high of 140,000 in January. For perspective, Avalanche had more active users in the first week of January than in all of October 2021. The network averaged around 70,000 daily active addresses during Q4 and reached a stable range with an average of 92,000 during Q1.\n\nSimilar to Q4, transaction activity on the network followed a similar pattern to daily active address growth. On aggregate, Avalanche's average daily transactions rose from 473,000 last quarter to 865,000 in Q1, which is ~ 74% of Ethereum\u2019s roughly 1.17 million. Daily transactions continued their upward trend with additional DeFi application launches and the rollout of GameFi subnets such as DeFi Kingdoms Crystalvale and Crabada. Ultimately, while on testnet, Crabada would become the top transaction driver on Avalanche during Q1. Beyond DeFi and GameFi, total 24 hour NFT volume surpassed $1 million for the first time, while the NFT market cap broke $110 million.\n\nThroughout 2021, the network experienced volatility in average daily transaction fees. With further releases of Apricot, transaction fees have since stabilized, averaging around $0.67 per transaction. Apricot is intended to facilitate \"verifiable pruning,\" a process where nodes can securely compact historical transactions. It features a fee mechanism that enables transaction costs to be low and predictable for users. While stable, transaction fees have been trending upward in tandem with daily transactions. With more anticipated releases of Apricot, we should expect to see average transaction fees continue to stabilize and trend downwards.\n\nFurther, the continued launch of subnets should put downward pressure on transaction fees. Subnets are a horizontal scaling strategy that aims to validate Avalanche blockchains running in parallel, enabling transaction order, and increased performance by splitting up network traffic allowing for optimization and more control over transaction fees.\n\nIntuitively, as daily active addresses and transactions grew, total revenue increased. Revenue grew by 72.7% over the quarter, and cumulative revenue became a more significant fraction of the network FDV. To put it into perspective, cumulative revenue as a percentage of FDV is 20x from a year ago, which signals that fundamentals like network revenue are moving more in line with market value.\n\nAvalanche\u2019s network revenue (transaction fees) is atypical for smart contract platforms. Rather than distributing transaction fees to validators, 100% of fees are burned from the network\u2019s circulating supply. This drives value to all token holders through increased scarcity rather than compounding the balances of validators and delegators. In other words, revenue growth should put upward pressure on the market value of AVAX. The question is just how statistically significant the spread between revenue and market value is. With that in mind, as fundamental value (as opposed to speculative value) becomes a more substantial part of market value, a strong correlation between revenue and market value should theoretically exist.\n\nMost notably, a spike in daily revenue on November 22, 2021, was accompanied by a spike in FDV. The same relationship exists between circulating market cap and price. Additionally, the spread between the two variables tightened during Q1, with occasional spikes in revenue once again accompanied by spikes in FDV. As the spread tightens, the network usage becomes more correlated to the market value. This correlation could indicate that the network is moving closer to fundamental value versus speculative value. If the relationship holds, then revenue will have a significant relationship with network value.\n\nSince June 2021, engaged stake and nominal staking yields have been stable, with an average annualized yield of ~10%. One of the last significant token unlocks occurred during March, but there was no indication of a change in engaged stake. Should those tokens engage or disengage in staking, there could be additional volatility in yield over the near term.\n\nEcosystem & Development Overview\n\nHeading into 2022, Avalanche DeFi was expected to be fueled by the ongoing Avalanche Rush program and the new $200 million Blizzard ecosystem fund. Over the course of Q1, Pangolin (PNG), an Avalanche native DEX, and Terra (LUNA) joined the Rush program and combined to bring TerraUSD (UST) to the Avalanche ecosystem. In total, $2 million in AVAX incentives were combined with additional LUNA and PNG rewards to incentivize usage.\n\nContinued network adoption was also evident in Avalanche development activity with unique contracts deployed and contract deployers having grown by 60.9% and 13.1%, respectively. Although development marched forward, TVL declined by 5.5%.\n\nThe TVL decline would have been more drastic if not for the continued growth and development in the DeFi sector. TVL is highly sensitive to overall market valuations. While TVL on Avalanche experienced a slight decline, top DeFi protocols Aave, Benqi, and Trader Joe experienced TVL declines of 4%, 18%, and 20%, respectively. Their collective TVL declined by 12% \u2014 more than twice the total Avalanche DeFi ecosystem\u2019s decline. Essentially, the continued growth and development of newer and smaller protocols in the Avalanche DeFi ecosystem offset the market forces negatively impacting top protocol TVL. Ultimately, like other metrics in the Avalanche ecosystem, TVL appears to have also stabilized at around $11 billion.\n\nAave, Trader Joe, and Benqi solidified their positions as the top three DeFi protocols after joining Rush in Q4. Collectively, these three protocols experienced a 12% decline in TVL, which is greater than the decline of the entire Avalanche DeFi ecosystem. The disconnect between the greater decrease in TVL across the top DeFi protocols and the lower decline of the entire DeFi ecosystem can be attributed to additional launches of DeFi services on the network, such as the launch of Platypus Finance (PTP).\n\nPlatypus Finance is a stableswap protocol that was the fastest growing DeFi application over the quarter, having grown from just $10 million to over $750 million in TVL, representing a ~7,500% increase. Platypus also became one of the top 10 applications generating network transactions on Avalanche.\n\nAdditional launches and Rush deployments, such as Pangolin and Terra, helped prop up Avalanche\u2019s TVL despite overall market declines. The other notable trend across Q1 was the steady long tail of DeFi protocols on Avalanche. Entering Q1, 60 protocols had amassed $1 million TVL, up from just 29 from the prior quarter. Exiting Q1, 60 protocols maintained the $1 million TVL mark. Despite the flat to down quarter, the number of applications with recorded TVL grew from 100 to 150.\n\nQ1 marked the beginning of Avalanche\u2019s highly anticipated GameFi subnet launches. Crabada quickly passed 5,000 users, measured by the number of unique wallet addresses interacting with the application's smart contracts. Daily transactions grew from 60,000 to over 400,000 over Q1, measured by transactions made to Crabada\u2019s smart contracts. Daily volume generally ranged between $130,000 and $1.5 million as measured by the total amount of incoming value to the application's smart contracts. Finally, the TVL in the application's smart contracts neared $50 million by the end of the quarter. Ultimately, the emergence of new DeFi and GameFi applications was fueled by continued growth in developer metrics.\n\nQ1 developer activity in the Avalanche ecosystem aligns closely with the network's overall TVL growth and recent entry into GameFi. The number of unique contracts deployed grew by 60.9% quarter over quarter and reached an all-time-high in March, just as Crabada and DeFi Kingdoms launched their subnets. The number of unique contract deployers slowed on a month-to-month basis but still managed to grow by 13.1% quarter over quarter. With the deployment of the Multiverse and Culture Catalyst funds, March's surge in contract deployments should continue through Q2 2022.\n\nThe growth of events in the Ava Lab\u2019s Github repository grew significantly (76.4%) throughout Q1. Given this was the greatest increase to date, the number of events indicates that the network\u2019s core team is accelerating the infrastructure buildout.\n\nStaking and Decentralization Overview\n\nThe security of PoS networks like Avalanche requires users to lock up the network\u2019s native tokens and participate in validation duties. A distributed network of validators and active participants can help ensure the network functions as intended.\n\nAfter a downwards trend at the beginning of 2021, engaged stake settled at around 60%, which has been maintained through Q1 2022.\n\nStaking amounts during Q1 were relatively uneventful, with average stake changes in the single digits quarter over quarter. Such predictability and lack of volatility are generally good for network health. Validator stake was consistently about 5.85 times greater than the amount of delegated stake. The amounts of unresponsive validator stake were higher than average on a few days, but the total amount of offline stake never came close to levels that could compromise the network.\n\nWhile the average staking amount was relatively flat, there was a material increase in the average number of validators and delegators. The average validator count grew from 1,138 to 1,259, representing a 10.6% increase in network security participants. The number of average validators joining the network stayed at about 11% growth each quarter. This stability is indicative of a growing, decentralized network.\n\nEach new Avalanche subnet will be required to validate on the Avalanche P-chain. As more subnets launch, the average number of validators should increase in tandem. The average number of delegators also grew from 16,459 to 17,179, representing a 4.4% increase. The number of delegators consistently outnumbered the number of validators, consistent with other PoS networks that support native delegation. The average number of offline validators continued to decline, decreasing by 14.9% over the quarter. Ultimately, low volatility in the network\u2019s staked AVAX combined with an increase in validators and delegators is a sign of healthy decentralization.\n\nThe Nakamoto coefficient is a metric first introduced by Balaji Srinivasan to quantify the decentralization of blockchain networks. The coefficient represents the minimum number of actors who can collude to disrupt the network. For Avalanche, the Nakamoto coefficient equals the number of validators that control one-third of the network\u2019s stake. Avalanche\u2019s Nakamoto coefficient hovered in the low 30s to begin 2021 but fell to 25 in June. Since this decline, the coefficient has remained stable in the upper 20s, putting Avalanche above the industry average for other Layer-1 networks.\n\nCompetitive Analysis\n\nCurrently, the Layer-1 space is a competitive race between new and legacy protocols to achieve the maximum possible network speed at the lowest possible cost and with the greatest degree of security. Each competitor has focused on maximizing these activities while making a range of trade-offs regarding centralization. The ideal blockchain would be fast, secure, widely used, and adequately decentralized.\n\nThe core technical advancements, developer activity, and ecosystem growth strategies may separate one L1 from another. Here, we evaluate Avalanche\u2019s progress versus the top five EVM compatible chains (including Avalanche) by TVL. The methodology used to derive this peer group is simply by grouping the EVM chains with the largest TVL, seeing as today, DeFi is the sector driving the majority of each network\u2019s economic activity.\n\nAvalanche experienced the lowest decline in value in terms of market cap and closed in on BNB Chain market share while further separating itself from Fantom and Polygon.\n\nSimilarly, Avalanche\u2019s daily revenue trended upward. At the same time, all other EVM chains experienced a decline, allowing for Avalanche to close in on BNB Chain and further separate from Fantom and Polygon.\n\nAvalanche\u2019s P/S ratio declined over the quarter, while other chains aside from Fantom experienced an increase in this valuation metric. From a relative valuation perspective, Avalanche is now more in line with Ethereum with a P/S of 91x versus Ethereum\u2019s 81.5x.\n\nBoth Avalanche and Fantom reached similar levels in Q1 daily transactions. Ethereum has held steady at ~1.17 million transactions per day, with Avalanche now reaching ~74% of Ethereum\u2019s average daily transactions. With the incentive programs taking hold and subnet launches on the way, Avalanche has an interesting opportunity to surpass Ethereum over the next quarter.\n\nQ1 was a flat to down quarter for the crypto market, with aggregate TVL decreasing from $240 billion to $230 billion. Avalanche\u2019s TVL declined at the second slowest rate among the top EVM chains, only trailing behind Fantom. A significant portion of Avalanche\u2019s stability came at the expense of Ethereum, BNB Chain, and Polygon, each declining by double-digit percentages. As the above chart illustrates, Avalanche closed in on BNB Chain in this area. The Avalanche Mcap/TVL ratio also ended among the lowest. As a measure of network value relative to TVL, it signifies a closer relationship between the network value and the DeFi economic activity occurring on the network.\n\nKey Events, Catalysts, and Strategies for Ecosystem Growth\n\nQ1 2022 proved to be another significant quarter for the Avalanche ecosystem. Indeed, growth strategies and development activity contributed to Avalanche's ecosystem growth, as evidenced by the data presented in the previous sections of this report. The results can be attributed to several key developments:\n\nThe continued deployment of Avalanche Rush\nDeployment of the Blizzard ecosystem fund\nCustom EVM subnet development\nIntroduction of the Multiverse program and Culture Catalyst fund\n\nJanuary 2022\n\nAvalanche's Q1 began with the launch of the Subnet-Ethereum Virtual Machine, a custom VM that enables users to easily and rapidly create their own, configurable EVM-compatible blockchain. By the end of the first week of January, Pangolin announced plans to launch its own subnet. During the first week of January, not only was the Avalanche ecosystem gearing up for subnets, it was introducing additional enterprise partners. Ava Labs entered into a strategic partnership with Turkey's electronic vehicle manufacturer Togg to design and build smart contract-based services to improve autonomous mobility.\n\nBy the middle of January, Bitwise, a prominent crypto index fund manager, reconstituted the Bitwise 10 Large Cap Crypto Index and added AVAX. Days later, Terra passed a proposal to bring UST to Avalanche with Liquidity Mining Proposal #3. Further ecosystem collaboration came about when Celsius Network announced support for Avalanche, allowing users to borrow against AVAX from a centralized provider. Further, 1inch, a widely used DeFi aggregator, was deployed on Avalanche.\n\nJanuary concluded with the first subnet launches on Avalanche with Spaces, a website allowing users to store and share links, images, and files all on-chain, and WAGMI, a subnet demo that is a high-throughput testbed for EVM optimizations. Finally, to round out the month, Anchor Protocol, the largest DeFi protocol on Terra, proposed and passed a UST borrowing strategy whereby sAVAX entered the platform as its newest collateral asset.\n\nFebruary 2022\n\nAs reported in Q4 2021, one of renowned street artist Banksy's most iconic pieces, Love is in the Air, became a fractionalized NFT on Avalanche. The NFT was made possible by Particle, which partnered with Avalanche to bring fine art on-chain in November. By February, the Banksy NFT generated interest and purchases by celebrities such as Paris Hilton. The Particle Banksy collection would later sell out in March.\n\nAlso reported in Q4, a multi-year agreement with Andretti Formula E Autosports marked the first title sponsorship from a blockchain company with a Formula E team with a natural alignment between organizations committed to sustainability. By mid-February, the Avalanche Andretti team made its debut at the Mexico City E-Prix, the Formula E World Championship.\n\nMarch 2022\n\nMarch was a pivotal month of Q1. The uptick witnessed in daily transactions was largely due to the launch of the Crabada and DeFi Kingdoms subnets with Crabada running testnet and DeFi Kingdoms live on mainnet. To support the growth and development of subnets, the Avalanche Foundation announced the launch of Avalanche Multiverse, a $290 million (~4 million AVAX) incentive program. The first subnet to receive incentives through the Multiverse program was DeFi Kingdoms. Subsequently, Wildlife Studios joined the Multiverse program and will be expanding its flagship game, Castle Crush, onto its own subnet, intending to integrate NFTs and tokens into the game.\n\nAt the end of March, the sold-out Avalanche Summit took place in Barcelona, Spain, with sponsors including Circle, Terra, and Bridge Tower Capital, to name a few. During this time, the Avalanche Foundation and Web3 social media platform Op3n announced a $100 million creator fund called Culture Catalyst. The fund intends to help creative projects launch on Avalanche and Op3n. The program's first recipient will be musician Grimes, who plans to create an \"intergalactic childrens' metaverse book.\"\n\nEcosystem Challenges\n\nQ1 did not present any drastic challenges like those that came with the growing pains of Q4. As reported last quarter, the Avalanche C-chain recorded new highs for daily transactions which caused the network to temporarily experience higher than usual transaction fees. This quarter, network optimizations known as Apricot quickly became apparent as average daily transaction fees declined and stabilized. With that in mind, transaction fees were trending upward towards the end of Q1 as daily transactions increased.\n\nThe anticipated solutions to scaling and lowering costs include governance, pruning, and subnet development, which will involve removing a gas limit mechanism, among other optimizations. The launch of subnets is in motion, and the horizontal scaling approach with subnets takes place will influence how transaction fees trend going forward.\n\nThe Road Ahead\n\nCurrently, Avalanche does not maintain an updated public-facing roadmap, so the protocol developments are not prescribed. However, it is expected that Avalanche Rush will continue to drive DeFi growth, Blizzard will support overall ecosystem expansion, Multiverse will drive subnet development, and Culture Catalyst will bring creative talent to the ecosystem.\n\nIt is also anticipated that core platform upgrades will continue. Significant upgrades (Apricot) are being implemented in six phases, following a successful series of Phase 5 in Q1. All phases of Apricot broadly represent one of the solutions (pruning) to the optimizing transaction fees.\n\nAs discussed during the Q4 Analyst Call, user experience improvement is of high priority. As part of this effort, Ava Labs announced details about <a href=\"https://messari.io/intel/event/a6060efe-af6c-4977-8590-6fa4aac69678\">Core</a>, a free, non-custodial wallet explicitly created for applications on Avalanche with native support for subnets. The first iteration of Core is a browser extension, with the second being the Core mobile wallet expected to be released in early Q2. Ava Labs also announced that the Avalanche Bridge will enable support for Bitcoin, allowing BTC holders to transfer their BTC onto Avalanche securely. Bitcoin support is also scheduled to go live on mainnet in Q2. Ultimately, Ava Lab\u2019s goal is to make the user experience as seamless as possible, and the Core wallets and bridge developments are the first steps.\n\nAvalanche on-chain governance is also still in development. AVAX will, at some point, be used to provide on-chain governance for critical network parameters where participants can vote on changes to the network and settle network upgrade decisions democratically. Some of these parameters will include factors such as the minimum staking amount, minting rate, and transaction fees.\n\nWhile all Avalanche incentive programs may continue to catalyze ecosystem growth and garner more project launches and partnerships, significant technological advancements are critical for the teams developing the Avalanche infrastructure. The continued development of subnets and the launch of Core will play a key role. For subnets to flourish, Core will need to successfully support extended functionality for subnets, such as native bridging.\n\nClosing Summary\n\nNetwork usage, financial performance, development activity, and network infrastructure continued to grow and stabilize during Q1 2022. The growth was fueled by Avalanche Rush, the Blizzard ecosystem fund, the Ethereum Virtual Machine (EVM) subnet development, the Multiverse subnet incentive program, and the Culture Catalyst fund. Additionally, partnerships formed in Q4 with enterprises like Deloitte began implementing business solutions on Avalanche while more partnerships were formed. Altogether, Avalanche showed signs of capturing market share versus top EVM-compatible chains across several key metrics over the quarter.\n\nAcross the board, Avalanche experienced growth, and its key metrics stabilized across the network. While the market cap was relatively flat, the network experienced continued uptrends in usage, revenue generation, and a move towards favorable fundamental valuation. Further, continued network adoption was also evident in Avalanche development activity, with unique contracts deployed and contract deployers growing significantly.\n\nAvalanche incentive programs may continue to provide a catalyst for ecosystem growth. These programs may attract more project launches and partnerships, however, significant technological advancements are at the forefront of the teams developing Avalanche infrastructure. Significant developments to monitor going forward will be the continued development of subnets and the launch of Core. For subnets to flourish, Core will need to successfully implement its objectives to support extended functionality for subnets, such as native bridging. Ultimately, as with all Layer-1 networks, tracking the growth of the Avalanche network and its progress towards optimization and user experience will be top of mind looking ahead into the next quarter.\n\nThis report was commissioned by Ava Labs, a member of Protocol Services. All content was produced independently by the author(s) and does not necessarily reflect the opinions of Messari, Inc. or the organization that requested the report. Paid membership in Protocol Services does not influence editorial decisions or content. Author(s) may hold cryptocurrencies named in this report.\n\nCrypto projects can commission independent research through Protocol Services. For more details or to join the program, contact ps@messari.io.\n\nThis report is meant for informational purposes only. It is not meant to serve as investment advice. You should conduct your own research, and consult an independent financial, tax, or legal advisor before making any investment decisions. The past performance of any asset is not indicative of future results. Please see our terms of use for more information._\n\nAppendix\n\n  \n\n  \n\n  \n\n  \n  \n\n  \n\n  \n  \n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n  \n  \n\n  \n  \n\n", "references": [{"name": "James Trautman", "url": ""}], "published_at": "2022-04-12T14:00:00Z", "author": {"name": "James Trautman"}, "tags": ["Layer-1", "Quarterly-Reports"], "url": "https://messari.io/article/state-of-avalanche-q1-2022"}, {"id": "0a2efaf7-825d-4024-aa5e-63d3b8c037a1", "title": "State of Uniswap Q1 2022", "content": "Key Insights\n\nTotal trading volume and, correspondingly, liquidity provider fees, fell in Q1 2022 as the surge of interest in crypto and NFTs from Q4 2021 subsided.\nUniswap on Polygon found organic growth and became the leading non-Ethereum platform for V3 by transaction volume even though it was the latest network to go live; additional liquidity mining incentives in the upcoming quarter should continue to help drive growth.\nThe community is exploring areas for further expansion onto Celo and Gnosis Chain.\nThe Uniswap Grants Program gave out the largest grant wave in its history in Wave 6, which included a mix of grant proposals from the end of 2021.\n\nIntroduction to Uniswap\n\nUniswap facilitates the trading of tokens on the Ethereum network along with scaling solutions such as Optimism, Arbitrum, and Polygon. The protocol is recognized as a pioneer among decentralized exchanges (DEXs), first for its popularization of the X*Y=K constant product pricing curve of pooled liquidity in V2 \u2013 and subsequently for its concentrated liquidity and staggered trading fee features in V3. The constant product pricing curve has since been implemented across many other DEXs in the industry. The concentrated liquidity model and fee tiers continue to remain relatively unique across DEX applications.\n\nTo quickly recap, AMMs pair tokens into pools balanced by the aforementioned algorithm. Liquidity providers (LPs) can deposit funds into those liquidity pools where traders make trades by swapping tokens in and out \u2014 in effect, making trades with the pool. In exchange for providing liquidity, LPs earn transaction fees paid by the traders.\n\nImportant updates to the protocol in the past quarter include the rapid growth of trading activity on Polygon\u2019s Proof-of-Stake (PoS) chain (hereinafter: Polygon). Though Polygon was the last of Uniswap\u2019s scaling solutions to launch in 2021, Uniswap V3 transaction volume quickly surpassed other notable DEXs on Polygon, such as SushiSwap, QuickSwap, Balancer, on fractions of the total value locked (TVL) for other DEXs. Q1 2022 saw some important governance proposals as well: launches of V3 on Gnosis Chain and Celo have passed temperature checks and will be up for an on-chain vote shortly. One should also reasonably expect additional expansion proposals later this year.\n\nAfter a volatile Q4 trading quarter, 2022 represents an opportunity for normalization. Benchmarking quarter-over-quarter metrics will shed light on how Uniswap and its LPs respond to concerns of a bear market. A full appendix of quarterly data is available at the end of the report.\n\nMacro Overview\n\nOn the whole, Uniswap trading volume in Q1 2022 was 53.5% lower than the previous quarter. This corresponds with the global crypto market, which hit its peak market capitalization in Q4 2021 at $3 trillion and has since come back down to $2 billion. When token prices go up, trading volume generally increases as retail inventors become more interested; when token prices decrease, retail investors lose interest in crypto. And unlike Q4 2021, which saw both the resurgence of NFTs and all-time highs for BTC and ETH, trading activity in Q1 2022 has been more muted.\n\nOverall market liquidity dipped in Q1 2022, but to a lesser degree than volume. V2 was the only network to see a liquidity decline over the quarter, falling by 25.7%, while all the others saw nominal increases at a small scale. Since V2 includes more long-tail token pairs, a decline in V2 liquidity does coincide with lower retail trading volume. Meanwhile, market liquidity really shined in Uniswap\u2019s so-called scaling solutions, particularly Polygon. Polygon jumped almost 81.7% compared to the end of Q4 when it had just launched. The implications of Polygon\u2019s big win will be revisited throughout the report. Arbitrum and Optimism each saw growth too at 72.9% and 34.7%, respectively.\n\nPolygon\u2019s liquidity growth is particularly impressive given the lack of liquidity mining incentives for users in Q1. For context, when the initial governance proposal was made, up to $15 million was set aside by the Polygon team for liquidity mining purposes and another $5 million was prepared to support the ecosystem. As of the first week of April, these incentives have now been implemented. Only time will tell how much of a boost it'll give to Polygon's existing success.\n\nDaily LP fees fell 36.2% in Q1 2022 after jumping 54.0% in Q4 2021, resulting in final quarter-end numbers similar to the end of Q3 2021. Q4\u2019s numbers were such outliers due to the mainstream popularity of NFTs and all-time highs for both BTC and ETH. On the non-Ethereum front, Arbitrum gives Polygon a serious run for its money while Optimism lags behind. This data implies Polygon sees more trading of blue-chip token pairs (and thus, lower fees) while popular Arbitrum pairs trade in the higher fee tiers.\n\nTotal trading markets also continued to climb from the previous quarter, across all products from V2 on Ethereum to each of Uniswap\u2019s non-Ethereum networks. V2 continues to make up the vast majority of total available markets. V3 on Ethereum and Polygon comprise 11% of active markets while Optimism and Arbitrum remain negligible. As with market liquidity, Polygon grew the quickest in Q1, jumping almost 300% from the previous quarter. Given all the data, it\u2019s clear Uniswap has found a home on Polygon.\n\nMicro Overview\n\nThe markets on V3, while fewer in count, continue to trade more blue-chip token pairs. Trading activity on V3 also continues to rise on a quarter-over-quarter basis.\n\nTop V2 Markets\n\nThe top four most actively traded V2 markets for Q1 2022 were the following pools:\n\nUSDC/WETH\nUSDT/WETH\nSAITAMA/WETH\nFXS/FRAX\n\nTogether, the four pools represent less than 0.001% of the count of tradeable V2 markets but comprise 19.4% of total trading volume. Activity \u2013 and trends \u2013 from these four markets can be seen as leading indicators for the direction of the overall V2 ecosystem. However, given the trading pattern similarities USDT/WETH shares with USDC/WETH, further analysis of the pool was replaced in favor of the FXS/FRAX market for the purposes of this report.\n\nUSDC/WETH\n\nData from USDC/WETH shows trading volume continuing to decline after the launch of V3. V2 volume in the most recent quarter only accounted for 3.2% of total volume, only a tenth of V2 volume in Q2 2021. A total of $2.7 billion was traded in the V2 pool in Q1 2022, a 24.5% decline from the previous quarter. The capital efficiency of V3 makes it likely USDC/WETH trading activity on V2 will continue to decline and give way to further volume increases in its V3 counterpart.\n\nThe chart above represents our methodology of tracking LP profits/losses. Three scenarios were evaluated to compare the profitability of providing liquidity to this pool: a user providing liquidity for 30-, 90-, and 180-day windows. These windows were rolled through the entire last year to compare the profitability of these actions across time. For each window period, the corresponding impermanent loss caused by price change in the first and last day of the window was deducted from the equivalent yield generated from trading fees. The result is a moving net profit metric displayed above.\n\nThe USDC/WETH pair is a prime market to take a liquidity stake in, given the high volume of trades facilitated by the pool. Because most price fluctuations would be hedged by trading fees earned by LPs, one could expect decent returns when trading volume is high.\n\nOf the 365 days since Q2 of last year, only 52 of the rolling 180-day returns would have yielded losses for LPs who would\u2019ve chosen to retract their liquidity on any of those days. Even fewer days would have led to a loss for shorter-term LPs: for rolling 30-day LPs, the total impermanent loss would have exceeded fees for only 45 days of the year and only 12 days for those supplying rolling 90-day LPs.\n\nIn Q1 2022 alone, performance gets even better. All rolling 90- and 180-day LP positions over the entire 90 days in Q1 would have yielded a positive profit. For the rolling 30-day LP, every position would have been profitable, except for January 22-27th and March 5th.\n\nFXS/FRAX\n\nBoth tokens in the final V2 pool, FXS and FRAX, are tokens used by the <a href=\"https://messari.io/article/frax-a-fractional-algorithmic-stablecoin\">Frax Protocol</a>, an algorithmic stablecoin protocol built on a hybrid seigniorage model. FRAX is the actual stablecoin pegged to the US Dollar; FXS is the governance and value capture token used as partial collateral for FRAX. As a hybrid model, FRAX is collateralized by both the FXS token and a fraction of another stablecoin.\n\nThe extent to which the percentage of underlying collateral made up by FRAX and USDC or another stablecoin is determined by the collateral ratio, which changes with demand for FRAX. If FRAX supply is expanding, less stablecoin is needed; if FRAX is retracting, a higher collateral ratio of stablecoin is needed.\n\nWhat\u2019s important to know is that Frax has an FXS buyback program (Frax1559) for excess collateral. This occurs when yields are earned by the protocol\u2019s stablecoin collateral, causing total collateral to increase above the required collateral ratio. Frax uses the extra earned capital to mint new FRAX tokens and buy back outstanding FXS tokens.\n\nThus, the trading volume of the Uniswap FXS/FRAX pool is driven by the Frax1559 buyback program and should be relatively stable as long as FRAX remains successfully pegged to the US Dollar. Its emergence as a top-three traded pair this quarter reflects this stability while other volatile pools saw their trading volume sink. In total, trading activity in Q1 rose 6.9% for the most recent quarter after increasing 243.1% in Q4 2021.\n\nAnother factor adding to increased trading was chatter of a pending airdrop. The airdrop is for the upcoming FPI token. A snapshot was taken on February 20th of FXS of those who staked FXS tokens or were LPs of the FXS/FRAX pool. Those who heard about airdrop eligibility might have contributed to market activity by trading for FXS tokens or contributing to the liquidity pool.\n\nUnfortunately for LPs, the FXS/FRAX pool suffers mixed results. Trading fees were not strong prior to the implementation of FXS1559 while the token\u2019s price fluctuated wildly. The combination resulted in heavy losses across all three rolling time frames. Once the buyback program was initiated, trading volume picked up substantially. Though FXS price volatility didn\u2019t go away, the additional trading fees earned by LPs began to counteract impermanent loss, turning total LP fees positive.\n\nSAITAMA/WETH\n\nLast quarter, we described the rise of SAITAMA/WETH as a beneficiary of the November 2021 trading surge. After all, SAITAMA, as we noted, is the token for another of the doge-like projects that were so popular among retail investors, but its continued success has subverted expectations.\n\nNot only was SAITAMA/WETH a top-performing market in Q4 2021, it continued to be so for Q1 2022. That said, the asset pair did see overall trading volume fall 67.6% from the previous quarter. The trading volume growth of the previous quarters could not be sustained after a 2,500%+ increase in Q3 and a 700%+ increase in Q4. This highlights the broader trend of retail trading in the crypto markets: H2 2021, and Q4 2021 in particular, were very strong for memecoins and the general market, while Q1 2022 experienced a pullback.\n\nMarket liquidity for SAITAMA/WETH fell almost 40% from the previous quarter. Yet this decline still is less than the decline in trading volume. This all occurred while the price of SAITAMA fell by more than 75% over the quarter. LPs that kept their capital in the pool could have done so for many reasons, including the possibility of high fees or forgetting to close their market-making position.\n\nLPs who contributed liquidity to the SAITAMA/WETH pool saw a mix of positive and negative yields throughout the rolling 30-, 90-, and 180-day time frames. In line with expectations, most of the positive returns came in or after Q4 2021 when the trading volume began to pick up. Roughly 66%, or 62 out of 90 days in the quarter, led to positive returns for LPs over the 30-day time frame. The number of positive days increased to 82% for anyone supplying liquidity over a 90-day period but decreased to 32% for 180-day LPs, respectively.\n\nTop V3 Markets\n\nUnsurprisingly, the most active V3 markets are the USDC/WETH, USDC/USDT, and WBTC/WETH markets, which contributed 61.0% of V3 volume. Each market sheds a unique light on a different part of the crypto ecosystem: 1) ETH activity, the cornerstone of smart contract networks; 2) stablecoin markets, and 3) the relationship between the two largest crypto assets.\n\nUSDC/WETH\n\nThe USDC/WETH market is the predominant blue-chip stablecoin/ETH pair and the best indicator for ETH trading activity. It\u2019s worth noting that the USDT/WETH pair is also very active on Uniswap. In fact, it is the second most actively traded market. Demand for these three tokens is particularly high on Uniswap as most trades are denominated in those assets, which makes those markets the central routing point for market activity.\n\nTotal USDC/WETH V3 transaction volume for Q1 2022 amounted to $81.5 billion, an increase of 6.3% from the previous quarter. The majority of the increase came from the 0.05% fee tier, which jumped from $65.8 billion to $73.2 billion. The increase was partially negated by the decline in trading in the higher 0.30% tier. This trend highlights how competitive exchanges are. As noted in the Q4 2021 iteration of this report, capital competes with capital for fees and ultimately drives trades towards lower fee tiers.\n\nDividing the total fees by each dollar of liquidity highlights the yields an LP can expect to earn. A quick, high-level comparison of return on assets between the USDC/WETH V2 and V3 pools shows how much more capital efficient V3 is. V2 returns $0.04 for each dollar deposited, or 4.0%; the same calculation for V3 returns $0.12 for every dollar, or 12%. Note this doesn\u2019t account for each V3 LP\u2019s concentrated liquidity, but holistically summarizes V3\u2019s ability to generate a 3x higher return on its liquidity.\n\nAlthough Polygon found plenty of success in Q1, Arbitrum has a significant amount of liquidity available for USDC/WETH V3. Arbitrum has $16.2 million, i.e., 28.3% more liquidity than Polygon at $12.6 million. Because Arbitrum has been around longer, Polygon\u2019s liquidity has recently grown at a faster daily rate \u2014 and it will be supercharged even more with Polygon\u2019s liquidity mining program going live next quarter.\n\nUSDC/USDT\n\nUniswap was not competitive in the stablecoin DEX market until the implementation of its 0.01% trading fee tier. Once that became active, Uniswap could draw the attention of traders looking to pay the cheapest fees on highly correlated stablecoin pairs. The visual above clearly shows when that occurred.\n\nStablecoin trades in the USDC/USDT market jumped 60% overall against Q4 2021. This followed a 114.1% increase compared to Q3, more than tripling in nine months. Unsurprisingly, 87.3% of trading volume, or about $8.5 billion, came from the lower 0.01% fee tier. Liquidity, meanwhile, only increased 11.2% over the quarter.\n\nIn last quarter\u2019s report, we wrote about Uniswap\u2019s decision to implement the 0.01% fee tier as a boost for stablecoin trading volume. Analyzing the data above, Uniswap does appear to now be more competitive with Curve as a result of its enhanced capital efficiency.\n\nPrior to the launch of V3, Uniswap was doing a median of 8.54% of the combined volume between Uniswap and Curve. After the launch of V3, but prior to the implementation of the 0.01% fee tier, Uniswap stablecoin trading across both V2 and V3 operated at a median of 30\u201333% trading dominance. That median ratio now stands at 48.3% today, practically on parity with Curve. Uniswap\u2019s share of the two combined DEX\u2019s volume even reached a high of 71.4% on one day. Given the importance of stablecoins in the DeFi ecosystem, Uniswap\u2019s gains in this area are exciting to watch.\n\nWBTC/WETH\n\nTrading volume of the WBTC/WETH V3 pool fell 20.2% compared to Q4 2021. Notably, volume in the 0.05% pool fell 28.9% while volume in the higher 0.30% fee tier was mostly consistent across quarters. Liquidity in the smaller fee tier did jump 57.3% whereas the higher fee tier only moved up 13.7%. Since investor sentiment has noticeably cooled, some investors might be choosing to take a yield-generating LP position, earn fees on these (more stable) blue-chip assets, and re-evaluate the state of the market when better opportunities arise.\n\nBehind the scenes, Ethereum continues to show signs of losing its complete dominance of V3 trading. Over the last four quarters, the share of transaction activity occurring on Ethereum has gone from 100.0%, to 99.8%, to 98.4%, and finally, 96.4% in Q1 2022. Once again, the emergent winner in Q1 2022 continues to be Polygon. The WBTC/WETH protocol dominance level for Polygon shows the network starting at around 5% of all trading activity and peaking to 10% midway through the quarter. In total, the 3.6% gain by Polygon and other blockchains isn\u2019t earth-shattering, but it will be something to track as users continue to move towards cheaper scaling solutions.\n\nGrant Program\n\nUniswap approves grants almost every week, but to avoid publishing a blog post for each new funding, grants are batched together into waves. In Q1 2022, Uniswap released Wave 6 and Wave 7 of their Uniswap Grants Program. Note, the quarter in which batches become publicly shared does not necessarily correlate with the quarter they were made (i.e., some grants from the batches may have been funded in Q4 2021).\n\nWhat stands out from the quarter is the total grant funding distributed in Wave 6. The previous high occurred in Wave 5 with $946,000. Wave 6 was more than a 2.5x increase from this level, equating to $2.4 million of funding. More than $1 million was dedicated to the \u201cRFP and Challenge\u201d category. Some of the most notable grants from Wave 6 and Wave 7 are below:\n\nOther Internet (Governance Experiments) \u2013$1,000,000\n\nOther Internet received a $1 million grant from Uniswap Grants Program to further their research of Uniswap\u2019s open governance. In the summer of 2021, Other Internet completed initial research on the off-chain governance occurring in the protocol\u2019s Discord channels. The additional funding will support a series of action-oriented proposals to strengthen governance practices, many of which will ideally be implemented throughout crypto. Specific deliverables include a redesign of the governance process, a new committee for UGP, and insights into the protocol treasury. Money from this grant is expected to last the upcoming year.\n\nUnigrants Community Analytics Program \u2013 $250,000\n\nA quarter of a million dollars was set aside to fund winners of a new analytics-focused program. The objective of the program is to reward UNI token bounties to contributors who could produce analytics for the protocol. The purpose of the program is to use these analytics to further onboard new users into the community. A committee of five individuals, ranging from UGP members to independent analysts, were chosen to review applications and select bounty winners. More information about the Community Analytics Program can be found in the next section.\n\nTeam Secret \u2013 $112,500\n\nUniswap Grants Program decided to continue its partnership with Team Secret for the first half of the fiscal year 2022 after the team\u2019s top-three finish at The International, the biggest global DOTA tournament. As announced in June 2021, the partnership includes the team creating educational content around Uniswap and organizing future technology launches. The goal was \u2014 and continues to be \u2014 aimed toward reaching new audiences, especially those in the digitally native gaming community.\n\nArt Basel (Crypto Onboarding) \u2013 $68,500\n\nFunding was provided to set up a crypto booth at the upcoming Art Basel in December 2021. Occurring in Miami, the booth was dedicated to helping event attendees get onboarded with crypto. People were around to assist curious participants on setting up their first wallet, claiming their first event POAP, learning how to get into NFTs, and more. The end result saw over 300 people get onboarded into crypto and the DeFi ecosystem.\n\nCommunity Analytics Program\n\nAs stated prior, the Community Analytics program is designed to encourage more analytics for the growth of the Uniswap community. Multiple rounds of bounties have already occurred from the time the grant was approved till the end of Q1 2022.\n\nBounty #1: Uniswap on Polygon \u2014 Compare the deployment of Uniswap V3 to Polygon with its metrics on Ethereum. Include other DEXs in the analysis. The final product should display growth in a clean dashboard.\nBounty #2: Uniswap V3 LP Behavior \u2014 Create a dashboard analyzing LP behavior for Uniswap V3. Given the capital efficiency of the product, Uniswap wanted to better understand the fee tier, volume, and liquidity preferences of LPs.\nBounty #3: Uniswap V2 vs. V3 (L1) \u2013 Over any select time frame, provide analytics highlighting key metrics between the use of V2 compared to V3. V3 KPIs should be broken out by Layer-1 so Uniswap can better understand the drivers behind the adoption of its markets.\nBounty #4: Uniswap Governance \u2013 Study points of decentralization for Uniswap Governance, including all off-chain and on-chain voting procedures. This bounty was earned by selecting three specific data points and conducting an analysis of all relevant governance factors.\n\nThe Community Analytics Program will continue with Round 3, which is currently taking place. Submissions were due on April 1st, 2022. Winners will be announced one week later on April 8th.\n\nGovernance Updates\n\nFeb. 14, 2022 \u2014 <a href=\"https://messari.io/governor/proposal/252348af-cf95-436d-9566-08f2fc6fbc95\">Deploy Uniswap V3 on Harmony [Failed]</a>\n\nThe decision to approve Hermes DeFi with a Uniswap V3 codebase use grant was rejected for not meeting quorum. The proposed idea would have allowed another alternative DEX to use Uniswap\u2019s code to create an AMM on Harmony. Uniswap would, in turn, receive a plethora of benefits, including Hermes token ownership, trading fees, a perpetual trading pool on the AMM, and more. The community\u2019s concerns centered on how this would not have been a native Uniswap app launch, compared to other \u201cDeploy Uniswap to XYZ Blockchain\u201d proposals. Since sentiment was mostly positive, however, the decision to launch on Harmony \u2014 either through a third party or natively \u2014 might potentially be revisited if a quorum can be met.\n\nFeb. 21, 2022 \u2014 <a href=\"https://messari.io/governor/proposal/133d04f0-9d18-43b4-bac4-b8d2fdc5a6af\">Fund the Fee Switch Activation [Failed]</a>\n\nUniswap\u2019s fee switch mechanism is a known topic of debate. At the heart of the question is when and how Uniswap will activate its famous fee switch to distribute protocol revenue to UNI token holders. This proposal offered to create a fund to oversee the application of the fee switch mechanism for both V2 and V3 pools but was rejected by the community.\n\nMarch 12, 2022 \u2014 <a href=\"https://messari.io/governor/proposal/d63fe95c-2775-4b18-978a-0e08a9737127\">Provide Voltz with Uniswap V3 Additional Use Grant</a>\n\nProposed back in Q4, the decision to provide Voltz Protocol with the codebase use grant was successfully executed in March 2022. The codebase granted in this vote will be used for Voltz\u2019s new DeFi primitive for the trading of leveraged interest rate swaps. In return for approving this governance measure, Voltz has agreed to offer 1% of its token supply to Uniswap; if the protocol is successful in attracting liquidity, both Uniswap and Voltz stand to benefit.\n\nMarch 19, 2022 \u2014 <a href=\"https://messari.io/governor/proposal/1b536e61-d995-4503-acbc-5a2020694e41\">Deploy Uniswap V3 on Celo</a>\n\nA temperature check gauging interest in deploying V3 on the mobile-first, environment-focused Celo blockchain was passed in March 2022. Included in the proposal, if ultimately passed, will be $10 million in financial incentives, a third of which would be set aside for environmentally friendly assets such as tokenized carbon credits. By approving the temperature check, Uniswap and the Celo Foundation hope to move to a final vote shortly.\n\nMarch 25, 2022 \u2014 <a href=\"https://messari.io/governor/proposal/30f90fe0-b8ce-4e57-847e-c3379eee3f33\">Deploy Uniswap to Gnosis Chain</a>\n\nThe community voted to pass another temperature check regarding the deployment of Uniswap V3 to Gnosis Chain. Gnosis Chain recently underwent a rebranding effort from xDai Chain in an effort to grow usage of the network. Part of this proposal would include funding from the Gnosis Chain team in the form of $10 million from the Gnosis DAO ecosystem fund. Money received from the DAO will be allocated for a tailored liquidity mining program intended to attract users. A final vote should follow a similar timetable as the one needed to approve V3\u2019s launch on Celo.\n\nFinal Thoughts\n\nUniswap\u2019s first quarter of 2022 was primarily marked by organic growth on the Polygon network, exploring ways to expand V3 to other networks, and the pullback of overall trading across the larger crypto market. That last point is what community members may find concerning: if less trading activity occurs, won\u2019t that be detrimental to Uniswap?\n\nThe answer is a combination of yes and no. Exchanges always want to see healthy trading volume but the reality is Uniswap is well-positioned to deal with any correction in crypto markets. The fact users can enter into LP positions and earn yields suggests an engagement with the protocol will continue. Tracking how the protocol responds to a changing macro investment environment will be at top of mind for the rest of the year.\n\nThis report was commissioned by Uniswap Labs, a member of Protocol Services. All content was produced independently by the author(s) and does not necessarily reflect the opinions of Messari, Inc. or the organization that requested the report. Paid membership in Protocol Services does not influence editorial decisions or content. Author(s) may hold cryptocurrencies named in this report.\n\nCrypto projects can commission independent research through Protocol Services. For more details or to join the program, contact ps@messari.io.\n\nThis report is meant for informational purposes only. It is not meant to serve as investment advice. You should conduct your own research, and consult an independent financial, tax, or legal advisor before making any investment decisions. The past performance of any asset is not indicative of future results. Please see our terms of use for more information.\n\nAppendix\n\n", "references": [{"name": "Jerry Sun", "url": ""}], "published_at": "2022-04-11T13:30:00Z", "author": {"name": "Jerry Sun"}, "tags": ["Decentralized-Finance"], "url": "https://messari.io/article/state-of-uniswap-q1-2022"}, {"id": "f98ec96c-83ba-424e-a000-45ff0fe18fc3", "title": "Weekly Recap Ending April 7", "content": "Notable Messari Intel Updates\n\nTerraform Labs and the Avalanche Foundation have agreed to <a href=\"https://messari.io/intel/event/5ea53450-e78f-4aa5-92ac-0173f310913f\">swap $100 million LUNA and AVAX</a>. Conducted as an OTC deal, the Luna Foundation Guard will add $100 million AVAX to the UST reserve to support the UST/USD peg.\nThe Juno network <a href=\"https://messari.io/intel/event/bb722c05-f1de-49db-9881-8f85fedaa329\">halted at block 2,578,097</a>, which occurred on Apr. 5, 2022, at 11:00 UTC. The Cosmos-based smart contract network chain remained halted for two days before block production resumed.\nOffchain Labs have announced that <a href=\"https://messari.io/intel/event/fb8aba16-51d8-47a3-aac9-49af5d37b90a\">Arbitrum Nitro is ready</a>, and a full-featured Nitro devnet built on Ethereum's Goerli testnet has been launched. This is a fully built-out production implementation of Arbitrum Nitro including fraud proofs, the sequencer, the token bridges, and advanced call data compression.\nOpenZeppelin \u2014 a crypto cybersecurity technology and services company \u2014 has <a href=\"https://messari.io/intel/event/b6a101f2-cb20-446c-9585-488ccc330f3c\">uncovered a vulnerability</a> of Convex Finance protocol that put $15 billion at risk of a rugpull. The bug was fixed, and no funds were lost.\nThe team behind the Original Celo Treasury, Ocelot Labs, has shared details about its <a href=\"https://messari.io/intel/event/ed95795f-ade6-480d-8f4d-d2b099e71015\">plans to create an incentivized testnet and canary network built as a rollup on Celestia</a>.  \n\nNotable Messari Governor Updates\n\nThe Saddle DAO has <a href=\"https://messari.io/governor/proposal/10c1262c-b028-4b6e-8e3b-5c8a3034e41b\">submitted a proposal</a> that aims to deploy a wBTC/pBTC pool to Ethereum and Arbitrum. Saddle will launch a three month liquidity incentive campaign on Ethereum. Voting is currently active.\nThe Gearbox DAO <a href=\"https://messari.io/governor/proposal/ce23ad0e-6e97-4de4-a390-2aba32b18cf3\">submitted a proposal</a> that aims to adopt a new revenue model for the Gearbox protocol by monetizing user collateral, utilizing TVL, and lowering the withdrawal fee. Preliminary discussions are currently underway.\nThe Perpetual Protocol team has <a href=\"https://messari.io/governor/proposal/9405e9ff-0a35-42ac-8734-fe38a872a9f0\">submitted a proposal</a> that seeks to introduce the various changes to Perp V2 tokenomics which include a vote escrow model (vePERP), updates to the Perp protocol reward programs, governance controls for fee distributions, and a new 14-day governance cadence. Preliminary discussions are currently underway.\nThe Origin DAO <a href=\"https://messari.io/governor/proposal/813971da-f6d7-42dc-9469-ef95a5b869dc\">succeeded</a> in passing a proposal that aims to build and deploy a staking framework for OGN tokenholders that allows stakers to stake their OGN. The framework will enable marketplace and royalty fees generated from the Origin Story marketplace to be distributed to OGN stakers.\n\nSector Returns\n\nAfter three consecutive weeks of positive market sentiment, all sectors are underwater this week. Gaming was the biggest loser as it started showing signs of weakening momentum last week. Last week it was the only sector with a negative return, and this week it took the heaviest losses at -13.28%. Web3 was the other category within sector returns that had a double-digit loss week, shedding 9.99%.\n\nTop Assets\n\nDogecoin (DOGE) was the only asset within the top 10 assets by market capitalization that ended the week with a positive return. The original dog coin went so far as reaching a 29% gain this week at $0.1796 but then giving most of it back, closing the week with a 4.5% return. Avalanche (AVAX) was the laggard of the group, ending the week with a 10.4% decline.\n\nDeFi Assets\n\nIt was a very different outcome for the DeFi sector this week compared to last week. Whereas it was the best-performing sector last week, it was among the bottom three this week. Even though the category\u2019s performance was not impressive this week, there was one asset that took the spotlight: Anchor Protocol\u2019s ANC token. The Terra-based lending and borrowing platform saw its token end the week with a 29.5% gain. Impressive considering the rest of the assets in the category finished the week in the red. THORChain (RUNE) was the biggest loser, marking a 17.3% loss for the week.\n\nSmart Contract Platforms\n\nNEAR Protocol stole Waves\u2019 (WAVES) thunder this week as the NEAR token closed with a 24.6% gain, eyeing to break all-time-highs. It was the only asset within the top smart contract platforms by market capitalization sector that ended the week with a positive return. The catalysts behind NEAR\u2019s recent rally are news of a $350 million funding round led by Tiger Global and rumors that NEAR will launch its native stablecoin (USN), an algorithmic stablecoin with a similar mechanism to Terra\u2019s UST and staking APY of 20%. TRON performed the worst within the category and took the last spot with a 13.7% loss.\n\nCurrencies\n\nOnly two currencies made it above water this week with Dogecoin (DOGE) leading the group and Monero (XMR) securing the second position. As mentioned earlier; Dogecoin\u2019s (DOGE) price went as high as 29% at $0.1796 before returning most of the gains. The dog token ended the week with a 4.5% return. The currencies that did not end the week in positive territory traded fairly close to each other throughout the week, closing within a 6.9% range (BTC at -4.9% and BCH at -11.8%).\n\nWeb3\n\nAudius (AUDIO) was the only winner within the Web3 sector this week with half of the assets in the category reporting double-digit losses. The decentralized music streaming platform has been gaining popularity recently, which has been contributing to its appreciation in price. The token saw its price rise as much as 58.7% before returning most of the gains. It was still enough to secure the number one spot with a 10.6% return. Theta (THETA) secured the endmost position with a 16.3% decline.\n\nGaming\n\nDvision Network was the clear outperformer of the gaming sector this week as the virtual reality content ecosystem\u2019s DVI token price rose as high as 54% at $0.5799 but subsequently returned most gains. The performance was enough to help keep its spot in the first place and finished the week with a 21.6% return. Axie Infinity enters its second week in a row where the AXS token comes in last, following the hack of its cross-chain bridge.\n\n", "references": [{"name": "Guillermo Avil\u00e9s", "url": ""}], "published_at": "2022-04-08T20:32:00Z", "author": {"name": "Guillermo Avil\u00e9s"}, "tags": null, "url": "https://messari.io/article/weekly-recap-ending-april-7"}, {"id": "a22902fc-30fd-4c5c-8bdb-7bb83ec01f5c", "title": "Weekly Recap Ending March 31", "content": "Notable Messari Intel Updates\n\nThe Acala team has announced that both <a href=\"https://messari.io/intel/event/dd43249c-7bc3-4c0b-84ec-94fa39e741d2\">Acala and Karura will integrate with Wormhole</a>. Karura is expected to integrate with the Wormhole bridge in the coming weeks, after which Acala will be onboarded shortly after.\nThe Ronin Network bridge was <a href=\"https://messari.io/intel/event/94685297-863b-4cf1-a48d-0d3480ceb065\">exploited</a> for 173,600 ETH and 25.5 million USDC due to Sky Mavis's Ronin validator nodes and Axie DAO validator nodes being compromised on Mar. 23, 2022.\nThe BNB Chain team will introduce <a href=\"https://messari.io/intel/event/b4af76ec-45bb-4eef-8488-819a1823bf9d\">BNB Application Sidechains</a> (BAS) to increase scalability and reduce application fees. BAS will allow teams to choose their own validators sets rather than relying on the BNB Chain for security. Teams working on BNB Chain are expected to share details about the first BAS testnet that will focus on GameFi in the coming weeks.\nThe Evmos team announced that it plans to <a href=\"https://messari.io/intel/event/b75472f9-644f-4e8d-8dbb-50181c2f6986\">relaunch the network</a> in the second week of April. Currently, the team is coordinating with partners on testnet to patch bugs and ensure the system is functioning as expected.\nThe Alchemix Finance team has announced that it plans to <a href=\"https://messari.io/intel/event/6c9ceecd-b8e7-4762-bf0e-98591e20758c\">deploy on additional EVM compatible rollups</a> and layer one blockchains. The multichain rollout will occur in two phases. The first is the ability to bridge ALCX and alAsset tokens onto other chains, followed by the launch of the Alchemix protocol natively on other chains, allowing users the ability to create CDP positions on other platforms like Fantom.\n\nNotable Messari Governor Updates\n\nThe Ampleforth DAO has <a href=\"https://messari.io/governor/proposal/8eff04ad-9411-4804-ade8-f649b935ad1e\">submitted a proposal</a> that aims to execute the first FORTH minting of the FORTH token in order to fund the Ampleforth DAO treasury. Ampleforth governance allows for up to 2% inflation per year of FORTH minting. Voting is currently active.\nA proposal was submitted by Nomad and Blockchain at Berkeley and aims to <a href=\"https://messari.io/governor/proposal/6869274a-c168-4a9a-b101-24f8b18faedf\">deploy Uniswap</a> on the Moonbeam Polkadot parachain. In exchange for this deployment, Nomad will commit $2.5 million to the Uniswap Grants Program to help fund the growth of the multichain Uniswap ecosystem. Voting is currently active.\nThe Illuvium DAO has <a href=\"https://messari.io/governor/proposal/f4a7d0d5-d545-4d43-a9c3-268e887a71ec\">submitted a proposal</a> that aims to launch a Staking Flash Pool targeted at ApeCoin token holders pending ApeCoin\u2019s native staking release. Voting is currently active.\nThe Sushi DAO has <a href=\"https://messari.io/governor/proposal/9e8f7fa3-cc47-4267-92ac-bba0f5877ff5\">submitted a proposal</a> that aims to implement an Omnichain native asset bridge into Sushi, called Stargate, that is built on top of LayerZero. Stargate allows for streamlined transfer of funds across chains and implements UX improvements over traditional bridges. Voting is currently active.\nThe SpookySwap DAO <a href=\"https://messari.io/governor/proposal/07d6522b-93bd-4285-98b6-e78b29cfafdd\">succeeded</a> in passing proposal that aims to approve the sale of SpookySwap\u2019s veNFT, currently worth 1,798,926.05 SOLID to Deus Finance. The price of the sale would be approximately 1.6 million USDC. The rationale for this sale is that the value of the veNFT\u2019s use has lessened. SpookySwap would use the added capital to hire more developers and deepen BOO liquidity.  \n\nSector Returns\n\nThis week marks the third in a row where markets have seen a general positive return with the exception of the gaming sector. The DeFi sector was the best performer of the week, bringing in a return of 13.91%. Next up was the Web3 sector with a return of 10.27%. The gaming sector has been amongst the top performers for the past two weeks, securing multiple double-digit positive return weeks. This week saw a retracement for the sector as it was the only one to end the week on negative territory (-1.27%).\n\nTop Assets\n\nSolana (SOL) was the best performer amongst the top 10 assets by market capitalization this week, securing a 21.3% gain. Avalanche (AVAX) was the next best performer with an 11.4% return. Following closely was Terra (LUNA) which has continued its rally and now currently sits in ATH territory with a weekly return of 10.5%. Ripple\u2019s XRP performed the worst this week and was the only asset to end in a decline within the category (-3.2%).\n\nDeFi Assets\n\nIt has been an action-packed week for the DeFi space as the sector continues gaining momentum. Half of the top DeFi assets posted double-digit returns, with only one asset on the red. Leading the charge among the best-performing sector of the week was THORChain (RUNE) which brought a weekly return of 45.7%. The cross-chain liquidity protocol\u2019s asset has seen its price rise more than 277% since its February bottom. The second best performer was Aave (AAVE), which went on a rally following the release of V3, an upgrade that adds support to six blockchains. The lending and borrowing protocol ended the week with a 27.1% return. FRAX was the laggard of the group with a -1.5% return.\n\nSmart Contract Platforms\n\nWave\u2019s meteoric week comes from the back of three key events surrounding the Layer-1 blockchain. The first is the Waves 2.0 migration, the launch of a $150 million ecosystem fund and a partnership with Allbridge. However, critics have raised concerns regarding the sustainability of the ecosystem, pointing to the fact that the rise in interest in the blockchain was due to the rise in TVL, which was driven by Neutrino (an algorithmic price-stable \"assetization\" protocol built on top of Waves) buying up WAVES. Waves (WAVES) closed the week with a 155.0% gain. Cosmos (ATOM) took the last spot with a -3.2% loss.\n\nCurrencies\n\nThe top currencies sector posted the narrowest set of returns of the week, with returns within a 17.7% range. Leading the sector was Stellar (XLM) with a 10.2% return, the only asset within the category with a double-digit gain. Monero (XMR) was next up with a 4.2% return, followed by Bitcoin (BTC), returning 3.7% on the week. Zcash underperformed compared to the rest of the group, securing the last spot with a 7.5% loss.\n\nWeb3\n\nFilecoin (FIL) was on track to post a +35% return this week but at the last moment gave some of those returns back. It was enough to bring the open video infrastructure asset to compete with Theta Network (THETA) for the first spot. Filecoin ultimately secured the spot for the best performer with a 26.2% return while Theta Network (THETA) ended the week with a 23.9% return. Helium (HNT) took the last spot of the group with a -3.2% return.\n\nGaming\n\nSmooth Love Potion (SLP) was the best performer of the gaming sector this week, bringing in a 13.3% return for the week. Close by was Enjin (ENJ) which posted a weekly gain of 12.2%. Ultra (UOS) took the third spot with a 9.8% gain. Axie Infinity (AXS) took the last spot this week as it posted a loss of 11.9%, mainly driven by the news surrounding the Ronin bridge hack in one of the largest crypto exploits to date.\n\n", "references": [{"name": "Guillermo Avil\u00e9s", "url": ""}], "published_at": "2022-04-01T13:55:00Z", "author": {"name": "Guillermo Avil\u00e9s"}, "tags": ["Macro"], "url": "https://messari.io/article/weekly-recap-ending-march-31"}, {"id": "030b9757-f41b-481e-ab9f-41ee70222480", "title": "Filecoin Has It: An Ecosystem Overview", "content": "Key Insights\n\nFilecoin offers decentralized storage and cloud services on a global, open market. It has the largest market share in terms of used storage and network capacity.\nThe ecosystem has grown to over 330 projects up from \u200b\u200b40 at the start of 2021. Various use cases have emerged, including NFTs, Web3, gaming, metaverse, and audio/video.\nFilecoin aims to offer the foundation for data-intensive Web3 services through verifiable storage, content retrieval, compute, and programmable apps coming to the fore.\nThe main challenge for Filecoin is to pass the test of time and prove its reliability.\n\nData Availability and Integrity\n\nAlmost every Internet user relies on centralized services to store and process data. This has two major shortcomings: users are no longer in full control of their data, and it is hard to verify the integrity of the data. To address these shortcomings, a new generation of protocols and peer-to-peer networks have enabled decentralized storage and cloud services. One prominent protocol of this kind is Filecoin, which provides a cryptoeconomic guarantee that the data exists and can be accessed at any time. \n\nPut simply, Filecoin is a peer-to-peer version of AWS that regularly verifies data availability and integrity. This is made possible by deals negotiated on open markets for data services.\n\nDeals in Open Markets\n\nA storage deal is like a service level agreement (SLA) enforced on the Filecoin blockchain. Storage deals are agreements where users pay fees to storage providers to store their data. The terms of the deal include the fee amount and the duration of the storage deal.\n\nThe open-market environment incentivizes storage providers to offer their storage capacity in an efficiently priced way. That is, prices are determined by supply and demand dynamics, rather than a fixed pricing structure. To incentivize storage providers to participate in deals, Filecoin rewards them with the network's native token (FIL).\n\nFilecoin has two functions to keep data safe. First, it uses a cryptoeconomic guarantee that verifies the storage with zero-knowledge proofs. Second, it uses an economic penalty: if the data is unretrievable or the storage fails, storage providers are penalized through locked-up collateral. To enforce this, the Filecoin protocol requires storage providers to submit two ongoing verifiable cryptographic proofs. Proof of Replication first verifies that the data has been fully replicated. Upon success of this initial check, storage providers use Proof of Spacetime every day to prove that a random piece of data is still stored and available for retrieval throughout the deal\u2019s lifetime. Any failure leads to a penalty.\n\nTo retrieve data, users pay a retrieval provider to fetch the data for them. Unlike storage deals, which are handled on-chain, retrieval deals may happen off-chain. This results in a faster data retrieval process.\n\nTechnology in a Nutshell\n\nFilecoin is built on top of the InterPlanetary File System (IPFS), which serves as the Filecoin network\u2019s distributed data storage and sharing layer. Although some people use Filecoin and IPFS interchangeably, there are important differences between the two.\n\nPut simply, IPFS is like torrents on steroids. Similar to torrent trackers, IPFS uses a fingerprint of the data. Unlike torrents, IPFS leverages a single global peer-to-peer network. IPFS essentially tells users where their data is, but it lacks a built-in mechanism to incentivize data storage, which led to the development of Filecoin in the first place. Filecoin thus complements IPFS and facilitates an open market for storage with a guarantee, essentially making Filecoin the incentive layer of IPFS.\n\nIPFS may be regarded as a peer-to-peer version of HTTP, with an important twist. Traditional URLs and file paths identify a file by its specific geo-location on a server. IPFS uses content addressing to store data decentrally. It references a file by what\u2019s in it, i.e., by its content. A content address is unique and is the result of hashing, which is essentially the cryptographic compression of content into a long string of characters. When retrieving a file, the network only needs the file\u2019s hash to locate the nodes storing that file\u2019s content.\n\nNetwork Dynamics\n\nThanks to its open-market policy and incentive mechanisms, Filecoin has been able to attract significant storage capacity. Regardless of market conditions, Filecoin\u2019s committed storage capacity has grown steadily since 2020 to over 16,000 PiB, which is equivalent to approximately 65,000 copies of Wikipedia or 1,600 Netflix movie archives as of March 2022. The network capacity comes from over 3,900 decentralized storage providers distributed around the globe.\n\nWhat\u2019s the Demand for Filecoin?\n\nDemand for Filecoin comes from both Web2- and Web3-specific storage use cases. Adding up how much storage capacity is bound in deals quantifies the demand for Filecoin. However, when analyzing the underlying content in the storage deals, it is difficult to distinguish between useful storage and generated randomness as a way for storage providers to abuse the network.\n\nTo increase the amount of useful storage capacity on Filecoin, the Filecoin Plus incentive program was developed. The program incentivizes storage providers to participate in verified deals by increasing their share of the block rewards over time.\n\nStorage deal inflows grew from 400 TiB in October 2020 to over 7,600 TiB in March 2022, and Filecoin Plus clearly contributed to that growth. Since Q4 2021, there has been a transition from Filecoin Regular deal inflows (unverified data) to predominantly Filecoin Plus verified deal inflows.\n\nUsed storage on the network (i.e., active storage deals) has grown steadily from 0.25 PiB (1 PiB = 1024 TiB) in October 2020 to 45 PiB in March 2022. As shown below, over 26 PiB have resulted from Filecoin Plus deals, representing 57% of the total active deals on the network. \n\nThe recent flippening of Filecoin Regular deals by Filecoin Plus deals indicates that the verified data incentive mechanism is working as planned. The sudden drop-off in terms of active Filecoin Regular deals in December 2021 was a result of several storage providers going offline. The loss has been compensated by other storage providers picking up and contributing to the growth in Filecoin Plus active deals as of January 2022. As a result, the total deal volume fully recovered.\n\nWhile supply vastly exceeds demand, storage capacity is only one side of the story. What is equally important is the amount of used storage on a network. With 45 PiB of used storage and 16,000 PiB of storage capacity, Filecoin has a storage utilization ratio of 0.3%. To put these network metrics into perspective, competing decentralized storage providers, like Sia and Storj, have 6 PiB and 14 PiB, respectively, of network capacity. Total storage usage by Sia and Storj stands at 2.2 PiB and 8.6 PiB, respectively. In terms of storage utilization ratio, Sia and Storj surpass Filecoin at 36% and 60%, respectively. Although Arweave has 0.05 PiB of data stored, it has not been included since its data stored is negligible compared to the other storage networks: while it is currently growing from a relatively small base, it does not have network capacity per se.\n\nWhile the introduction of the Filecoin Plus program is a step forward, there is a concerted effort to incubate new businesses and use cases for building on Filecoin. The Filecoin ecosystem is channeled towards onboarding a large variety of use cases: from decentralized storage for NFTs, to music and video streaming, to metaverse and gaming.\n\nEcosystem of Developers and Builders\n\nFilecoin is actively supported by several organizations with the common goal of growing the Filecoin ecosystem. These organizations come together to form the Ecosystem Working Group. The responsibilities of the Ecosystem Working Group participants include maintaining and upgrading the underlying protocols, supporting the growth of the ecosystem, and facilitating governance. The most prominent organizations in the group include Protocol Labs, Filecoin Foundation, and Outercore. An overview of the main participating organizations is shown below.\n\nThese organizations have been actively developing a funnel of developers and builders through activities such as hackathons, accelerators, grants, mentorship and growth support. The funnel is designed to help early-stage projects and teams get to the point where they are ready to receive funding and investments. As a result, over 330 projects are currently being built on Filecoin and IPFS. Below is a breakdown of the funnel, showing projects\u2019 progression over time, grouped by their maturity stage.\n\nThe main objective for 2022 is to enable as many early-stage projects in the ecosystem to translate into full-fledged businesses -- i.e.,  advancing from initial stages all the way through Series D and beyond.\n\nAs a whole, the ecosystem has grown significantly in terms of integrations with applications and clients, tools for developers, and infrastructure. Recently, the Ecosystem Working Group has prioritized making it easier for end-users and developers to work with Filecoin. This has led to the development of services like Textile Powergate, Estuary, and NFT.Storage. All use cases in the Filecoin ecosystem are available here. A map of selected ecosystem players is shown below.\n\nSource: Filecoin\n\nIn terms of notable initiatives in 2022, the forthcoming launch of the Filecoin Virtual Machine (FVM) is worth highlighting. FVM is set to unlock programmable storage primitives (e.g., storage bounties, auctions), cross-chain interoperability bridges (e.g., to Ethereum, Solana, NEAR), data-centric DAOs, as well as Layer-2 solutions (such as reputation systems, data availability sampling, computation fabrics, and incentive-aligned Content Delivery Networks).\n\nMain Use Cases Leveraging Filecoin\n\nThe Filecoin ecosystem is large and rapidly expanding, positioning itself to become the backbone of the decentralized web. With the rising demand for cloud storage, Filecoin provides a decentralized alternative to the popular centralized platforms. Numerous additional use cases have emerged, and new ones are guaranteed to materialize in the near future. Four major categories have already found high demand: (1) NFT and Web3 storage, (2) permanent storage and Web2 datasets, (3) metaverse and gaming, and (4) audio and video.\n\nNFT Storage\n\nDuring the summer of 2021, NFTs entered the mainstream spotlight. Driven by network effects, NFTs dominated the crypto landscape in the form of social media profile pictures, fine art, collectibles, music, and more. Interestingly, a large number of NFTs generally point to off-chain storage locations for their metadata since storing it on-chain isn\u2019t feasible. Shortly after the 2021 hype, it became evident that a large portion of NFT metadata was not being stored in a decentralized, immutable manner, putting the content and value of the NFTs at risk. To address this shortcoming, NFT.Storage was developed.\n\nNFT.Storage utilizes Filecoin and IPFS to provide a simple decentralized storage solution specifically for NFT content and metadata. It focuses on perpetual redundant storage through dedicated IPFS servers managed by NFT.Storage and Filecoin. By participating in the Filecoin Plus incentive program, NFT.Storage is able to offer an unlimited amount of storage for NFTs, free of charge.\n\nLaunched in April 2021, NFT.Storage has already supported the permanence of over 40 million uploads of NFT data, totaling up to more than 260 TB of data. The simplicity of the service has allowed a wide range of users from individual artists to large marketplaces such as OpenSea, MakersPlace, MagicEden, Holaplex, Jigstack, and Galaxy to take advantage of perpetual NFT storage.\n\nWeb3 Storage\n\nFilecoin aims to become the storage layer of Web3. To that end, Filecoin has ongoing collaborations and storage bridges with various major blockchains and smart contract platforms. One of the most recent examples is <a href=\"https://messari.io/article/polygon-a-multi-sided-approach-to-zk-scaling\">Polygon</a>. The goal of the partnership is to meet the storage and infrastructure needs of developers for games and NFT-related Web3 projects. Notably, Polygon developers can easily use Filecoin through the storage bridge. Filecoin has also seen growing traction in the Solana ecosystem with a number of protocols and NFT marketplaces offering native support, including Metaplex, Magic Eden, and Holaplex.\n\nSource: Filecoin\n\nTo simplify building Web3 apps on Filecoin, the team launched Web3.Storage. It allows developers to store and retrieve data directly on Filecoin instead of dealing with complex decentralized storage networks. \n\nWeb3.Storage uses redundancy to store data across multiple Filecoin miners and geographically-distributed nodes on IPFS. These IPFS nodes are run by the Web3.Storage team. In addition, the service offers free storage indefinitely with unlimited data. This is made possible by the economics of the Filecoin Plus mechanism. Overall, Web3.Storage has experienced steady growth since its launch, growing from 3 million uploads in August 2021 to 16 million in March 2022.\n\nPermanent Storage & Web2 Datasets\n\nSimilar to Arweave, Lighthouse allows Filecoin users to permanently store files for a fixed price. In addition, the Filecoin Virtual Machine will enable permanent storage to be automated into smart contracts. A prominent use case for permanent storage is data archival. Given Filecoin\u2019s scale, the goal is to make archival storage as cost-effective as possible \u2014 essentially becoming a commodity for developers building apps on top of Filecoin. This enables the information layer for humanity to be created and preserved. \n\nThe Shoah Foundation is an essential project that archives testimonials from genocide survivors. When it comes to large public datasets, the Internet Archive project stores websites and documents for public access using Filecoin. In addition, Zarr and GainForest store big public datasets with the goal of preventing natural catastrophes related to climate change. The Zarr project makes climate data available to researchers for analysis at scale. GainForest leverages satellite images to combat the effects of climate change.\n\nMetaverse and Gaming\n\nThere is a new generation of metaverse and gaming use cases leveraging Filecoin and IPFS. The underlying common aspect of these use cases is user monetization. In this sense, Blockbets and Gala Games support revenue generation and payouts for gamers. When it comes to artist monetization, Mona supports artists displaying their high-end creations in virtual spaces and selling them to collectors. Metaverse AI takes human interactions to the next level: it allows gamers to play and monetize their interactions with other AI-powered virtual humans inside the game.\n\nAudio and Video\n\nRecently, several audio and video applications leveraging Filecoin and IPFS have gained substantial traction. Take, for instance, the Web3 alternatives to Spotify or SoundCloud. Audius is a music streaming service that looks and feels like SoundCloud, but leverages IPFS. Currents.fm and Inflow Music support communities of music creators and curators. Huddle01 could be the next Zoom. It\u2019s a low-bandwidth video conferencing platform tailor-made for remote meetings, with a focus on NFT communities.\n\nRegular users may not be able to tell that Audius, Currents.fm, Inflow Music, or Huddle01 are decentralized or that they specifically leverage Filecoin and IPFS. Nonetheless, there is an ongoing shift towards <a href=\"https://messari.io/article/the-nft-effect-on-the-music-industry\">Web3 streaming applications</a> without users necessarily noticing it.\n\nAs the Filecoin ecosystem matures, more use cases are constantly being discovered. The development of the Filecoin Virtual Machine will unlock previously impossible use cases, creating a whole new class of use cases.\n\nConclusion\n\nWhile decentralized storage is still in its early days, the Filecoin ecosystem has been thriving over the years. Filecoin and IPFS have been leveraged by a wide range of use cases, including NFTs, Web3, gaming, metaverse, and audio/video. Alongside Filecoin, alternatives like Arweave, Storj, and Sia could use the foundation of IPFS at scale. \n\nThe adoption of decentralized storage solutions and the integration of smart contracts built on top may open the door to novel applications. A significant milestone would be getting major browsers to adopt IPFS. Open data initiatives and decentralized compute may enable the next generation of applications beyond storage. \n\nThe main challenge for Filecoin is to prove its reliability as a storage provider and as an enabler of data-intensive Web3 services. Filecoin and IPFS operate at the cutting edge of the Web3 paradigm and offer an essential foundation for Web3 development. Their success depends on the Web3 applications building on those protocols.\n\nThis report was commissioned by Filecoin, a member of Protocol Services. All content was produced independently by the author(s) and does not necessarily reflect the opinions of Messari, Inc. or the organization that requested the report. Paid membership in the Hub does not influence editorial decision or content. Author(s) may hold cryptocurrencies named in this report and each author is subject to Messari\u2019s Code of Conduct and Insider Trading Policy. Additionally, employees are required to disclose their holdings, which is updated monthly and published <a href=\"https://www.google.com/url?q=https://messari.io/article/messari-employee-holdings-policy-and-disclosures&source=gmail-imap&ust=1647457925000000&usg=AOvVaw0jwd9uUO4e2D2TzMmDVmb\">here.</a> Crypto projects can commission independent research through Messari Protocol Services. For more details or to join the program, contact hub@messari.io. This report is meant for informational purposes only. It is not meant to serve as investment advice. You should conduct your own research, and consult an independent financial, tax, or legal advisor before making any investment decisions. Past performance of any asset is not indicative of future results. Please see our terms of use for more information._", "references": [{"name": "Mihai Grigore ", "url": ""}, {"name": "Sami Kassab", "url": ""}], "published_at": "2022-03-30T13:30:00Z", "author": {"name": "Mihai Grigore , Sami Kassab"}, "tags": ["Web-3"], "url": "https://messari.io/article/filecoin-has-it-an-ecosystem-overview"}, {"id": "13096134-b8fe-4de0-80b3-aacd2abefddd", "title": "Osmosis: Diffusing Liquidity Across the Cosmos Ecosystem", "content": "Key Insights\n\nOsmosis is a decentralized exchange built on its own sovereign, interoperable Layer-1 blockchain in the Cosmos ecosystem\nIt was the first app-chain to see significant IBC transfer volume and kickstarted DEX activity in the ecosystem\nNotable features of the DEX include highly customizable pool parameters, superfluid staking, and plans to incorporate MEV resistance into its underlying architecture\nThe protocol is powered by the native OSMO token, which can be used for staking and governance. OSMO rewards are also issued via liquidity incentives for LPs\n\nIntroduction\n\nInvestors\u2019 belief in a multichain world as an answer to blockchain\u2019s scaling problems has drawn interest towards the Cosmos Network ecosystem, where an \u201cInternet of Blockchains\u201d exists to accommodate a universe of independent, sovereign app-chains. Each app-chain in the network functions as its unique Layer-1 blockchain designed to add to the functionality of the Cosmos Network.\n\nTo connect such an ecosystem of blockchains, a healthy financial exchange is necessary. Through these exchanges, capital allocators gain the liquidity to foster a healthy market, invest in growth projects, and drive investment to promising opportunities. The Cosmos Network supports its own native DEX, but it is the Osmosis Protocol that leads the pack in terms of liquidity, trading volume, and fees. In this report, we\u2019ll take a look at Osmosis and understand the features that make it stand out compared to other like-minded automated market makers (AMMs) in this multichain world.\n\nOverview of Osmosis\n\nBackground\n\nOsmosis is an Inter-Blockchain Communication (IBC)-supported DEX in the Cosmos ecosystem. It was founded in January 2021 by Sunny Aggarwal, Josh Lee, and Dev Ojha, with the parent company Osmosis Labs being responsible for code development.\n\nThe co-founders each share experience working in the blockchain space. All three began at Tendermint, known for its byzantine-fault tolerance consensus engine. During that time, they worked on the underlying architecture of the Cosmos ecosystem and afterward split to work on various projects including the Keplr wallet. It was during this time they rejoined to start Osmosis, with the intention of building a fully-customizable DEX.\n\nHow Osmosis Works\n\nOn a functional level, Osmosis operates similarly to other AMMs. Liquidity pools lock tokens into a smart contract that self-executes trades via token swaps. Counterparties to traders come in the form of liquidity providers (LPs), who provide the underlying tokens, i.e., liquidity, to those pools. In return, those LPs receive designated LP tokens denoting their contribution to the pool, thereby measuring a share of the accrued fees generated. All traditional stuff.\n\nFurthermore, like many other AMMs, Osmosis relies on a deterministic pricing model to ensure the respective weights of tokens in each pool remain consistent. In fact, almost all AMMs use deterministic pricing because it helps determine the number of tokens in each trade. Although market pricing of any token may change, opportunities for arbitrageurs are minimized when the underlying pricing formula is maintained.\n\nLiquidity Incentives\n\nTo ensure abundant liquidity, the DEX institutes two mechanisms to help institute long-term viability: bonded liquidity gauges and exit fees.\n\nLongtime DeFi users may recognize the former as traditional liquidity incentives. The mechanism for bonded liquidity gauges is simple: LPs who add liquidity to a pool for a minimum period of time are rewarded with the native OSMO tokens.\n\nLPs can choose the period of time for which they willingly want to bond their tokens. The exact amount of OSMO rewards earned depends on the length of bonding time and the number of bonded tokens, all decided by protocol governance. Interestingly, not all pools receive rewards either; OSMO holders decide which pools earn liquidity incentives. Certain pools receive \u201callocation points,\u201d and subsequent OSMO rewards are issued proportionally based on each pool\u2019s points count.\n\nFortunately for the pools without internal incentives, OSMO tokens are not the only eligible rewards. External incentive providers, such as those traded within a pool, are able to distribute their own rewards. Just as with internal liquidity incentives, the external provider chooses which variables to set, such as the time needed for eligibility or the number of rewards.\n\nExit Fees\n\nIf bonded liquidity gauges are the carrot for long-term liquidity, exit fees are the stick. When LPs withdraw capital from liquidity pools, a small fee is charged in the form of LP tokens. This exit fee is determined by the pool creator and is designed to benefit the remaining contributors of the pool, seeing as the exit fee is burned. In total, when LPs decide to withdraw their liquidity, they get back their initial capital plus accrued transaction fees minus exit fees and impermanent loss.\n\nTraction\n\nNotably, Osmosis was the first IBC-enabled DEX in the Cosmos ecosystem. Although other DEXs such as Gravity DEX and Injective Protocol now exist, Osmosis was the first Cosmos-based app-chain to see a high volume of IBC transfers. Due to its first-mover advantage, Osmosis continues to rank first in IBC transactions and second in total transactions, behind the Terra ecosystem.\n\nOsmosis has benefited from the growing interest in the Cosmos ecosystem. Total trading volume and locked liquidity have both been on the rise since its launch. In fact, both metrics saw all-time highs within the last 30 days. And given past Osmosis activity or ownership of the OSMO token as a rumored qualifier for airdrops in the Cosmos ecosystem, there are no immediate signs of slowing down.\n\nProtocol Features\n\nLiquidity Pool Customization\n\nMuch of the inspiration behind Osmosis came from an Ethereum-based DEX, Balancer, and its ability to offer multi-asset liquidity pools. In the eyes of the Osmosis Labs team, blending assets into liquidity pools was the first of many customizable options. Through this level of customization, the role of the DEX evolved from only being able to trade spot-priced assets to be able to support an options market, interchain staking, and more.\n\nOsmosis pools offer flexible market-maker functions. Unlike Uniswap\u2019s constant product, Balancer\u2019s constant mean, and Curve\u2019s hybrid functions, Osmosis\u2019s functions are variable, thus realizing its goal of becoming an \u201cAMM laboratory.\u201d The DEX encourages liquidity providers to experiment with different market-making functions of their own choice. Osmosis spurs increased experimentation because new variations can ultimately lead to innovative solutions for reducing slippage or impermanent loss costs.\n\nPool parameters, including swap costs, initial token weights, and time-weighted average price calculations, are set by the pool\u2019s original creators. However, all Osmosis pools are self-governing by LP token holders. Voting power is distributed in accordance with fractional ownership of the capital in the pool. Longer capital commitments receive a boost in voting share. Since Osmosis expects the market to determine optimal capital efficiency, self-governing pools are merely another parameter to tweak to build the most competitive liquidity pool. The end game is a competitive market that provides greater skin-in-the-game for capital allocators.\n\nSuperfluid Staking\n\nCompared to a rollup-centric ecosystem like Ethereum\u2019s, multichain ecosystems like the Cosmos ecosystem face the challenge of bootstrapping their own security. Thus, for Zones in the Cosmos ecosystem, the issue of bootstrapping security becomes of utmost essence.\n\nOsmosis has designed a clever solution for this problem: superfluid staking. Considered one of the biggest advancements in proof-of-stake since liquid staking, this staking method allows LPs to provide liquidity with their native OSMO tokens while simultaneously using those same tokens to bring security to the underlying network. A visual representation of the Osmosis superfluid staking platform is below.\n\nThe superfluid staking model <a href=\"https://messari.io/article/the-superfluid-evolution-of-stake\">flips existing liquid staking solutions upside down</a>. Instead of providing liquidity to a bonded asset, superfluid staking takes bonded liquidity from an asset and stakes it to the network. The fact the asset is already bonded to local liquidity pools only helps simplify the network\u2019s balance between security and economic liquidity.\n\nWhitelisted liquidity pools are the only ones eligible to participate in superfluid staking. That\u2019s because Osmosis wants to limit the minting of risky assets by malicious actors who can then drain staked liquidity pools for the underlying OSMO token. Preventing this from happening is crucial for strong security, and the decision to determine whitelisted pools are eligible is left up to Osmosis governance.\n\nThe benefit of superfluid staking should be clear: it allows LPs to double their rewards through yields generated from trading fees and through staking rewards for securing the network. Meanwhile, the underlying network benefits from the extra security, leading to a win-win situation for all parties. Even more exciting, Osmosis doesn\u2019t have to be the only beneficiary. The protocol can offer staking-as-a-service to help other app-chains bootstrap their security too. The end result is a mesh network of intertwined security backed by this superfluid staking feature.\n\nCosmWasm Integration\n\nIn early March, Osmosis announced it had successfully worked with blockchain devtool company, Confio, to integrate the CosmWasm inter-blockchain smart contract engine into the Osmosis Protocol. By doing so, Osmosis can now access an untapped pool of resources because CosmWasm hosts one of the largest developer ecosystems outside of Ethereum and Solana.\n\nCosmWasm offers a WebAssembly virtual machine (Wasm) for developers familiar with Go and Rust. Developers receive a toolset to build new permissioned smart contracts which can run across multiple Cosmos SDK blockchains. Think of it as a framework intended to boost interoperable smart contract functionality between various Cosmos app-chains.\n\nThe announcement potentially hints at additional features coming to Osmosis, such as yield aggregators, liquidity management tools, and more. While this is exciting news for those looking to maximize yields, the Osmosis Labs team has made it clear its end goal is to remain an interoperable DEX-focused protocol \u2013 with additional bits and pieces from other contributors.\n\nMEV Resistance\n\nOsmosis\u2019s upcoming roadmap includes the tackling of maximum extractable value (MEV), one of the largest challenges seen in decentralized transactions. Since all trades are facilitated through the blockchain \u2013 meaning they\u2019re available on the public ledger \u2013 miners are able to rearrange transactions within their block to their own benefit. Miners would have an advantage over ordinary users in situations where it is important to get a transaction approved first, such as for front-running trades or acquiring a prized NFT. This type of MEV behavior disadvantages DEX users in favor of those with privileged access to the blockchain.\n\nMEV originated as a privacy issue only to evolve into a financial one. According to MEV Explore, over $600 million has been extracted away by miners since January 2020 on Ethereum alone.\n\nOsmosis\u2019s solution to MEV is to implement a form of encryption called threshold cryptography.\n\nThe process for threshold cryptography begins before transactions hit the mempool. Encrypted transactions hide transaction details from validators, preventing validators from figuring out which transactions to prioritize first. Only after the transactions are finalized and executed can validators see the details. Note that only the trade detail is encrypted during this process; the fee amount will continue to remain public. As a result, pending transactions continue to get added to the blockchain in order of fee amount.\n\nOSMO Tokeneconomics\n\nAs the native governance token, OSMO is behind all the features of the Osmosis app-chain. A maximum supply of 100 million tokens will be set in circulation daily epoch-based issuances. The emissions schedule is similar to Bitcoin\u2019s famous \u201chalvening,\u201d except Osmosis will follow a \u201cthirdening\u201d schedule, reducing the number of new tokens by a third every year. The tokens applicable for issuance will be split among staking rewards, developer vesting, community pool allocations, and liquidity mining incentives. The full supply curve schedule can be found below.\n\nThe OSMO token launch was a fair launch distributed across airdrop recipients and the protocol\u2019s strategic reserve. Notably, 50% of the supply was airdropped to ATOM holders, and the remaining 50% was set aside for a strategic reserve, which will support the ongoing development of the protocol. The reserve tokens could be used to fund open-source projects, make investments, or provide grants.\n\nConclusion\n\nCompetition for transaction volume is fierce. At the end of the day, successful applications must continuously innovate to keep attracting liquidity providers. The Osmosis community believes the exchange has a strong chance to corner the market. With its position as a multichain centerpiece, status as a host to flexible pool parameters, reputation as a staking innovator, and exciting MEV-resistant roadmap, Osmosis is prepared to capture a significant amount of liquidity and protocol revenue. Only time will tell how successful it\u2019ll be \u2013 but early indicators look promising.\n\nThis report was commissioned by Osmosis, a member of Protocol Services. All content was produced independently by the author(s) and does not necessarily reflect the opinions of Messari, Inc. or the organization that requested the report. Paid membership in the Hub does not influence editorial decision or content. Author(s) may hold cryptocurrencies named in this report and each author is subject to Messari\u2019s Code of Conduct and Insider Trading Policy. Additionally, employees are required to disclose their holdings, which is updated monthly and published <a href=\"https://www.google.com/url?q=https://messari.io/article/messari-employee-holdings-policy-and-disclosures&source=gmail-imap&ust=1647457925000000&usg=AOvVaw0jwd9uUO4e2D2TzMmDVmb\">here.</a> Crypto projects can commission independent research through Messari Protocol Services. For more details or to join the program, contact hub@messari.io. This report is meant for informational purposes only. It is not meant to serve as investment advice. You should conduct your own research, and consult an independent financial, tax, or legal advisor before making any investment decisions. Past performance of any asset is not indicative of future results. Please see our terms of use for more information._", "references": [{"name": "Jerry Sun", "url": ""}], "published_at": "2022-03-29T14:00:00Z", "author": {"name": "Jerry Sun"}, "tags": ["Decentralized-Finance", "Decentralized-Exchanges", "Layer-1"], "url": "https://messari.io/article/osmosis-diffusing-liquidity-across-the-cosmos-ecosystem"}, {"id": "2ce07fc8-9a70-4f5e-8ad8-afac95f92e3d", "title": "Oasis Network: Growing a Responsible Data Economy with Privacy", "content": "Key Takeaways\n\nThe Oasis Network is designed to be a privacy-focused, scalable, Proof-of-Stake (PoS) Layer-1 smart contract platform that is Ethereum Virtual Machine (EVM) compatible.\nThe network's value proposition is its multi-layer modular architecture that enables the scalability and flexibility to deploy low-cost privacy-focused smart contracts.\nGiven the size of the Layer-1 smart contract economy, there is a significant opportunity for the network to accrue value.\nThe launch of the Emerald ParaTime and the resulting launch of DeFi applications sparked noticeable network activity at the beginning of 2022.\nLaunching the Cipher ParaTime in Q2 2022 is anticipated to bring Oasis Network's confidential smart contracts into existence and drive new use cases within DeFi.\nThe Parcel ParaTime is a set of privacy-first, data governance APIs designed to give users better control of their data and enable developers to deploy an isolated compute environment for privacy-preserving analysis.\nA growth strategy consisting of an ecosystem fund, grants programs, developer accelerators, and community initiatives is in place to support ecosystem growth.\n\nThe Layer-1 smart contract platform race for market share and adoption turned into an all-out sprint as use cases expanded and alternatives to the Ethereum network experienced exponential growth through the end of 2021. Networks like Terra, BNB Chain, Fantom, and Avalanche witnessed unprecedented growth in average daily network transactions, active daily addresses, market capitalization, and total value locked (TVL). Much of the growth can be attributed to the competitive forces shaping traditional industry strategies that resemble Michael Porter's Competitive Strategies. Congestion on the Ethereum network, the slow rollout of Layer-2 scaling solutions, the ability to bridge assets cross-chain, and the ability to execute smart contracts on more efficient networks allowed new alternatives to gain a competitive position as differentiated solutions and cost leaders.\n\nWhile Layer-1 platforms exhibit many fundamental differences, almost all of them aim to solve the blockchain trilemma by attaining adequate decentralization, scalability, and security while hosting smart contracts. While their smart contracts inherit blockchain's data availability and security, they also inherit its lack of confidentiality. With that in mind, the top Layer-1s do not currently support privacy on their public networks as all records are logged on the blockchain, allowing anyone to read their contents. This presents privacy concerns, due to the possibility of linking ledger addresses to real identities. As adoption grows, users may start to prefer privacy surrounding their activity or sensitive data. This lack of confidentiality, in a sense, could potentially be considered a fourth problem for Layer-1 platforms to solve, and perhaps a \"quadrilemma\" is on the verge of sparking the next leg of the race towards adoption.\n\nAs adoption continues, new platforms with privacy solutions may start to experience the exponential growth realized in the recent past. One such platform, the Oasis Network, is a Layer-1 that aims to solve the trilemma and do so with the flexibility to host privacy-enabled smart contracts. With its unique architecture and deployment of confidential computing technology, the Oasis Network is planting the seeds for growing an open, data-responsible economy with privacy.\n\nBackground\n\nThe Oasis team was formed in 2018 and consists of contributors from around the globe with diverse backgrounds ranging from start-ups to traditional finance and tech companies. The team also has strong roots in academia. Dawn Song, a professor at the University of California, Berkeley, known for her research in computer security and artificial intelligence, is the Founder of Oasis Labs. Oasis Labs is an active member of the Oasis Ecosystem, and one of the early contributors to the Oasis technology. The team raised funds from well-known venture capital firms and investors such as Andreessen Horowitz (a16z), Polychain Capital, Pantera, and Binance Labs, among others, to support the network\u2019s initial development. After the private testnet launch in 2018, the public testnet underwent various iterations alongside bug bounties, audits, and network upgrades before the public mainnet launch in 2020. Fast forward to today, and it has since gone through additional technical developments and an ecosystem expansion that includes a $200 million ecosystem fund while becoming the second-most <a href=\"https://messari.io/article/messari-fund-analysis-q4-21-examining-liquid-portfolios-of-crypto-funds?utmsource=newslettertop&utmmedium=organicemail&utmcampaign=fundanalysisq421\">commonly held</a> asset by crypto funds as of Q4 2021.\n\nSource: Oasis\n\nAt the onset, the Oasis Network was designed to be a privacy-focused, scalable, Ethereum Virtual Machine (EVM) compatible Proof-of-Stake (PoS) smart contract platform. Its privacy and scalability features are designed to advance DeFi and Web3 by creating a new type of digital asset called Tokenized Data. Unlike existing tokenized data solutions at the application layer, the Oasis Tokenized Data solution is at the network layer, allowing applications to build on top of and harness the benefits of its confidential compute technology. Collectively, the design is intended to allow users to take control of and monetize the private data they generate, thereby incentivizing what Oasis calls a data-responsible economy.\n\nNetwork Architecture\n\nThe Oasis Network utilizes a modular architecture that separates consensus and smart contract execution into the Consensus Layer and the ParaTime Layer, respectively. Both layers are integrated to provide the same functionality of a single network. However, separating these layers allows ParaTimes to process transactions of different complexity in parallel with shared consensus. With this flexibility, workloads and upgrades processed on one ParaTime will work symphonically with consensus to independently ensure network security and finality without impacting other ParaTimes.\n\nSource: Oasis\n\nThe Consensus Layer\n\nThe Consensus Layer accepts updated state hashes from ParaTimes and writes them into the next block of the Oasis blockchain, while ParaTimes operate as separate networks that can be configured and customized to run specific applications. The network's two-layer modular solution addresses both security and scalability. While the flexibility to develop ParaTimes in isolation supports scalability, it also enables specific execution solutions such as confidential computation technology to address smart contract privacy concerns.\n\nSource: Oasis\n\nThe Consensus Layer is the foundation of the Oasis Network and, in and of itself, is designed around the principles of modularity, which allows for agnostic consensus such that it can be interchangeable with any consensus logic in the future. Currently, the base layer consists of a modified version of Tendermint Core, a Byzantine-Fault Tolerant (BFT) consensus engine. It uses a PoS mechanism and a decentralized set of validator nodes and node operators. The validator nodes are randomly selected to form a committee that accepts state hashes from ParaTimes, maintains the public ledger, and ultimately secures the network. The committee's size dictates the security of the Oasis blockchain and is currently set to 110 validator nodes. Further, unlike most consensus layers, node operators run distinctive types of nodes that are tasked with providing a minimal set of services (e.g., staking and registry) specifically for ParaTime functionality.\n\nThe Consensus Layer Beyond Tendermint Core\n\nAs the Consensus Layer diagram above illustrates, the multiple layers of consensus begin at the top, with the nodes tasked with providing a minimal set of services. These services range from maintaining epoch-based time-keeping services to coordinating key manager runtimes and storing and publishing policy documents and status updates required for key manager replication. This multi-node architecture aims to reduce complexity and, ultimately, the risk of computational errors at the execution layer.\n\nFurther, Tendermint Core consumes consensus logic via the Application Blockchain Interface (ABCI), the interface between Tendermint and a single application. Since the Oasis Network has multiple services that need to be provided by the Consensus Layer, it uses an ABCI application multiplexer which performs some common functions and dispatches transactions to the appropriate service-specific nodes. This is how core consensus is able to interact with each of the service nodes.\n\nCore Layer Staking and Consensus Voting Power\n\nThe current voting power mechanism is stake-weighted, which means the consensus voting power is proportional to its stake. In this model, the network will require signatures by validators representing greater than two-thirds of the total stake of the committee to sign a block. Note that in Tendermint, a validator's opportunities to propose a block in the randomly generated block proposer order are also proportional to its voting power.\n\nValidators must stake a minimum of 100 tokens to contribute to the network's security. Each registered entity can have at most one node elected to the consensus committee at a time. The chance of being selected for the committee will be proportional to a validator's stake weight (self-stake amount plus delegated stake).\n\nThe network currently targets an inflation rate between 2% and 12%, with validator reward amounts dependent on the length of time staked. To be eligible for staking rewards in a given epoch, a node needs to sign at least 75% of blocks in that epoch.\n\nThe network will only slash for double-signing. Double-signing penalties will result in the loss of the minimum stake amount and a frozen node. Freezing the node is a precaution to prevent the node from being over-penalized. The network will not slash for liveness or uptime. Oasis requires a 14-day unbonding period if validators or delegators move their staked funds. During this time, staked tokens are still at risk of getting slashed for double-signing and do not accrue rewards.\n\nThe ParaTime Layer\n\nThe ParaTime Layer is the smart contract execution layer that consists of multiple, parallel ParaTimes, each representing a computing environment with a shared state. Operating a ParaTime requires the participation of node operators, who contribute nodes to an open or closed compute committee in exchange for rewards. Oasis uses discrepancy detection to verify ParaTime execution. This verifiable computing technique permits the use of smaller committees and requires a smaller replication factor for the same level of security, which, according to Oasis, is more efficient than sharding or parachain models. The two key features include (1) random selection of compute nodes from a population to form a compute committee and (2) only accepting the results if all committee members agree. If there is a discrepancy, a separate protocol called \"discrepancy resolution\" is enabled, serving as another security parameter. In a sense, smart contract execution functions similarly to the Consensus Layer and its use of node operators and a compute committee. ParaTimes can be operated by anyone and can have their own reward system, participation requirements, and structure; meanwhile, node operators can participate in any number of ParaTimes.\n\nSource: Oasis\n\nAs described previously, the separation from consensus allows the network to address scalability through its modular design. The separation also allows ParaTimes to be different from each other. One difference is the ability to run confidential ParaTimes or non-confidential ParaTimes, with the latter being similar to Ethereum and other alternative Layer-1 networks. Furthermore, ParaTimes can evolve independently while maintaining consensus even as security, scalability, or privacy technologies advance. In other words, the network can maintain a public ledger while having an ecosystem of separate ParaTimes that can evolve with technological advancements, allowing it to adapt and serve future use cases. Beyond confidentiality, Paratimes have the flexibility to configure parameters such as the size of the committee's performing execution, which relates to the level of security a user needs to satisfy particular business requirements. Further, ParaTimes can run different VMs such as EVM or Rust-based smart contracts and can be designed to be permissioned or permissionless systems. Ultimately, ParaTime customization and flexibility allow developers to strike the desired balance between security, performance, and privacy.\n\nConfidential ParaTimes\n\nPrivacy-enabled smart contract execution is one of the core value propositions that Oasis is known for. Cipher, an upcoming ParaTime, will support confidential smart contracts. In a confidential ParaTime, nodes are required to use a secure computing technology called a Trusted Execution Environment (TEE). TEEs are analogous to a black box for smart contract execution. With the use of key management (illustrated in the ParaTime Layer diagram above), encrypted data goes into the black box (i.e., Secure Enclave) along with the smart contract, where the data is decrypted, processed by the smart contract, and then encrypted before it is sent out of the black box. This process ensures that data remains confidential and is not disclosed to the node operator or application developer. Other secure compute technology, such as Zero-Knowledge Proofs (ZKPs), can also be used to execute private smart contracts. The interchangeability of secure compute technology is an additional example of modularity and value proposition at the ParaTime Layer.\n\nSource: Oasis\n\nThe ROSE Token\n\nThe ROSE token is the Oasis Network's native token used for transaction fees, staking, and delegation on the Consensus Layer and for smart contract operations that require fees on the ParaTime Layer. The token is also anticipated to be used for network governance, which is currently being modeled to be a hybrid off- and on-chain mechanism whereby changes to the network will be determined democratically by node operators. Voting power is anticipated to be based proportionally on self and delegated stake.\n\nSuppose the network's value proposition of privacy allows for continued traction. In that case, the token will likely accrue value from increased protocol revenue, the expansion of network infrastructure and node operator stake, and demand for governance stake. The token itself has a fixed supply of 10 billion ROSE. Not all tokens were released publicly on mainnet launch. Due to release schedules and locks, only a fraction (1.5 billion ROSE) of the total existing token supply was introduced into circulation at mainnet launch.\n\nAs a percentage of the total existing token supply, the quantity of ROSE tokens reserved for various network functions follows the allocation below.\n\nBackers: Between 2018 and 2020 Oasis raised over $45 million from well-known investment funds that acquired 23% of the total supply cap at network launch.\n\nSource: Oasis\n\nCore Contributors: As compensation to core contributors for contributing to the development of the Oasis Network, 20% of the total supply cap was allocated at network launch.\n\nFoundation Endowment: With the initial 10% allocation of the total supply cap, the endowment to the Oasis Foundation is tasked with developing and maintaining the Oasis Network. A portion of the Foundation tokens not introduced to the circulating supply at launch are staked on the network. Foundation staking rewards go back into the network via validator delegations, network feature development, and ecosystem grants.\n\nCommunity and Ecosystem: Funding programs and services that engage the Oasis Network community, including developer grants and other community incentives by the Oasis Foundation, initially held 18.5% of the total supply cap.\n\nStrategic Partners and Reserve: Funding programs and services provided by key strategic partners in the Oasis Network initially held 5% of the total supply cap.\n\nStaking Rewards: On-chain rewards are set to be paid out to stakers and delegators for contributing to the security of the Oasis Network. Approximately 2.35 billion ROSE (23.5% of the supply cap) will be paid out as staking rewards to stakers and delegators over four years. Rewards will be disbursed by on-chain mining mechanisms, calculated based on how many blocks are produced, how many nodes are participating in staking, and how many tokens are staked.\n\nSource: Oasis\n\nThe tokens not allocated for staking will be disbursed according to the following 10-year release schedule:\n\nSource: Oasis\n\n  \nThe token supply curve above begins at launch, which occurred in 2020. A rapid increase of unlocked tokens began after 12 months and began to level off recently in the 15th month. In 2024, the token supply release will experience a further leveling until hitting its plateau in the 10th year.\n\nCurrent State and Glimpse into the Oasis Network Ecosystem\n\nLike many digital assets, the ROSE token has declined in valuation by ~50% year to date (YTD), along with a decline in trading volume across exchanges. The top three trading pairs by volume are trading on Binance (USDT, BUSD, BTC) currently making up ~45% of all ROSE trading volume.\n\nWhile trading volume has declined, liquidity of the ROSE token is still relatively healthy, with daily trading volume ranging between $100 million to $500 million, equating to ~$125 million in trading volume on average YTD. Though valuation and trading volume metrics have experienced a downward trend, network usage has experienced a noticeable upward trend.\n\nAt the beginning of 2022, the Consensus Layer of the network was averaging below 10,000 transactions per day. By the middle of January, transactions grew to greater than 140,000, representing an approximate 2,600% increase. Current daily transactions of 110,000 are outpacing the YTD average of 100,000, which also indicates an upward trend. As of March 15, 2022, consensus consists of 153,000 active addresses and has processed 7 million transactions in the aggregate. Further, Emerald launched this year and has generated as many as 3.8 million transactions in a single day and is averaging about 650,000 transactions per day.\n\nBeyond market data and network usage, the network infrastructure has grown from 100 active validators to 110 and has witnessed evolving decentralization metrics.\n\nCurrently, seven validators contribute to just under ~33% of the network's total stake. The methodology behind the Nakamoto Coefficient assumes 33% is the threshold of total stake needed to compromise a network. The higher the coefficient, the more secure a network is deemed to be as it would require a greater number of validators to collude against the network. Given this methodology, the Nakamoto Coefficient of Oasis is similar to other Layer-1 networks, even though most others launched before Oasis, allowing for more time to decentralize their networks. Only time and adoption will determine the extent Oasis Network grows validator sets and a more diversified distribution of stake.\n\nEcosystem Overview\n\nThere may be a reason why the Oasis Network's token symbol is ROSE.\n\nSource: Oasis\n\nAn oasis is a fertile place in an arid environment. The water it provides turns into a thriving ecosystem of plants and animals. In the same way, the Oasis Network provides the resources for applications to build DeFi services and new use cases. Evaluating Oasis Network's current state is a starting point for assessing the ecosystem. Given recent developments and anticipated value propositions to come, following along to see whether it succeeds at thriving will be top of mind as we look ahead into 2022.\n\nA key driver of recent growth was the result of launching the Emerald ParaTime. Emerald is the EVM-compatible system essential for Solidity-based smart contract execution. Having EVM compatibility and Solidity support means that any token developed for Ethereum can be migrated through existing bridge infrastructures like Wormhole, cBridge, and Multichain, which also went live earlier this year. Emerald also allows the ERC-20 token standard to run natively on the Oasis Network. Ultimately, the launch of Emerald brought a flurry of DeFi activity to the network, which is reflected in the increase of daily transactions at the beginning of 2022.\n\nDeFi on the Oasis Network\n\nSource: Oasis\n\nAlong with Emerald, the network launched DeFi infrastructure including the Oasis Wallet for the ROSE token, and it also integrated with bridges like Multichain. This sparked the network's first DeFi application, YuzuSwap (YUZU). YuzuSwap is the network\u2019s first community-developed decentralized exchange (DEX) that offers users low-cost trading services. The DEX allocates 20% of all transaction fees to the YUZU DAO where holders of the YUZU token can use those funds to incentivize further protocol growth. Within a month of launch, YuzuSwap exceeded $100 million in TVL and $1 billion in trading volume.\n\nAnother major contributor to recent growth is ValleySwap (VS), a DEX that launched as recently as February 24, 2022. The launch of ValleySwap clearly generated a renewed uptrend in network activity at the end of February as daily transactions spiked at that time. As of March 15, YuzuSwap and ValleySwap are producing ~$1\u20133 million in daily trading volume and have accrued $37 million and $125 million in TVL, respectively.\n\nThe third-largest\u00a0DeFi application on Oasis is Fountain Protocol (FTP), the network\u2019s first lending protocol. It launched with 200,000 FTP in incentives and generated over $7 million in TVL in its first day. Using Fountain, users can experience one-stop management of DeFi assets with high capital efficiency and take advantage of the low-cost Oasis Network. As of March 15, Fountain Protocol is the third-largest DeFi application on the Oasis Network after growing to $17 million in TVL.\n\nWith the launch of these DeFi protocols, the Oasis Network not only saw an increase in daily transactions but rapid growth in TVL.\n\nIntuitively, the market cap to TVL ratio declined as the market cap declined by 50%, and TVL increased by 190%. This fundamental ratio represents how a network is valued relative to value locked. If the ratio is a large number, the network value is viewed as being overvalued. In other words, a network with an MCap/TVL below 1 represents a network value that is less than the capital locked in the entire network. Given that the network was carrying a nearly $1 billion market valuation before the launch of DeFi, it makes sense to see such a drastic decline in the ratio after the resulting growth of TVL.\n\nThe Ecosystem Beyond Emerald\n\nOasis Network is launching two additional ParaTimes that go beyond Emerald. The Parcel ParaTime and the Cipher ParaTime. Parcel is the system that stores, governs, and computes confidential data. By integrating Parcel SDK into their applications, developers can incorporate privacy-preserving data storage, governance, and computation. This ultimately serves as the Tokenized Data engine, which can convert any data file into an NFT.\n\nWith Parcel, the Oasis Network intends to foster a responsible data society using Tokenized Data. Data providers on the Oasis Network will be able to put their Tokenized Data to use by earning rewards from applications that analyze or control how their sensitive information is used on different services. This concept differs from the data ownership we are familiar with today in that data is not monetized or controlled by those who generate it.\n\nSource: Oasis\n\nCurrently, Parcel is a permissioned ParaTime for use by enterprise partners such as Binance, Genetica, and BMW. Binance is one such partner that has engaged with Oasis to combat bad actors across various exchanges. With theft and attacks as prevalent events in crypto, exchanges need a platform to identify and ban bad actors. Oasis and Binance created the CryptoSafe Platform to enable exchanges to share threat intelligence data. Using the network's confidential compute feature, exchange data can be kept confidential even when compared across exchanges. While Parcel is currently a permissioned network, it is anticipated that it will become permissionless by the end of 2022, bringing Tokenized Data into public reality.\n\nFurther, the third piece of the puzzle is the Cipher ParaTime. Cipher is the confidential smart contract system set to launch at the end of Q2 2022. Cipher is a core value proposition of Oasis that will support WebAssembly smart contracts that make confidential compute possible.\n\nWhen the additional ParaTimes launch, they have the potential to open the network to an ecosystem aimed at privacy-first DeFi, including privacy-preserving decentralized exchanges. To that end, they are designed to make it easier for DEXs to prevent front-running transactions, for NFT users to protect their assets privately, and for them to hypothetically unlock more value from traditional credit and lending markets seeking confidentiality. An example of how DeFi applications can unlock the value of Parcel and Cipher is depicted below.\n\nSource: Oasis\n\nIn this example, users will be able to utilize Cipher and a Trusted Execution Environment (TEE) to protect their private data while monetizing and disclosing private data to various DeFi services through the power of Parcel.\u00a0 For example, a user's risk profile and reputation could be used such that lending services can manage risk and gauge appropriate collateralization requirements. With this knowledge, lending services like Aave could offer under-collateralized lending based on credit-worthy reputations. It will be interesting to track their adoption and usage as the market opportunity for these ParaTimes is substantial. Additional use of these ParaTimes may also generate or supersede the network activity as their Emerald counterpart did in early January.\n\nCompetitive Landscape\n\nCompared to the top five protocols by TVL, Oasis metrics may not be as large but represent the market opportunity the network has when compared to other Layer-1 platforms. There are a few other key items to point out. First, Oasis launched its Consensus Layer later than most of the top L1s in existence today. It also didn't launch its EVM ParaTime until January of this year. Lastly, none of them have confidential compute technology at the center of their ecosystems. Nonetheless, when we evaluate each network over the same period, Oasis experienced greater growth in TVL than each of the top chains. As of March 15, 2022, Ethereum experienced a 23% decline in TVL while Oasis experienced a 192% increase. Although this very well could be the result of the high growth that is usually experienced by any early-stage endeavor, the traction may suggest there is a driver for using and building on the Oasis Network technology.\n\nThe key to Oasis closing the gap on its multibillion dollar counterparts may rely on the privacy value proposition on the way. If adoption becomes apparent and the gap closes by even a small percentage, Oasis is poised to capture market position as a privacy-enabled, smart contract platform.\n\nThe Road Ahead, Potential Challenges, and Growth Strategy\n\nLike many networks in this highly competitive space, positioning in the market may come with some challenges. The growth of the network infrastructure for additional ParaTimes needs to continue for a successful launch. As with the launch of any network, some potential risks and setbacks could occur due to a lack of infrastructure and decentralization. Given the recently generated network activity from the launch of DeFi, Oasis needs to find strategies to successfully launch additional ParaTimes, maintain growth, and pursue opportunities to close the gap with more mature networks. With that in mind, Oasis does appear to have a strategy to mitigate these challenges. In addition to the anticipated launch of Cipher and Parcel, the Oasis Foundation has engaged with a group of backers that include Binance Labs, Pantera, Dragonfly Capital, and others to pool together more than $200 million in funding for developers and projects looking to build on the Oasis Network. Moving forward, it will be imperative to evaluate the continued growth of Emerald and the launch of Cipher and Parcel in tandem with the capital efficiency of the ecosystem fund.\n\nIn addition to the ecosystem fund, the Oasis Foundation has been working with development teams through Grant and DevAccelerator programs to build applications and integrations on top of the Oasis Network. As a result of these programs, there are over a dozen recipients actively building.\n\nFinally, the Oasis Network has implemented a strategy to build community by way of an Ambassador Program and University Program. Oasis seeks to build a global body of ambassadors to run meetups, answer developer questions, and stress test the Oasis Network. The University Program stretches across five continents, with over 25 university departments and blockchain clubs participating. University Program members run nodes and build apps that include Blockchain at Berkeley, Tsinghua University's Student Association of Digital Finance, and Cambridge University's Blockchain Society.\n\nCollectively, Oasis has organized an ecosystem fund, grant, accelerator program, and community programs to mitigate network risk by expanding network infrastructure and driving network activity for the foreseeable future.\n\nClosing Summary\n\nThe Layer-1 smart contract platform race for adoption and market share is likely far from over as Ethereum continues its architectural redesign and incorporates scaling solutions. New use cases continue to demand alternative solutions, and one of those solutions may very well address the desire for confidential computation technology on a purpose-built, modular execution layer. With its unique architecture and deployment of confidential computing technology, the Oasis Network seeks to meet such a demand. Oasis stands well-positioned to close the gap in the Layer-1 race as the network moves forward with expanding applications on Emerald and launching Cipher and Parcel.\n\nThough technical challenges may present themselves along the way, Oasis is positioned with a growth strategy that includes an ecosystem fund, incentive programs, and community initiatives organized to mitigate such challenges and drive growth. Although many Layer-1s experienced exponential growth in 2021, Oasis was not quite in the race as major developments and launches had yet to occur. To that end, this year is a pivotal year for the Oasis Network, as the network unleashes its value proposition to the decentralized world.\n\nThis report was commissioned by Oasis, a member of Protocol Services. All content was produced independently by the author(s) and does not necessarily reflect the opinions of Messari, Inc. or the organization that requested the report. Paid membership in the Hub does not influence editorial decision or content. Author(s) may hold cryptocurrencies named in this report and each author is subject to Messari\u2019s Code of Conduct and Insider Trading Policy. Additionally, employees are required to disclose their holdings, which is updated monthly and published <a href=\"https://www.google.com/url?q=https://messari.io/article/messari-employee-holdings-policy-and-disclosures&source=gmail-imap&ust=1647457925000000&usg=AOvVaw0jwd9uUO4e2D2TzMmDVmb\">here.</a> Crypto projects can commission independent research through Messari Protocol Services. For more details or to join the program, contact hub@messari.io. This report is meant for informational purposes only. It is not meant to serve as investment advice. You should conduct your own research, and consult an independent financial, tax, or legal advisor before making any investment decisions. Past performance of any asset is not indicative of future results. Please see our terms of use for more information._\n\n####", "references": [{"name": "James Trautman", "url": ""}], "published_at": "2022-03-29T13:30:00Z", "author": {"name": "James Trautman"}, "tags": ["Layer-1"], "url": "https://messari.io/article/oasis-network-growing-a-responsible-data-economy-with-privacy"}, {"id": "602dc58f-5e9e-4b52-9e78-dbaab4bde647", "title": "Akash: A Decentralized Approach to Cloud Computing", "content": "Key Takeaways\n\nOutsourcing data storage and compute power to cloud computing providers offers many benefits; however, nearly one-third of server capacity goes unused and a majority of the market share is consolidated among three companies: Amazon, Google, and Microsoft.\nAkash addresses the lack of efficiency and centralization in the cloud computing market with a decentralized marketplace that connects entities seeking cloud services to providers eager to rent out their excess compute resources.\n\n  \"Cloud computing is a great euphemism for centralization of computer services under one server.\" \u2013 Evgeny Morozov\n\nAlthough the old guard of cloud computing uses more than one server, it can still exercise totalitarian power over its data centers, which are full of many servers. With cloud providers like Amazon Web Services (AWS), Google Cloud, and Microsoft Azure accounting for over 60% of the cloud computing market, most of the internet\u2019s data lives on centralized networks at the behest of only three owners.\n\nAkash Network gives consumers an alternative to centralized cloud providers in its Akash Deployment Marketplace that allows users to set a price they are willing to pay to deploy their software while providers with extra compute power bid to host the user\u2019s application. This marketplace for underutilized computing resources functions very similarly to Airbnb, allowing providers to rent out unused capacity.\n\nOn the Importance of Cloud Computing\n\nNo one is shielded from the omnipresent cloud. Whether it's your phone, car, streaming service, or social media accounts, you utilize cloud technology every day. In its simplest form, cloud computing allows you to access services on the internet instead of on your machine.\n\nIn the archaic days of DVD players, the only legal way to watch Disney movies was by physically purchasing the DVD and inserting it into the player connected to the television. Watching many movies required purchasing a collection of these discs. The cloud changed the mechanics of this physical interaction while keeping the same product, films. By storing the archived film data and running backend processes of the Disney Plus streaming service on remote servers, Disney eliminated the requirement for users to have product-specific hardware (DVD players) so it could deliver the same product through the internet.\n\nDisney doesn\u2019t just use the cloud to host customer-facing applications like its streaming service. For the operational side of its business, Disney and many other companies use cloud technology for data protection, data analytics, storage backup, server virtualization (virtual machines), and software development. But companies like Disney don\u2019t need to own the server infrastructure that facilitates all of these necessary operations. Instead, most companies outsource server management to cloud service providers.\n\nBefore the prevalence of Amazon Web Services, Google Cloud, and Microsoft Azure, companies had their own onsite data centers. From hiring IT teams that manage hardware updates and maintenance to purchasing large plots of real estate and paying colossal energy bills, costs related to IT infrastructure would be recorded as capital expenditures. However, paying for cloud computing where the cloud provider absorbs all of the costs associated with IT infrastructure is considered an operational expense, which is tax-advantaged. Although deploying applications to a big three cloud provider comes with monetary benefits and improved operational efficiencies, cloud consumers are locked into vendors and have limited control over their deployments in a centralized cloud environment.\n\nAs more enterprises understand the higher levels of scalability, flexibility, and cost-savings they can achieve by outsourcing IT infrastructure to cloud service providers, Gartner predicts that in 2022 end-users will spend $482 billion on cloud services. This is up 54% from the $313 billion spent in 2020. The pandemic\u2019s push for remote-hybrid work is only helping to accelerate the growth of the cloud computing industry. According to Flexera, 92% of U.S. companies already utilize cloud technology, with 90% claiming usage is higher than initially planned due to the pandemic. This is in stark contrast to Europe, where only 42% of enterprises were on the cloud in 2021, up from 19% in 2016.\n\nDespite the rapid growth and prevalence of cloud computing, 30% of server capacity sits idle in many data centers. As the market for cloud computing continues to grow globally, a convergence will emerge among providers seeking to rectify supply-side inefficiencies and enterprises looking for the flexibility to scale their business, outsource IT infrastructure, and avoid the complications caused by centralized entities.\n\nThe Akash Marketplace\n\nAkash is an open-source platform with a distributed peer-to-peer cloud marketplace that connects users seeking cloud services to infrastructure providers with excess computing resources. Its platform is used for hosting and managing deployments and contains cloud management services that leverage Kubernetes to run workloads.\n\nThese users, called tenants, are typically developers seeking to deploy Docker containers to cloud providers that meet specific criteria. A Docker container essentially contains packaged code, its dependencies, and ensures the corresponding application runs the same on any computing environment. For example, even if the configurations of an application differ when it is developed on a laptop, tested in a sandbox, and sent to the cloud to run, containers can support all three environments without requiring changes to the code.\n\nThe Akash marketplace functions through a reverse auction model, giving users the ability to name a price and describe the resources they want for deployed containers. When a cloud provider, which can range from an individual to a data center, underutilizes computing resources, it rents those resources out by bidding to host deployments, in the same way Airbnb hosts can rent out their extra space. Deploying containers on Akash costs roughly 10 times less than any of the big three cloud service providers (Amazon Web Services, Google Cloud, and Microsoft Azure).\n\nAll records of requests, bids, leases, and settlement payments are stored on-chain using the Akash Token (AKT).\n\nLeadership\n\nGreg Osuri, co-founder and CEO: With a cloud architecture and entrepreneurial background that dates back to 2008, Osuri founded Akash as a decentralized alternative to the traditional cloud computing industry. Before Akash, Osuri founded four other companies and worked at distinguished firms, including Miracle Software Systems as a technical architect, IBM as a critical infrastructure consultant, and Kaiser Permanente as a cloud infrastructure consultant. Osuri\u2019s notable founding projects include AngelHack, one of the most diverse developer ecosystems in the world with over 175,000 developers in 50 cities, and Overclock Labs, Akash\u2019s core contributor focused on making a decentralized and open internet.\n\nAdam Bozanich, co-founder and CTO: Bozanich is a veteran in the software engineering space and has held senior-level roles since 2006. With experience across software development domains, Bozanich worked in QA automation at Symantec, security engineering at Mu Dynamics, and server engineering at Topspin Media. He also co-founded two other companies before Akash: Sprouts Tech and Overclock Labs with Osuri.\n\nWho Runs the Network, Overclock or Akash?\n\nOverclock Labs essentially bootstrapped the Akash Network under the direction of Osuri and Bozanich. Since then, Akash has become a decentralized protocol. Although Overlock is still involved in Akash\u2019s development, it does not control the majority of the 100 validators on the network and, hence, cannot manipulate AKT transactions. Despite its lack of control, Overclock is still Akash\u2019s principal contributor to its open-source codebase, though many contributors come from outside of Overclock.\n\nSince 2020, Akash Network\u2019s GitHub has seen a rise in the commits of contributors not affiliated with Overlock Labs. A commit is an addition or change to the code of any length. Because commits vary in complexity and utility, they can be used as an indicator for developer activity within a given project. Although Overclock continues to account for the majority of Akash\u2019s development, Akash\u2019s own developer community is growing and contributing to the development of the project at an increasing rate.\n\nThe Akash Network\n\nThe Akash Network built its blockchain on a Cosmos SDK framework utilizing the Tendermint Byzantine-Fault Tolerant (BFT) engine for its Delegated Proof-of-Stake (DPoS) consensus algorithm. To simplify the seven or eight buzzwords used in the previous sentence, at its core, Akash uses the Tendermint engine as the security and networking layer of its blockchain. And it uses the Cosmos SDK to customize various aspects of its blockchain, from governance to staking.\n\nStaking AKT in a DPoS Protocol\n\nBecause Akash uses a DPoS consensus algorithm, staking responsibilities vary between delegators and validators. Validators operate nodes to secure on-chain AKT network transactions. Although anyone can become a validator, only those with the computing resources and technical expertise to run an Akash node will.\n\nThe minimum system requirements that Akash recommends to operate validator nodes include a 4-core CPU, 16GB of RAM (memory), 256GB of SSD (storage), and a Linux Ubuntu OS. Of course, better specifications will equal better performance; regardless, these are relatively modest minimum requirements compared to a blockchain like Solana. On Solana, validators need a 12-core/24-thread CPU, 128GB of RAM at a minimum (256GB RAM suggested), and three separate storage units (recommended) totaling 2 TB (500 GB for accounts, 1 TB for ledger, 500 GB for OS).\n\nThe frequency with which the consensus algorithm chooses validators to approve network transactions \u2014 and hence, receive inflationary rewards \u2014 is in proportion to the amount of AKT the validator stakes. This creates a competitive environment among validators to acquire AKT themselves or from delegators.\n\nDelegators delegate their right to earn validation rewards on AKT to a validator who does the work of running a node. This validator then splits the rewards with the delegator (in proportion to how much they delegated) and takes a commission fee off the top. AKT holders can delegate through the Keplr desktop wallet.\n\nAKT Tokeneconomics & Utility\n\nAt genesis, 100 million AKT were distributed to the allocations found in the graphic above, while roughly 289 million AKT were scheduled to be released as inflationary emissions to stakers initially set to a 100% APR meant to halve every two years. Governance voting changed halving to roughly every 3.7 months. According to Akash founder Greg Osuri, the protocol has plans to reward cloud providers with emissions, though the functionality will be implemented at a later date.\n\nThe vesting schedules are described below based on the initial allocations of the 100 million AKT at genesis (September 2020):\n\nInvestors (34.5% or 34.5 million AKT): roughly 17.3 million AKT released after a one-year lock-up, following a graded vesting schedule unlocking roughly 8.6 million AKT after every six months\nTeam & Advisors (27% or 27 million AKT): 11 million AKT released after a one-year lock-up, following a graded vesting schedule unlocking six million AKT after every six months\nDecentralized Cloud Foundation (19.7% or 19.7 million AKT): one million AKT unlocked at TGE following a graded vesting schedule unlocking roughly 8.9 million AKT after the first month, then roughly 4.1 million AKT after the next six months, then roughly 2.1 million AKT after the following 11 months and after two more six-month periods\nEcosystem (8% or 8 million AKT): 2 million AKT released after a one-month lock-up, following a graded vesting schedule unlocking 1.5 million AKT after the first six months, then after the following 11 months, and then after two more six-month periods\nTestnets (5% or 5 million AKT): 800,000 AKT released after a one-month lock-up, following a graded vesting schedule unlocking 1.05 million AKT after the first six months, then after the following 11 months, and then after two more six-month periods\nVendors & Marketing (4% or 4 million AKT): 800,000 AKT released after a one-month lock-up, following a graded vesting schedule unlocking 800,000 AKT after the first six months, then after the following 11 months, and then after two more six-month periods\nPublic Sale (1.8% or 1.8 million AKT): No vesting schedule\n\nAKT is a utility token with multiple uses in the protocol encompassing security, rewards, network governance, and transactions.\n\nNode operators that validate transactions on the mainnet and receive rewards must have a total stake of AKT that positions them as a top 100 holder among peers. This total stake comes from the amount the validator allocates themself combined with the amount delegated to them. Validators on Akash are not required to stake a minimum amount of their own AKT holdings. Accounting for more AKT increases the odds a node operator will get chosen to validate transactions, thereby increasing the frequency of their rewards. To dissuade malicious/lazy validators, those who do not adhere to the consensus guidelines risk getting a portion of their stake slashed.\n\nNot yet implemented but mentioned in the whitepaper, Akash plans to charge a \u201ctake fee\u201d for every successful lease. It would then send the fee to the Take Income Pool to be distributed to holders. The take fee is planned to be 10% for AKT transactions and 20% for when other cryptocurrencies are used. Akash also plans to reward holders for the time lock-up of their AKT holdings. Holders who stake for longer periods of time will be eligible for larger rewards.\n\nOnly AKT holders can participate in governance. This includes submitting proposals and voting on them. The cost of submitting a proposal is a non-refundable deposit of 1,000 AKT. For passed proposals that require binary updates(code changes), validators must update the codebase to avoid penalties and continue validating the network.\n\nAKT is the ecosystem\u2019s reserve currency, used for gas fees and as the default medium of exchange in transactions between providers and tenants. The Akash whitepaper describes a settlement option to lock in an exchange rate between AKT and a settlement currency that is meant to counter AKT price volatility in marketplace transactions. This settlement option has yet to be implemented.\n\nAkash\u2019s Continued Development\n\nAkash learned not to develop too far into the future after postponing the development and release of supermini, the home-based miniature supercomputer that would have seamlessly integrated with the Akash Network allowing people to use it for heavy workloads or to rent it out.\n\nWith 33 cloud providers supporting 525 active leases at about a 90% discount to traditional cloud computing market prices (due to supply being much higher than demand), Akash is working on ways to unlock market expansion. It plans to improve both its blockchain and cloud marketplace. Developing on both fronts will make Akash\u2019s products more palatable to traditional cloud computing consumers and open the protocol up to wider crypto adoption.\n\nThe release of Akash\u2019s Testnet 3 on March 7, 2022, shows that the team is focused on developing new features for the mainnet including:\n\nPersistent storage: Workloads containing large data sets such as blockchain nodes will be able to persist data between restarts. If deployment drops or re-initializes, data will not be lost.\nFractional uAKT: Removes the implicit minimum cost of deployment (one uAKT per block). Fractional uAKT will keep prices more consistent and resource consumption more accurate to the cost.\nAuthZ: Users can authorize a wallet to spend a set number of tokens by another source wallet exclusively on deployments. This reduces security concerns when big teams work together on deployments without using large shared wallets. It allows new community members to spin up deployments without access to a faucet.\nInflationary Curve: An automatic curve mechanism that autocorrects when the inflation differs from the plan outlined in the whitepaper. This removes the need for human intervention where governance proposals would need to be quickly submitted to implement a fix.\n\nThe full list of developments Akash is planning for 2022 can be found on its roadmap. According to Akash founder Greg Osuri, most of the fourth-quarter deliverables from 2021 have been developed and are still in the process of being implemented into production.\n\nAkash\u2019s target markets, from Web3 to artificial intelligence and machine learning (AI/ML), continue to grow in parallel. As the Web3 crowd seeks decentralized computing infrastructure and the heavy-duty compute crowd seeks low-cost flexible solutions to deploy software, Akash will have many opportunities to meet the demands of the thriving cloud compute user base.\n\nDecentralized Cloud Competition\n\nAkash is not the only blockchain project disrupting the nearly half-trillion-dollar cloud computing market. Other decentralized competitors include Dfinity (Internet Computer), Ankr, and Cudos. Although Ankr launched with a similar model to Akash, today, Internet Computer and Ankr both approach cloud computing from different perspectives. Meanwhile, Cudos nearly replicates Akash.\n\nDfinity / Internet Computer\n\nWhile Internet Computer is mostly considered a smart contract platform, it seeks to decentralize everything in its protocol, from the consensus algorithm to the servers the validation nodes connect to when approving network transactions that get broadcasted through the internet.\n\nIt\u2019s not that unique to claim decentralization of the consensus algorithm. Nearly every project claims it, but few actually adhere to it (looking at Solana \u2014 validators can\u2019t plan a network restart on a decentralized system). However, Internet Computer also claims to decentralize the servers its validator nodes utilize to perform consensus. This is in stark contrast to Ethereum, where roughly 25% of the nodes were being operated on centralized AWS infrastructure in 2019.\n\nInternet Computer is not a direct competitor to Akash\u2019s marketplace for underutilized computing resources. Instead, it created a system where independent node operators pay data centers to host their nodes while cloud providers get compensated for contributing computing capacity that facilitates network activity. By pairing computing resources provided by independently operated data centers around the world with its node operators, Internet Computer has attempted to make a truly decentralized protocol running on a decentralized network of data centers as opposed to AWS-owned servers. Despite similarly making use of excess computing power, Internet Computer does not generate market activity for cloud computing like Akash. It may take a share of potential cloud providers but does not seriously threaten Akash\u2019s marketplace.\n\nAnkr\n\nThe Ankr project launched with the intention to use idle computing resources in data centers to build an open-source cloud that it was going to call the \u201cdistributed cloud computing network.\u201d This would have made Ankr a near replica and direct competitor to Akash. However, instead of letting users run any application on Ankr\u2019s proposed cloud service, it pivoted to specifically providing access to Web3 infrastructure via RPCs (Remote Procedure Calls) that are used for making requests of server processes.\n\nExclusively focusing on Web3, node providers join the Ankr network to offer cloud services that connect those building decentralized apps, protocols, and smart contracts to various blockchains through API endpoints. Ankr uses its global node delivery system and developer toolkit to service over 50 PoS blockchains. Similar to the Internet Computer, the nodes in Ankr\u2019s ecosystem that support its RPC layer may only threaten the number of providers Akash is able to connect to. Again, this does not seriously threaten Akash\u2019s marketplace.\n\nCudos\n\nCudos is another item in the product line offered by the Cudo Network. With Cudo Network\u2019s Cudo Miner product (different from Cudos), any user wishing to mine must download the Cudo Miner application, select a token to mine, and the application will mine the selected token while the machine sits idle. In the same spirit of utilizing idle compute power, Cudos will offer a very similar product to Akash with a marketplace that would connect cloud providers with underutilized resources to builders wishing to deploy WASM containers and virtual machines.\n\nAs of writing, Cudos is building its mainnet using the Cosmos SDK, while its testnet is accessible from the Big Dipper block explorer. Despite connecting idle compute power with builders, Cudos has no plans to operate its marketplace with a reverse auction or make its source code open-source like Akash. With yet to launch its mainnet, Cudos is far behind Akash in capturing market share from both the supply-side and demand-side of the cloud market.\n\nVMs\u2026 Maybe Later\n\nVirtual machines (VMs) are an extension of the old guard, the way virtualization solutions used to be implemented, and Akash does not have any explicit plans of supporting them. In a conversation with Akash founder Greg Osuri, he mentioned that compute providers have no restrictions on providing VM support \u2014 and that one even expressed interest \u2014 but that at this stage in Akash\u2019s development, it wouldn\u2019t make much sense. As a growing protocol, Akash is focused on supporting the technology with an expanding user base, not the one that enterprises use as an excuse to avoid change.\n\nAlthough some industry doubts remain on containers\u2019 ability to handle heavy-duty applications like artificial intelligence and machine learning in a similar manner to VMs, studies have proven negligible differences, if not better performance from containers. Akash recognizes the accelerating cloud compute demand for AI/ML and is preparing to handle the potential growth outside of its typical Web3 tenants.\n\nA Compliment, not a Killer\n\nAkash is not meant to replace the centralized cloud computing industry, it will simply complement it. If the conspirators are right, Ethereum might actually get killed by Solana, Polkadot, Cosmos, NEAR, or Algorand (not really, but a long-time Algonaut can dream). Cloud Computing and Akash\u2019s fit in the industry is different. Similar to how Airbnb is not destroying hotels, Akash is not destroying centralized data providers. Both Airbnb and Akash simply allow individuals to rent out unused capacity.\n\nAkash may be able to entice cloud customers by offering prices at a fraction of the cost of the big three providers, as well as providing the flexibility of no vendor lock-ins and control over the resources used to host deployments. As traditional enterprises build out crypto divisions and become more literate in Web3 technologies, Akash will be at the forefront of the decentralized cloud computing space with a functioning mainnet and a business model that alleviates supply-side inefficiencies.  \n\n\u2014\n\n**This report was commissioned by Akash, a member of Protocol Services. All content was produced independently by the author(s) and does not necessarily reflect the opinions of Messari, Inc. or the organization that requested the report. Paid membership in the Hub does not influence editorial decision or content. Author(s) may hold cryptocurrencies named in this report and each author is subject to Messari\u2019s Code of Conduct and Insider Trading Policy. Additionally, employees are required to disclose their holdings, which is updated monthly and published <a href=\"https://www.google.com/url?q=https://messari.io/article/messari-employee-holdings-policy-and-disclosures&source=gmail-imap&ust=1647457925000000&usg=AOvVaw0jwd9uUO4e2D2TzMmDVmb\">here.</a> Crypto projects can commission independent research through Messari Protocol Services. For more details or to join the program, contact hub@messari.io. This report is meant for informational purposes only. It is not meant to serve as investment advice. You should conduct your own research, and consult an independent financial, tax, or legal advisor before making any investment decisions. Past performance of any asset is not indicative of future results. Please see our terms of use for more information._", "references": [{"name": "Micah Casella", "url": ""}], "published_at": "2022-03-29T13:30:00Z", "author": {"name": "Micah Casella"}, "tags": ["Web-3"], "url": "https://messari.io/article/akash-a-decentralized-approach-to-cloud-computing"}, {"id": "bf337ae1-5b19-4c13-bcdc-525b5c2eaa30", "title": "Polkadot Ecosystem Overview", "content": "Polkadot Ecosystem Overview\n\n\u201cThe parachain model was created with the belief that the future of Web3 will involve many different types of blockchains working together. Just as the current version of the internet caters to different needs, blockchains need to be able to provide a variety of services. Parachains solve this.\u201d - Polkadot founder Gavin Wood\n\n  \nKey Takeaways\n\nPolkadot\u2019s first 11 parachains are live.\nThe first 11 parachains bonded 126 million DOT (11% of the total supply; worth $2.1 billion) for the two year lease periods.\nEach parachain brings unique functionality and use-cases to the ecosystem.\nThe next major technical task is the buildout of the Cross-Consensus Message Format (XCM).\n\nIntroduction - Parachains Are Live\n\nOn Dec. 17, 2021, five years after conception, Polkadot successfully completed its multi-stage launch with the launches of the inaugural parachains. Now that parachains are live, end users are finally transacting on Polkadot.\n\nWhat\u2019s a parachain? A parachain is an application-specific, highly customized Layer-1 developed with Polkadot\u2019s blockchain development framework Substrate. It has its own economy, token, governance, and users like legacy Layer-1s. However, unlike legacy Layer-1s, a parachain is not siloed. Instead, it is connected to the Relay Chain, Polkadot\u2019s other major technical component.\n\nWhat\u2019s the Relay Chain? The Relay Chain is the nucleus of Polkadot. It is the Layer-0 base chain housing all validators and responsible for securing, governing, and connecting the parachains. In addition to the Relay Chain governance, the parachains also have sovereign governance, which is further explained in the analogy below. The Relay Chain can support an estimated 100 to 250 parachains. The parachain cap is primarily driven by the costs associated with scaling Polkadot\u2019s Cross-Chain Message Passing (XCMP) and abiding to the optimal 10:1 validator-to-parachain ratio to maintain decentralization and performance quality.\n\nAnalogy: The United States. The Relay Chain is the federal government, and parachains are individual states. The federal government secures, governs, and unites the individual states. At the same time, states secure, govern, and coordinate themselves. Should a dispute ever arise, the federal government outranks state governments.\n\nWhat does the Polkadot token (DOT) do? Polkadot\u2019s native token DOT is a utility and governance token used for participating in governance, transaction fees, security via staking, and bonding for parachain slots. As of March 2022, DOT is the <a href=\"https://messari.io/article/messari-fund-analysis-q4-21-examining-liquid-portfolios-of-crypto-funds\">most commonly held asset</a> among crypto funds.\n\n For a deeper dive into Polkadot, please see our previous reports <a href=\"https://messari.io/article/polkadot-primer?referrer=asset:polkadot\">Polkadot Primer One</a> and <a href=\"https://messari.io/article/the-polkadot-kusama-ecosystem?referrer=asset:polkadot\">Polkadot Primer Two</a> \n\nIn addition to the VC funding, Polkadot\u2019s unique architecture paired with the flexibility of Substrate has attracted the second largest developer community. Now that parachains are live and the massive VC funding is secured, the fruits of the developers\u2019 labor are accessible to the masses. In this report we will delve into Polkadot's first 11 parachains.\n\nEcosystem Overview - The First 11 Parachains\n\nAs noted above, the Relay Chain can support an estimated 100 to 250 parachains. For a parachain to gain access to the myriad of benefits offered by the Relay Chain, it must win a candle-style parachain slot auction by bonding the most DOT.\n\n  \nProspective parachains raise DOT, often via their communities, in exchange for their native tokens. At random times in the candle auction, the parachain with the most bonded DOT wins the slot. At the conclusion of the lease period, the lender's bonded DOT is returned (and they keep the parachain token).\n\n  \nAfter 11 auctions, 126 million DOT (11% of the total supply; worth $2.1 billion) has been bonded. The first batch of winners (auctions 1\u20135) were onboarded to Polkadot on Dec. 17, 2021. The second batch of winners (auctions 6\u201311) were onboarded to Polkadot on Mar. 11, 2022. Each of the winners brings unique functionality and use-cases to the Polkadot ecosystem.\n\n  \nNote not all functionality described below is active\n\nAcala\n\nAcala won Polkadot\u2019s first auction with 32,515,980 DOT raised. Acala is a decentralized finance network built on Polkadot, which powers the aUSD stablecoin ecosystem. Acala boasts a suite of financial functionality centered around aUSD:\n\n  \nAcala Dollar (aUSD)\n\nThe Acala Dollar (aUSD) is a stablecoin generated by the Honzon protocol - a Maker DAO (DAI) inspired mechanism. Users mint aUSD by creating an over-collateralized debt position with approved reserve assets like DOT, LDOT, and ACA. The team plans to expand collaterals to BTC, ETH, and native tokens of other parachains. Acala, along with an initial nine Polkadot parachain teams and several supporting venture funds, has launched a $250 million aUSD Ecosystem Fund. As of Mar. 8, 2022, 6.17 million aUSD have been issued.\n\n  \nLiquid Staking (L-Token)\n\nAcala boasts liquid staking functionality via the Homa protocol. Users stake their tokens and receive L-Tokens (e.g. LDOT) which represent the principal staked asset plus the staking yield continuously accruing. L-Tokens are accessible as ERC-20 and Substrate based tokens and can be used across Acala\u2019s DeFi protocols.\n\nAcala Swap\n\nAcala Swap is a constant-product AMM DEX supporting ERC-20 and native Substrate based tokens. Acala Swap is running a liquidity bootstrapping event to celebrate its kick-off. Users can pay gas fees on Acala swap in any token.\n\nAcala Token - ACA\n\nThe <a href=\"https://messari.io/article/acala-polkadot-s-likely-inaugural-tenant?referrer=asset:acala\">Acala token (ACA)</a> is a utility and governance token used for participating in governance, transaction fees, and incentivizing Acala collator nodes.\n\n  \nAdditionally, Acala has a partnership with fintech unicorn Current, a community-run treasury, and Acala EVM+ enabling full-stack composability between EVM and Substrate. As of early March 2022, Acala has $528 million in TVL. You can find the Acala roadmap here.  \n\n  \nMoonbeam\n\nMoonbeam won Polkadot\u2019s second auction with 35,759,931 DOT raised. Moonbeam is an EVM-compatible, cross-chain smart contract platform. Moonbeam allows developers to port their projects with minimal to no code changes, and provides a developer friendly environment for launching new projects:\n\nEthereum-Style Unified Accounts\n\nAny parachain can offer an EVM implementation by enabling the frontier pallet designed by Parity and Moonbeam. However, parachains with an EVM implementation require users to have private keys for both the EVM and Substrate account. Moonbeam offers Unified Accounts - users only need one private key (the EVM style key) to interact with EVM and Substrate. The Unified Account functionality allows users to use their existing accounts on Moonbeam, and use the Metamask wallet.\n\nXC-20 Assets\n\nMoonbeam introduced the XC-20 token class, a new token class offering the native interoperability of Substrate based assets, while allowing users and developers to interact through the familiar ERC-20 interface.\n\nMoonbeam Token - GLMR\n\nThe Moonbeam Token (GLMR) is a utility and governance token used for participating in governance, transaction fees (80% burned and 20% allocated to on-chain treasury), incentivizing Moonbeam collator nodes, and supporting the gas metering of smart contract execution.\n\n  \nAs of early March 2022, Moonbeam has $141 million in TVL with a growing ecosystem. Moonbeam plans on supporting new projects with grants and bounty programs.\n\nAstar Network  \nAstar Network won Polkadot\u2019s third auction with 10,333,552 DOT raised. Astar is a multi-chain smart contract platform supporting Web Assembly (WASM) and EVM. Astar provides multiple solutions for developers to build smart contracts:\n\nCross-Virtual Machine (X-VM)\n\nToday, virtual machines are disconnected and struggle to communicate e.g. the ability to call a Substrate contract within an EVM contract. To unify the various smart contract engines, Astar is developing the Cross-Virtual Machine (X-VM). X-VM allows smart contracts to execute calls and read storage data from different virtual machines and languages.\n\nZK Solutions\n\nAstar has been developing ZK scaling solutions. In the near future, Astar will implement the ZK plonk pallet (the plonk is called universal ZK Snark).\n\n  \ndApp Staking\n\nWhen building applications, developers often face a plethora of fees with no offsetting income. dApp staking is a reward mechanism for developers or administrators of smart contracts. Astar staking rewards are sent to application developers based on a dynamic rewards model. Eventually, Astar will allocate 50% of staking rewards to developers. Astar also plans to introduce functionality allowing developers to fund their project(s) directly from supporters.\n\n  \nAstar Token - ASTR\n\nThe Astar Token (ASTR) is a utility and governance token used for participating in governance, transaction fees, incentivizing Astar collator nodes, dApp staking, and Layer Two application support.\n\n  \nAdditionally, Astar supports Polkadot's largest DEX by TVL ArthSwap, recently raised a $22 million round led by Polychain, and has two Ethereum bridges. As of early March 2022, Astar has $386 million in TVL. Astar plans on connecting with Cosmos and adding a host of additional functionality.\n\nParallel Finance\n\nParallel Finance won Polkadot\u2019s fourth auction with 10,751,519 DOT raised (79% raised through the Parallel Auction Loan Platform). Parallel is a DeFi platform boasting a suite of functionality:\n\nMoney Market\n\nParallel\u2019s decentralized Money Market protocol offers lending, borrowing, and staking functionality. Users who opt to stake can participate in leverage staking. Leverage staking allows users to lend and stake simultaneously, thus earning double yield. How? When a user stakes DOT, they receive a liquid derivative token xDOT. xDOT can be lent back to Parallel to receive a lending fee in addition to the present staking yield. Users can further opt to borrow against xDOT to increase leverage. The Parallel Finance platform algorithmically selects the highest performing nodes to maximize staking yield.\n\n  \nAuction Loan Platform\n\nThe Auction Loan Platform raises DOT for prospective parachains. Contributors are incentivized to lend their DOT through the Auction Loan Platform because they receive extra bonuses from both Parallel and the prospective parachain and stay liquid via a liquid staking derivative cDOT. cDOT can be utilized across Parallel\u2019s DeFi protocols.\n\n  \nParallel Token - PARA\n\nThe Parallel Token (PARA) is a utility and governance token used for participating in governance, transaction fees, incentivizing Parallel collator nodes, and staked in the security module.\n\n  \nAdditionally, Parallel plans on releasing an AMM with stableswap functionality, a multi-chain wallet, and a host of additional functionality. As of early March 2022, Parallels Auction Loan Platform has raised $553 million commanding 22% market share.  \n\nClover Finance\n\nClover Finance won Polkadot\u2019s fifth auction with 9,752,487 DOT raised. Clover is an EVM-compatible cross-chain infrastructure platform providing the tooling for developers to migrate and scale their applications. Clover boasts a suite of products including:\n\n  \nUniversal Cross-Chain\n\nClover has various wallet implementations for interacting with applications across Substrate-based chains on Polkadot and Kusama, EVM chains, and Solana. Users can send, receive, wrap, and unwrap cross-chain assets across different networks without navigating between them (similar to Zapper).\n\n  \nClover Wallet\n\nClover Wallet is a non-custodial, cross-chain wallet helping users manage, track, and interact with assets across Substrate-based chains on Polkadot and Kusama, EVM chains, and Solana. Clover Wallet is available on mobile, extension, and web.\n\nClover Cross-Chain Explorer\n\nClover Cross-Chain Explorer is a cross-chain block explorer offering multi-chain indexing across Substrate-based chains on Polkadot and Kusama, EVM chains, and Solana. Users can search through blocks, transactions, and accounts.\n\n  \nClover Token - CLV\n\nThe Clover Token (CLV) is a utility and governance token used for participating in governance, transaction fees, incentivizing Clover collator nodes, and treasury management.\n\nAdditionally, Clover plans on releasing a cross-chain bridge, cloud-service API, gas-fee redistribution which shares a percentage of transaction fees with developers, a gasless end-user experience, and identity-based fees to offer reputable users reduced pricing.\n\n  \nEfinity\n\nEfinity won Polkadot\u2019s sixth auction with 7,695,377 DOT raised. Efinity is a purpose-built blockchain for NFTs developed by the Enjin team. Efinity is designed to support NFTs from any blockchain:\n\nToken Standard\n\nEfinity is introducing a new standard for interoperable, cross-chain tokens. It will be compatible with Substrate based chains Polkadot and Kusama, ERC-20, ERC-1155, ERC-721, and other chains and their standards. The token standard supports fungible tokens, non-fungible tokens, and grouped NFTs.  \n\nFuel Tanks\n\nFuel Tanks are used purely for transaction fees. Developers deposit EFI into their Fuel Tank(s) to subsidize costs for their users/players.\n\n  \nDiscrete Accounts\n\nDiscrete accounts enable easy onboarding by not requiring new users to have a crypto wallet. On-chain items can be placed in a developer controlled wallet that players can claim at a later time when ready.\n\nNFT.io Marketplace\n\nEfinity and Enjin are developing a new NFT marketplace called NFT.io, slated for closed beta in March. NFT.io is a cross-chain NFT marketplace offering novel price discovery mechanisms via Efinity.  \n\nEFI\n\nThe Efinity token (EFI) is a utility and governance token used for participating in governance, transaction fees, facilitating liquidity, rewarding network participants, funding fuel tanks, and increasing transaction limits on Enjin\u2019s JumpNet EVM chain.  \n\nAdditionally, Efinity will roll-out novel user-friendly features and leverage Enjin's existing infrastructure. Over 100 projects have committed to building applications and games on Efinity and Enjin.\n\nComposable Finance\n\nComposable Finance won Polkadot\u2019s seventh auction with 6,075,487 DOT raised. Composable is a DeFi infrastructure platform designed for cross-chain interoperability. Composable is building a comprehensive technical stack:\n\n  \nCross-Chain Virtual Machine (X-VM)\n\nThe Cross-Chain Virtual Machine (XCVM) is a virtual machine providing an environment for developers to run cross-chain smart contract functions. The XCVM connects Substrate to other networks via its Innovation Availability Layer. It determines the optimal route for instructions using the Routing Layer.\n\n  \nMosaic\n\nMosaic is a cross-chain transfer availability layer integrated with EVM-compatible chains including Ethereum, Arbitrum, Avalanche, Polygon, Fantom, Moonriver, etc. Mosaic uses multiple assurances to ensure transfers are delivered including liquidity forecasting, rebalancing of liquidity vaults, and community-run liquidity bots. Developers can build with Mosaic by using the Mosaic SDK.\n\n  \nMural\n\nMural facilitates the cross-chain transfers of NFTs leveraging Mosaic.\n\n  \nComposable Token - LAYR\n\nThe Composable token (LAYR) is a utility and governance token used for participating in governance, transaction fees, and incentivizing Composable collator nodes.\n\n  \nAdditionally, Composable was highlighted in the yearly Electric Capital developer report for its increase in developers. You can find Composable\u2019s roadmap here.\n\nCentrifuge\n\nCentrifuge won Polkadot\u2019s eighth auction with 5,435,161 DOT raised. Centrifuge is bringing real-world asset financing to DeFi to bring down the cost of capital for small-businesses and provide DeFi investors with a stable source of yield uncorrelated from the crypto markets. Centrifuge leverages a <a href=\"https://messari.io/article/centrifugal-transparency-for-tokenized-assets?referrer=asset:centrifuge\">multi-pronged technical stack</a>:\n\n  \nPeer-to-Peer Network\n\nCentrifuge\u2019s peer-to-peer network provides a secure method to create, exchange, and verify asset data between collaborators and tokenize the assets into NFTs. Asset Originators can selectively share asset details with service providers who can assess the data and contribute information to the minted NFT. The data origin can be verified using cryptographic signatures.\n\nTinlake\n\nTinlake is an application acting as an open market-place for real-world assets. Businesses tokenize their financial asset(s) into NFTs and use the NFTs as collateral in their Tinlake pool. Users have access to all pools and invest DAI in their pool of choice. Each pool contains two tranches with varying levels of risk-reward.\n\n  \nCentrifuge Token - CFG\n\nThe Centrifuge Token (CFG) is a utility and governance token used for participating in governance, transaction fees, incentivizing Centrifuge collator nodes, and rewarding network participants.\n\n  \nAdditionally, Centrifuge leverages existing legal and commercial frameworks to securely finance real world assets. As of early March 2022, Centrifuge has $76 million in TVL.\n\nHydra\n\nHydraDX won Polkadot\u2019s ninth auction with 2,462,543 DOT raised. HydraDX is a cross-chain liquidity protocol reducing liquidity fragmentation by accommodating many crypto assets into a single trading pool.\n\nOmnipool\n\nThe HydraDX Omnipool is a liquidity pool servicing all assets. All trades in the Omnipool are denominated in LERNA (LRNA), meaning LRNA allows assets to be priced against each other. The quantity of LRNA available in the pool fluctuates in relation to the total liquidity - as liquidity is added LRNA is minted, and as liquidity is removed LRNA is burned. Since the Omnipool mints LRNA to match every addition of liquidity, LPs are able to provide liquidity in whichever assets they wish, and accrue trading fees whenever those assets are purchased from the pool.\n\n  \nHydraDX Token - HDX\n\nThe HydraDX Token (HDX) is a utility and governance token used for participating in governance and to stabilize the LRNA value.\n\n  \nInterlay\n\nInterlay won Polkadot\u2019s tenth auction with 2,751,954 DOT raised. Interlay brings Bitcoin to any blockchain.\n\nInterBTC\n\nInterBTC is a fully-collateralized and interoperable BTC pegged derivative. To mint interBTC, users lock their BTC in a vault. The vault can be an existing one or one the BTC owner ops to create. All vaults are over-collateralized with a specific asset. The over-collateralized asset acts as insurance should malicious activity occur within the vault. If malicious activity does occur, the BTC depositors are reimbursed in slashed collateral at a premium rate. The first vaults will be collateralized with DOT.\n\n  \nInterBTC v. Competitors\n\nInterBTC is a decentralized and trustless BTC pegged derivative. How? Anyone can become a vault in InterBTC (decentralized), vaults cannot prevent users from minting InterBTC (censorship resistant), vaults lock collateral in different assets (capital efficient), and if BTC is lost or stolen users are reimbursed in collateral at a beneficial rate (trustless).\n\n  \nInterlay Token - INTR\n\nThe Interlay Token (INTR) is a utility and governance token used for participating in governance, transaction fees, and incentivizing Interlay collator nodes. The team plans to tightly integrate INTR into interBTC to enable premium features, better rates, and higher insurance coverage.\n\n  \nAdditionally, Interlay plans to add new vault collaterals and connect with other blockchains including Ethereum, Cosmos, and Solana. Interlay is aiming to become a decentralized Bitcoin bank enabling vaults to re-use custodied BTC and deposited collateral for structured financial products.\n\nNodle\n\nNodle won Polkadot\u2019s eleventh auction with 2,475,528 DOT raised. Nodle is a decentralized wireless network providing secure, low-cost connectivity and data liquidity to IOT devices. The Nodle Network leverages Bluetooth Low Energy (BLE) via millions of smartphones and routers to allow enterprises and smart cities to connect IOT devices to the Internet at low-cost while maintaining privacy and security.\n\n  \nNodle Cash App\n\nNodle Cash App is a mobile application enabling users to connect to the Nodle Network, known as the Citizens Network. Once the application is downloaded, users must turn on Bluetooth and location services in the phone's settings. The Nodle Cash app will detect sensors and smart devices and connect to them anonymously. For the service provided, the app user receives Nodle Cash, also known as the NODL token.\n\n  \nNodle Token - NODL\n\nThe Nodle Token (NODL), also known as Nodle Cash, is a utility and governance token used for participating in governance, transaction fees, rewarding participants of the Nodle Network, and incentivizing Nodle collator nodes. NODL is distributed every six seconds to participants of the Nodle Network.\n\nAdditionally, the Nodle Network is has 5 million daily active smartphones with 30 million IoT devices moving approximately 100 GB of data across 100+ countries on a daily basis.\n\nConclusion - Only the Beginning\n\nLooking forward, Polkadot has 30 new slot auctions scheduled through February 2023 (bringing the total to 41). Arguably the most important technical task during this time will be the buildout of Polkadot\u2019s Cross-Consensus Message Format (XCM). Today, a light client version, HRMP, is being tested on Kusama. A core tenet of Polkadot\u2019s value proposition is to ensure a successful rollout of XCM to enable fluent cross-parachain communication. Polkadot will continue to build its unique modular architecture and make a significant push for market share in 2022 and beyond.\n\n  \n This report was commissioned by Polkadot, a member of Protocol Services. All content was produced independently by the author(s) and does not necessarily reflect the opinions of Messari, Inc. or the organization that requested the report. Paid membership in the Hub does not influence editorial decision or content. Author(s) may hold cryptocurrencies named in this report and each author is subject to Messari\u2019s Code of Conduct and Insider Trading Policy. Additionally, employees are required to disclose their holdings, which is updated monthly and published <a href=\"https://messari.io/article/messari-employee-holdings-policy-and-disclosures\">here.</a> Crypto projects can commission independent research through Messari Protocol Services. For more details or to join the program, contact hub@messari.io. This report is meant for informational purposes only. It is not meant to serve as investment advice. You should conduct your own research, and consult an independent financial, tax, or legal advisor before making any investment decisions. Past performance of any asset is not indicative of future results. Please see our terms of use for more information._", "references": [{"name": "Nicholas Garcia", "url": ""}], "published_at": "2022-03-28T13:30:00Z", "author": {"name": "Nicholas Garcia"}, "tags": ["Decentralized-Finance", "Decentralized-Exchanges", "Web-3", "Metaverses", "Layer-2", "Layer-1", "Stablecoins", "NFTs", "Lending", "Interoperability"], "url": "https://messari.io/article/polkadot-ecosystem-overview"}, {"id": "ee0716ba-df1f-4e6d-97de-57249e75746b", "title": "Weekly Recap Ending March 24", "content": "Notable Messari Intel Updates\n\n<a href=\"https://messari.io/intel/event/4da2fd78-ad15-4fdc-91c9-b95eeb90ce66\">Terra will be launched on THORChain</a> this week following the upcoming hardfork. The node launcher for terra-daemon has been merged on chaosnet, and node operators should begin syncing their chain daemons now in anticipation for chaosnet\u2019s launch.\nAva Labs has shared details about <a href=\"https://messari.io/intel/event/a6060efe-af6c-4977-8590-6fa4aac69678\">Core</a>; a free, non-custodial wallet explicitly created for applications on Avalanche with native support for Subnets. The first iteration of Core will be a browser extension that is expected to be released at the end of March 2022. A Core mobile application is expected to be released in early Q2 of 2022.\nElectric Coin Co. has announced that they have <a href=\"https://messari.io/intel/event/32b90c8c-28dc-4ba7-9fe9-40c200ed9e36\">delayed the NU5 upgrade</a> until mid to late May. During testing, the ECC core team found a consensus bug that caused the testnet chain to fork. A fix has been implemented and will be included in the upcoming Zcashd release 4.7.0.\nTHORChain halted at block 4,786,559 to perform the scheduled hard fork. More info can be found <a href=\"https://messari.io/intel/event/60837ece-fffe-40a3-a8ca-ba97fa1e5b61\">here</a> on the events that happened during the hard fork.\n\nNotable Messari Governor Updates\n\nThe Cream DAO <a href=\"https://messari.io/governor/proposal/a9fe7d72-9e06-48b0-b0f0-ea46b5978122\">succeeded</a> in passing a proposal that aims to end an ongoing bounty payment of 2,576.25 ETH to whitehat hackers that helped recover funds exploited from Cream platform in August 2021. The remaining ETH from the bounty payment will be used to compensate depositors impacted by losses from the platform in another exploit in October 2021.\nThe Quickswap DAO <a href=\"https://messari.io/governor/proposal/0967b3a3-5194-4565-ac89-12a886de5f3a\">succeeded</a> in passing a proposal supporting a QUICK token split; the winning outcome came in favor of a 1:1000 split.\nThe ApeCoin DAO <a href=\"https://messari.io/governor/proposal/f61c5bf4-b82e-4b52-9e38-3aa781562f6f\">submitted a proposal</a> that aims to establish the ApeCoin DAO's governance process and outlines the DAO\u2019s values and mission. ApeCoin DAO will be governed by ApeCoin tokenholders who are able to both submit and vote on APE Improvement Proposals (AIPs). The submission process will be administered by a special counsel within the Ape Foundation called the \"Board\". The Board will be composed of DAO members as elected on an annual basis. Voting is currently active.\nThe Bancor DAO <a href=\"https://messari.io/governor/proposal/4206d187-e18c-4a4d-96a4-0d4391cc9f15\">submitted</a> a proposal that aims to assess sentiments about decreasing the vBNT pool fee from 1.5% to 1.0%. The proposal follows community members' concerns about the vBNT pool performance after the fee was initially increased from 0.75% to 1.5%.\nThe Sushi DAO <a href=\"https://messari.io/governor/proposal/9e8f7fa3-cc47-4267-92ac-bba0f5877ff5\">submitted</a> a proposal that aims to implement an Omnichain native asset bridge into Sushi, called Stargate, that is built on top of LayerZero and allows for token swaps across chains. Stargate allows for streamlined transfer of funds across chains and implements UX improvements over traditional bridges. For example, Stargate can take some of the users\u2019 native source gas, and drop some native gas to the user on the destination chain eliminating the need for gas faucets. Stargate on Sushi will support 7 networks on launch: Ethereum, Polygon, Avalanche, BSC, Fantom, Arbitrum, and Optimism\n\nSector Returns\n\nThe month-long pattern of weekly trend reversals seems to have been broken. This week marks two consecutive weeks where all sectors covered have finished in green territory. The gaming sector has seen some solid performance over the past two weeks, finishing top second last week and now leading the pack with a 19.51% return. Top assets by market capitalization were next up, gaining 14.28% on the week. The rest of the sectors covered brought in single-digit returns ranging from 8.49% for smart contract platforms to 5.61% for currencies.\n\nTop Assets\n\nAfter some time out of the spotlight, Cardano (ADA) is back. This time leading the group by a large margin and securing a 34.4% gain on the week. Catalysts behind the alternate Layer-1 asset\u2019s recent performance could be related to the token making up the largest percentage within Grayscale\u2019s \u201cSmart Contract Platform ex Ethereum Fund\u201d and Coinbase recently announcing support for ADA staking. All other assets within the category ended the week with positive returns. Solana (SOL) took the second spot, returning 17.2%, followed by Dogecoin (DOGE) with 17.0%, Polkadot (DOT) with 14.5%, and Ethereum (ETH) with 11.8% amongst the double-digit gainers.\n\nDeFi Assets\n\nLoopring has rocketed to the number one position this week within the top ten DeFi assets category after news of its integration with GameStop for their upcoming NFT marketplace. Through this partnership, GameStop will build their NFT marketplace on top of the Loopring L2, a scaling solution that will enable users to mint and trade NFTs at a fraction of the cost of transacting through the Ethereum mainnet, whilst inheriting its security. Other notable performers within the top DeFi assets by market capitalization were Uniswap (UNI) which returned 18.5%, Curve (CRV) with 12.6%, and PancakeSwap (CAKE) with 10.1%.\n\nSmart Contract Platforms\n\nEthereum Classic (ETC) has secured its spot as the best performing asset within the top 100 assets by market capitalization this week. The Ethereum Classic blockchain\u2019s ETC token saw its price increase by 75.5% on the week, driven around speculation that current ETH miners will embrace ETC mining after the upcoming Ethereum merge. Among the other smart contract platform assets with double-digit returns were Cardano (ADA) returning 34.4%, NEAR Protocol (NEAR) with 19.2%, Solana (SOL) with 17.2%, Polkadot (DOT) with 14.5%, and Ethereum with 11.8%.\n\nCurrencies\n\nThe currencies sector had an impressive week, with 7 of its top 10 assets posting double-digit gains. Leading the sector was Dash (DASH) with a 33.9% return. The Bitcoin fork token broke off from the pack early during the week and was able to continue its upwards trend while the rest of the assets in the category flattened out. Bitcoin Cash (BCH) secured the second position with a 25.5% return, and Zcash (ZEC) trailed closely, taking third place with a 23.6% gain.\n\nWeb3\n\nWeb3\u2019s outperformer this week was Audius (AUDIO). The decentralized music streaming protocol\u2019s token had a significant jump in price on the 19th which was able to maintain until the end of the week, allowing it to easily secure the first spot at a 44.6% gain. Next up were Theta (THETA) with a 16.5% return and Livepeer posting a 15.1% gain.\n\nGaming\n\nPLA (PLA) did not seem poised to have a breakout week as it traded well within the pack for most of the time. The same can be said about Axie Infinity (AXS); however, these two tokens saw their price surge substantially within the last two days of the week. PLA led the sector this week as it secured a 59.9% gain, while Axie followed with a 46.0% return. Enjin (ENJ) was the third-best performer, bringing in 20.6%.\n\n", "references": [{"name": "Guillermo Avil\u00e9s", "url": ""}], "published_at": "2022-03-25T14:09:00Z", "author": {"name": "Guillermo Avil\u00e9s"}, "tags": ["Macro"], "url": "https://messari.io/article/weekly-recap-ending-march-24"}, {"id": "167cfff0-6701-413c-96a0-c9765d1e6c91", "title": "Pocket Network: A Decentralized Solution to Access Handling", "content": "Key Takeaways\n\nThe dependence on centralized infrastructure creates single points of failure and degrades the promise of decentralization.\nPocket Network addresses Web3\u2019s access handling side with a censorship-resistant node network, zero downtime and no sunk cost to applications.\nPocket is designed to facilitate a multichain future, integrating with over 40 blockchains and growing rapidly in average daily relay servicing (52x YoY) and the number of service nodes (24x YoY).\nDespite Pocket\u2019s high inflation, the linear rewarding with serviced relay volume resulted in a 30% increase in total POKT supply in three months. Subsequent concerns around stakeholder dilution drove the DAO to tame inflation.\nPocket\u2019s upcoming massive V1 upgrade is a significant step towards a highly scalable network equipped with enterprise-grade service quality.\n\nThe recent Web3 proliferation has been quite a lure for the intellectually agile. Both builders and skeptics gathered around its fire and started participating in the show. With the recent market volatility, the stars guiding investors dimmed their lights on builders. Once perceived as rockstars, builders slowly gave the spotlight to skeptics, as if it was their time to shine. As large as the scope of commentary was, most of the balanced criticisms converged on specific argument patterns, with the incomplete decentralization of blockchain networks taking the lead.\n\nOn Tradeoffs\n\nCritics often describe the networks as being built around an illusion of decentralization. They point out that hash rates have been consolidated into only a few mining pools and that smart contract platforms depend too much on private infrastructure providers, which could become centralized points of failure. Although these criticisms on the incomplete trustlessness problem are intrinsically valid, things tend to get more nuanced on the battlefield. When applications optimize for cost efficiency, they often opt for a centralization trade-off, especially when the costs significantly outweigh the benefits of decentralization. On top of that, centralized infrastructures provide high-quality service, making them a superior choice on multiple fronts.\n\nAs a means to an end, decentralization is potentially not a scalable design choice. To move away from a centralized infrastructure would require distributed solutions with enterprise-grade service qualities. Quality, cost, and decentralization are the three heads of the chimera that Web3 infrastructure providers need to execute in order to have a chance of broad adoption.\n\nPocket: Information Routing in a Blockchain Transaction\n\nEnter Pocket Network, a full-node coordination engine. Pocket strives to become a leading decentralized access solution by simultaneously tackling three fronts: censorship-resistant RPC handling services, zero downtime, and no sunk costs.\n\nThe Pocket Network aims to disrupt a specific step in a regular blockchain transaction. For instance, in an Ethereum transaction, smart contracts are filled with logical, Ethereum Virtual Machine (EVM)-compatible directives. Whenever interacting with these contracts, users first need to submit their request to an Ethereum full node equipped with EVM. This full node can be a local or external node. If the user runs a local full node, they can read the chain data as well as validate the transaction to broadcast to the network without an external connector. However, running a full node is a costly and inefficient activity and is limited by performance issues such as downtimes and high latency. Instead of taking on this operational overhead, applications refer to node services to acquire chain data and handle their transactions.\n\nSource: BlockChannel\n\nAccessing a server, or in this case accessing a blockchain through an external node, requires the user to determine a first interaction point. Who will give the information about the chain state? Who will take the first transaction request in case of a write request? Which node will play the role of a customs and see if the submitted transaction is valid before releasing it to the chain? This first non-local interaction point is determined using RPC, an API that allows the application to send their request to a specified full node via a URL.\n\nEvery interaction, both state-changing transactions and information requests, involves this path. When users do a particular action on their wallet, it triggers a call, resulting in an API request routed to a full node. For example, Metamask chooses Infura as their default RPC endpoint provider. If a user wanted to send funds to another address or to check their own wallet's token balance, Metamask would route their request to the nodes operated by Infura.\n\nThe lack of a well-developed decentralized alternative before Pocket Network made applications heavily rely upon centralized node providers such as Infura and Alchemy. The centralization of these gateways makes the network susceptible to single points of failure with unexpected downtimes and the threat of censorship. A fresh case of censorship occurred with Infura and Metamask accidentally blocking transactions originating from Venezuela.\n\nPocket Network\u2019s decentralized RPC protocol is designed to obviate these kinds of problems with a distributed full-node network that is designed to be highly redundant. Contrary to the centralized incumbents who are bound to operational bottlenecks when expanding, Pocket Network is relieved of the burden of running their own nodes, operating similarly to prominent marketplaces like Uber and Airbnb. As a coordination-providing intermediary network, Pocket can remain chain agnostic, function as an L0 despite being an L1, and rapidly scale the services into new chains. So far, the network has been able to attract 34,000 service nodes (and counting) while expanding to more than 40 networks within a brief amount of time. Thus, Pocket became one of the fastest-growing decentralized infrastructure providers in the space.\n\nHow Pocket Helps Bridge Multiple Blockchain Worlds\n\nFundamentally, the design of the Pocket Network V0 is akin to the mythological tree Yggdrasil, with numerous network integrations reaching to blockchain worlds like branches, fostering them with essential information. Meanwhile, the service is grounded in three components like Yggdrasil\u2019s three roots: application, nodes, and network layer.\n\nIn the Pocket ecosystem, applications are the agents operating on smart contract protocols like Ethereum and Harmony. They seek API request handling services from Pocket\u2019s distributed node system, constituting the demand side of the network. On the market\u2019s supply side dwell two types of nodes ensuring that the information bridging demand of applications is met: service nodes and validator nodes.\n\nAnyone who downloads the chain history can run a full node and connect applications with relay handlers as well as being able to secure the network. However, Pocket requires nodes to stake at least 15,000 POKT to be eligible for handling application API requests and thus perform interchain information dissemination. These relay handlers are the service nodes that sit between the Pocket Network and the external blockchain, performing the essential part of the network\u2019s magic by running a Pocket full node and at least one RelayChain node (a full node on integrated networks) to connect the applications with the external networks. Among these service nodes, the top 1000 by staked amount can become the validator nodes. Validators check if service nodes handle relays and forging blocks with valid transactions through the Pocket\u2019s implementation of Tendermint PoS.\n\nThe third component, the network layer, is a set of rules that lies underneath, orchestrating critical operations such as application to service node coordination, reward and punishment mechanisms, and dispute settlements.\n\nReal-world transaction\n\nAlthough applications are the primary users of the Pocket Network, regular Web3 wanderers may also experience how the possible TCP/IP of the Web3 node infrastructure works by changing the Metamask RPC route to Pocket\u2019s public nodes. Applications refer to Pocket\u2019s facilitating website Portal to demand an RPC endpoint, which is currently the sole access point for applications. More direct and censorship-resistant integration through PocketJS will be enabled with permissionless app staking.\n\nIn contrast to the subscription-based payment model of the centralized providers, Pocket Network doesn\u2019t request direct payment from applications to mint a dedicated RPC endpoint. Instead, it adopts a stake-to-use model that requires users to stake POKT in order to access services.\n\nApplications can choose between a free tier or stake-based subscription. Pocket\u2019s free tier option serves the same number of relays as Infura\u2019s $225/mo subscription plan: 1 million relays/day. Applications can subscribe to the free tier, or preferentially, they can stake POKT and benefit from additional relaying services proportional to their staked amount (~130 relay/POKT at the time of writing). Nevertheless, app staking will not become permissionless until the protocol\u2019s major V1 upgrade to ensure sustainable scaling and high-quality service. As it will remain capped to an arbitrary number of app stakes (currently 2,298) with the Portal able to share a stake between multiple applications, most applications subscribe to the free tier and let Pocket Foundation cover their entry costs.\n\nPocket\u2019s access dashboard Portal is equipped with tools to support service quality. Before matching applications with service nodes, it runs a sync check and its Cherry Picker to make sure the nodes are synced to the chain\u2019s current state and operate on low latency. As applications start using their dedicated URL to send information to a non-native chain (e.g., requesting to see the total deposit amount in an Aave lending pool), a Pocket full node dispatches their relaying request to the network and initiates a session between them and the service nodes.\n\nSessions are regularly updated data structures that dictate which service nodes handle relay requests of the application for a predetermined time interval. Currently, an application is matched with 24 service nodes in a session, and the relaying service continues for four Pocket blocks before getting tumbled. The same 24 nodes typically serve an application for approximately one hour before a new session starts and the application is paired with a new set of nodes.\n\nSource: Pocket Network\n\nService nodes route relay requests to and from the non-native chain and keep track of the number of relays delivered. After the session is complete, they bundle them in batches and send them as proof-of-relays to Finality Storage. Validator nodes check the legitimacy of proofs to see if service nodes indeed provided the service. Then they forge Pocket blocks with valid transactions.\n\nAt the end of the block production, if the relays are valid and the application didn\u2019t invoke Challenge Transaction to challenge the proof-of-relay, the network mints tokens proportional to the volume of relays (currently 0.00843 POKT/relay). The reward pool is distributed among facilitators as such:\n\nService Nodes: 89% of the minted POKT\nPocket DAO: 10%\nValidator Nodes: 1%\n\nService nodes take the lion\u2019s share of the rewards. Coupling this form of generalized mining that leverages POKT as a unit of work with the lucrative return potential for the service nodes, the network experienced quite the success in building the supply side. This translated into a ~24 times the YoY growth, currently sitting at over 34,500.\n\nAdd to this zero downtime, no sunk cost, and censorship-resistant service provision, as well as Pocket\u2019s appealing free tier option. All of these have helped the network nurture the demand side of the market. Right now, the protocol handles over 200 million relays a day on average, indicating an increase of ~52x YoY. The significant uptick in average daily relays followed Pocket Network\u2019s integration with Harmony in October 2021. As Harmony users had issues with the default RPC providers and switching to Pocket alleviate these problems, Pocket captured a substantial amount of the network traffic right after the integration. As of today, approximately 150 million of the   200 million daily relays originate from the Harmony network.\n\nIn 2021, the network served 6.4 billion relays to Harmony, followed by Ethereum with 3.7 billion. Although these numbers seem somewhat small compared to Infura\u2019s 12 billion daily calls in 2019 and 2 billion daily ethcalls in 2020, the growth of the Pocket Network still merits attention. It took ten months for Pocket to hit the first billion cumulative relays milestone and only another six months to handle the same number of relays in less than a week.\n\nTokeneconomics and Reward Mechanism\n\nThere is a delicate relationship between a chain\u2019s technical capabilities and its economic model. Both need to uniquely coincide to permit the desired coordination game to unfold with success. With community concern centered around the sustainability of highly inflationary tokeneconomics, the protocol's economic life cycle is divided into three phases with which the POKT incentivization mechanism is calibrated to attain fast growth first and later switch to a more sustainable economy.\n\nAfter establishing a solid supply side in the Bootstrapping Phase, the protocol is currently in its Growth Phase, where the high inflation rates are intrinsic to its expansion strategy. In the same way Pool 2 attracts liquidity in DeFi, the Growth Phase of the tokeneconomics model revolves around the economic flywheel where a high APR on the native token attracts service liquidity, which in turn accelerates the growth of relay service capabilities and network integrations.\n\nWhen the growth of inflation becomes higher than the growth of total staked POKT supply and when the POKT price appreciates to a sustainable level, the Pocket DAO will initiate the\n\nMaturity Phase\n\nOverall, the POKT tokeneconomics is designed to attract long-term participants and diminish unproductive speculation. This vision is materialized in two instances: covertly banishing non-participant tokenholders from the network through high inflation rates and separating the right to governance from token holdership via merit-based vote claim.\n\nHowever, the truth is there is growing inflationary pressure on staked tokens with increased network adoption, due to node providers getting paid with freshly minted tokens for their relaying services. The rapid increase in total token supply tarnishes Pocket\u2019s low-cost stake-to-use payment model with a non-negligible dilution cost. Due to the protocol-implemented cap on staked apps, the discrepancy between the increased actual demand and total supply causes speculative price appreciation to remain essential for taming the turbulent difference sustaining the network growth.\n\nTo give a concrete example, the total POKT supply increased from 660 million to 960 million in the last six months, considerably diluting any application stake at the time. Yet, the inflation has been proportional to the increase in the number of relays. Hence, an increase in average daily relays combined with a speculative appreciation has offset the dilutive effect with an increase in overall network value, turning any upfront cost done at the time to a ~2x accounting profit.\n\nIn other words, the market demand allowed a positive ROI for the early adopters. However, after witnessing exponential growth in the last couple of months, the discrepancy between demand and supply became more apparent. The community acted quickly and recently passed two proposals to implement a more sustainable inflation mechanism. By adopting a gradually declining inflation, they aim to stabilize network dynamics and introduce protection to network stakeholders before any token burning starts.\n\nAs the inflationary pressures of Pocket\u2019s linear token minting punish non-participant tokenholders during rapid network expansions, POKT speculators have sought ways to generate income with their tokens. The most popular solution has been node financing, where POKT holders allocate their tokens to node runners for a share of the service. This service can only be accessed through custodial services. Moreover, the amount of staked POKT has no influence over the selection chances for a session, causing service node operators to strategically distribute their POKTs to multiple wallets and maximize the number of eligible wallets they hold.\n\nBoth of these phenomenons have a magnifying effect on the supply, thus affecting assessments on the meaningful supply-side growth. Although Pocket's ADR / ASN growth indicates that the network experienced a somewhat balanced adoption last year, a large portion of the relay handling capacity remains underutilized. Recently, the growth of the supply side started to significantly outpace the demand side, meaning that the average node profitability has been declining since its local peak on January 7, 2022.\n\nV1 Upgrade\n\nUntil recently, one deal-breaker for apps was the high latency of the network compared to centralized solutions. However, Pocket managed to tackle this problem and achieve a competitive latency by increasing the number of nodes in a session from 5 to 24 and improving its latency filters.\n\nSource: Internal test conducted by the Pocket Network team.\n\nOn top of that, the Pocket team is laser-focused on improving service quality with their massive V1 upgrade. The transition to V1 will comprise consequential alterations that will prepare the Pocket Network to scale its relay services by orders of magnitude. It aims to further lower the latency and boost the network in many ways with a novel chain architecture. Not expected to launch until at least the following year, the upgrade will offer new design mechanisms on four different modules of the chain: utility, consensus, peer-to-peer, and persistence.\n\nBecause Pocket Network must maintain a service quality on par with centralized competitors, they intend to incorporate massive enhancements to their incentivization and inspection mechanisms to further optimize the network for high-quality servicing.\n\nA major change is the addition of a new network agent. The underutilization of proof-of-relay challenging (Client-side Challenge Feature) and the inconvenience attached to the fail-first-correct-later approach drove Pocket to introduce a new agent in V1, fisherman. Disguised as an application, this new agent will play the role of an inspector and score nodes on availability, latency, and consistency of their services.\n\nPocket\u2019s V1 will also incorporate a quality-focused reward mechanism. In V0, Cherry Picker ranked nodes by their latency and made sure those with high latency got fewer chances for servicing. Like Cherry Picker\u2019s filtering, this new mechanism will distribute relay rewards not according to the individual relay volume but to the test scores provided by fishermen.\n\nBecause scaling to handle trillions of relays requires a vastly robust infrastructure, Pocket\u2019s V1 will focus on ensuring the network is ready to scale on all fronts. At the moment, Tendermint BFT requires extensive communication between nodes which causes a bottleneck for scaling the number of nodes. In V1, the protocol will adopt its own implementation of HotStuff BFT. This will be assisted with the introduction of task-specialized communication and an effective message dispersion method. Transitioning from random gossip of Tendermint BFT to structured gossip is expected to result in lower bandwidth usage and higher network efficiency.\n\nThe introduction of the quality-inspecting fishermen will also help network scale. Using these new agents, the network will be able to tinker with the protocol design to accommodate more clear-cut roles for nodes. Recently, the protocol separated tasks between validator nodes and service nodes to make sure they were less bound by each other\u2019s requirements. V1 aims to double down on the specialization feature by stripping the responsibility of keeping track of relay proofs away from service nodes thanks to fishermen. Thus, the network will make requests handling the sole responsibility of service nodes and allow them to allocate resources to increase network efficiency.\n\nV0 allowed developers to access RPC handling services with zero downtime and without the sunk cost of a subscription-based payment model. V1 will primarily focus on doubling down on the current value propositions instead of expanding the scope of operations. Since the permissionless app staking and the ultimate design for scalability won\u2019t be unleashed until V1, the network\u2019s true potential will remain unrevealed until this significant upgrade.\n\nConclusion\n\nOne may argue that the current permissioned state of Pocket's Portal is a sign of faux decentralization. One could further their argument by saying that not all nodes are created equal according to Pocket\u2019s proof-of-useful-work (generalized mining) mechanism. And the current node concentration might increase even more with professional node providers gaining an edge with V1 quality measures.\n\nFirstly, it might be counter-productive to get lost in often mismatched linguistic interfaces while arguing about the definitions and immediately condemning a practice if it doesn\u2019t exactly fit our ideal. Instead, it might be more pragmatic to take any endeavor that strives for diminishing the total censorable points of failure and consider it a cherishable improvement.\n\nSecondly, Pocket aims to thwart these with the eventual transition to permissionless application access, optimizing efficiency in V1 to lower technical requirements to run a node, and introducing a more granular geolocalization to give small nodes a competitive edge. Therefore, its full decentralization is also subject to a gradual process.\n\nFinally, Web3 needs a more decentralized infrastructure. As such, a multichain future dependent on seamless integrations between multiple networks requires decentralized infrastructure even more. As the focus for the last years primarily rested on enhancing the smart contract ecosystem with L2s and alternative L1s, the importance of decentralized middleware remains to be explored. With its distributed node network to tackle one of the pain points of the space, Pocket might be the missing point in the grand picture of decentralization as it carries the potential to help the space move away from centralized incumbents.\n\nCritics might call the current permissioned state of Pocket\u2019s Portal an example of faux decentralization. They might label Pocket\u2019s proof-of-useful-work mechanism (generalized mining) an unfair advantage for professional node providers. But instead of arguing about semantics, the focus of the conversation should be on Pocket\u2019s endeavor to diminish the total censorable points of failure, which is a cherishable improvement. Beyond that, Pocket aims to refute its critics\u2019 claims by gradually transitioning to permissionless application access, optimizing efficiency in V1 to lower the technical requirements to run a node, and introducing a more granular geolocalization to give small nodes a competitive edge.\n\nPocket\u2019s eventual move to full decentralization will meet Web3\u2019s need for a more decentralized infrastructure. Because a multichain future depends on the seamless integration between multiple networks, the focus for the last several years has been on enhancing the smart contract ecosystem with L2s and alternative L1s. With its distributed node network acting as a decentralized middleware, Pocket Network can become the key to helping the space move away from centralized incumbents.\n\nThis report was commissioned by Pocket Network, a member of Protocol Services. All content was produced independently by the author(s) and does not necessarily reflect the opinions of Messari, Inc. or the organization that requested the report. Paid membership in the Hub does not influence editorial decision or content. Author(s) may hold cryptocurrencies named in this report and each author is subject to Messari\u2019s Code of Conduct and Insider Trading Policy. Additionally, employees are required to disclose their holdings, which is updated monthly and published <a href=\"https://www.google.com/url?q=https://messari.io/article/messari-employee-holdings-policy-and-disclosures&source=gmail-imap&ust=1647457925000000&usg=AOvVaw0jwd9uUO4e2D2TzMmDVmb\">here.</a> Crypto projects can commission independent research through Messari Protocol Services. For more details or to join the program, contact hub@messari.io. This report is meant for informational purposes only. It is not meant to serve as investment advice. You should conduct your own research, and consult an independent financial, tax, or legal advisor before making any investment decisions. Past performance of any asset is not indicative of future results. Please see our terms of use for more information._", "references": [{"name": "Hasan Furkan G\u00f6k", "url": ""}], "published_at": "2022-03-25T13:30:00Z", "author": {"name": "Hasan Furkan G\u00f6k"}, "tags": ["Web-3"], "url": "https://messari.io/article/pocket-network-a-decentralized-solution-to-access-handling"}, {"id": "00c483b0-05b8-4959-a841-e58f3820b4a0", "title": "$Push it (Real Good): Decentralized Notification Service in a Multichain World", "content": "Key Takeaways:\n\nPush notifications are mostly absent in Web3 today, despite being a critical component of Web2.\nWeb3 organizations manage a scattershot of social media accounts to interact with their communities.\nEthereum Push Notification Service (EPNS) aims to solve this problem by offering a multichain, Web3 approach to push notifications and decentralized wallet-to-wallet communications.\nThe EPNS protocol incentivizes community engagement through its governance token PUSH and a network of delegates.\nThe company\u2019s roadmap for 2022 dictates a rich set of features including multichain support and direct wallet-to-wallet communications.\n\nPush notifications are ubiquitous in digital life today, but in Web3\u2019s current state, targeted push notifications are mostly absent. Instead, companies manage a scattershot collection of fragmented social media accounts to communicate with their users. When it comes to new feature sets, margin calls, governance votes, or even potential hacks, Web3 companies today find it difficult to simply reach their users. Ethereum Push Notification Service (EPNS) aims to solve this problem by offering a multichain, Web3 approach to push notifications and decentralized wallet-to-wallet communications. The project combats fragmented Web3 communications by enabling and incentivizing direct communications between decentralized services and users, without simultaneously compromising on features like user anonymity.\n\nIt\u2019s hard to imagine a world without push notifications. First introduced to mobile via the Apple Push Notification Service in 2009, the average American now receives 45+ daily pinged notifications to a phone, browser, or tablet. Perhaps unsurprisingly, roughly 60% of users opt-out of receiving push notifications, allowing generally only the most critical pings from financial and utility applications.\n\nDecentralized and Web3 platforms, by nature of their permissionless-ness, neither receive nor store typical user data, like names, emails, or phone numbers, which is a feature rather than a bug. It\u2019s meant to protect users from situations like a corporate data leak. Rather than permitting a company to store their data centrally, the Web3 user takes this responsibility and controls her own data, deciding when and whom to trust with that data. For companies seeking to engage and re-engage their users, though, the Web3 paradigm presents new challenges. Especially in a multichain world, where user activity spans tens or hundreds of applications across multiple blockchains, companies are finding it increasingly difficult to adequately communicate with and retain their users. On the user side, this is an equally challenging problem: interacting with multiple DeFi products requires users to constantly check metrics like liquidity margin, implied impermanent loss, or the sundowning of specific rewards programs. Look no further than the \u201cclose call\u201d from January 2022, as MakerDAO vault owner \u201c7 Siblings\u201d narrowly missed a $600 million ETH liquidation.\n\nSource: EPNS\n\nEPNS is building a detailed roadmap to alleviate this exact pain point,, incentivizing both companies and users to opt-in rather than opt-out and solving for communications fragmentation and asynchronicity in a multichain world.\n\nEPNS Enabling the Web3 Push Notification\n\nEPNS was founded in 2020 by Harsh Rajat and Richa Joshi, who together have over two decades of experience in founding and operating tech startups. Harsh and Richa are based in Mumbai, but the company employs a globally distributed team of over 30 people across development, product, and marketing. EPNS successfully closed a seed round in December 2020, raising $750 thousand at a $5 million valuation via a SAFT agreement, with participation from 25 angel investors and VCs, including Balaji Srinivasan, BlockRock Capital, LD Capital, and others. In March 2021, the company extended its SAFT offering to take on further investment, and raised $660 thousand from strategic and existing investors at a $12 million valuation.\n\nIn the company\u2019s own language, \u201cEPNS is a protocol for blockchain-based notifications that are chain agnostic, platform independent and incentivized.\u201d The protocol enables users (wallet addresses) to receive notifications and obtain token incentives through active participation. EPNS can be thought of as a wallet-to-wallet or service-to-wallet communications network, which enables pertinent off-chain events (e.g., Snapshot proposals) and on-chain information (e.g., block confirmations) to be transmitted to specific addresses (see this post on all the ways EPNS can integrate into DeFi). The protocol is a partially permission-based system, meaning all users \u2013 i.e., contract owners, channels, or users receiving notifications \u2013 must opt-in to receive or send notifications. EPNS maintains a public key registry of all opted-in users, which it considers non-invasive information because public keys are by nature publicly searchable.\n\nAny user can create what is called a channel. A channel exists to coordinate and send notifications to the channel\u2019s subscribers. Each channel\u2019s key information, such as description, organization website, and image, are input and stored as a JSON payload on IPFS. To successfully launch, each channel also requires a staked pool to fund its operations and incentivize subscribers. The protocol regulates the minimum and maximum $DAI deposit required to stake; currently, the staked pool requirement is minimum 50 $DAI with a cap of 250,000 $DAI. Each channel\u2019s pool is directly deposited to Aave (or in the future, a similar open-source lending protocol). The yield from this deposit is distributed to channel subscribers based on a time-based distribution model. Deactivating a channel comes with a minimum 10 $DAI penalty, which is set to disincentivize users from spoofing channels. The penalty fee is ultimately deposited into a separate fee pool operated by the treasury. According to the company, the specifics around staking requirements are subject to change in future versions of the protocol, ultimately to be decided via governance vote.\n\nSource:EPNS\n\nEPNS envisions three types of channels: open, closed, and mutual. Open channels are open to all users without restriction and can indirectly subscribe users by paying them a small fee (e.g., CoinDesk). Closed channels cannot be freely subscribed to and instead pay subscribers to opt-in. Mutual channels require both parties to approve a user subscription. Once the channel is established, the EPNS protocol algorithmically maintains the appropriate incentives via its public registry by distributing staked tokens and adjusting spam ratings across its user base.\n\nEPNS operates two universal channels, \u201cEPNS Channel'' and \u201cEPNS Alerter Channel\u201d, which are intended to only send out notifications of extreme importance to all its protocol users and channels. These notifications include for instance mainnet downtime, hacks, or similar events. For universal channels, users are required to opt-out if they wish to no longer receive protocol-wide notifications.\n\nEPNS takes spam into careful consideration, as mobile notifications have historically been overly exploited for retargeting and advertising. To combat spam at the protocol level, a rating is attributed to every channel based on time since launch, user growth, and unsubscribes due to spam. This rating is from 0 to 1 (1 = bad actor), with automatic notification throttling above a score of 0.8. The throttle mechanism is intended to systematically punish spam-like behavior at the channel-level. It is currently unclear exactly how the protocol will handle disputes around specific spam ratings.\n\nThough EPNS utilizes a semi-centralized infrastructure to provide its notification and message service to decentralized applications and users (see Whitepaper \u201cIntegration Flow\u201d), the vision is to further decentralize its infrastructure over time. For instance, the company is researching the possibility of enabling a static EPNS file stored directly on IPFS that could point to a channel\u2019s website hosted on IPFS. This could enable user-to-user communication, like hashed chat feeds and even decentralized video messaging. The following diagram shows how dApps and services can integrate with EPNS today.\n\nSource: EPNS Whitepaper\n\nFurther information for integrating services with EPNS can be found under the company\u2019s smart contract documentation, which stipulates further criteria around the activation and deactivation of channels.\n\nEPNS is the simultaneous developer of five products on top of the EPNS protocol: EPNS Infra; a mobile application; a dApp; Showrunners; and a JavaScript (JS) Library. EPNS Infra is the name for the middleware which transmits data from decentralized protocols to centralized carriers like iOS, Android, and web browsers. The mobile application is the user interface (UI) for sending and receiving notifications at the user level, while the dApp enables decentralized carriers like Compound or Aave to also receive notifications. Showrunners are meant to be exemplar channels run directly by the EPNS team to show off the full capabilities of the protocol and drive interest. Showrunners include notifications for events like ENS domain expiry, Compound liquidation alerts, and gas fee idiosyncrasies. The JS Library is a product for integrating EPNS simply and efficiently into third-party apps.\n\nOn January 11, 2022, after more than a year of development, the EPNS protocol went live on the Ethereum mainnet, meaning the company\u2019s suite of products are open for use. Ahead of the mainnet launch, ChainSafe Systemscompleted an audit of the protocol in October 2021 and identified a number of bugs and issues that the company immediately fixed. As of February 2022, no known bugs or exploits have been reported.\n\n$PUSH Launch and Tokeneconomics\n\nShortly after closing their extended seed round, EPNS announced details surrounding its $PUSH token generation event (TGE), including an overview of $PUSH tokenomics. According to the TGE press release, $PUSH tokens have been capped at 100 million tokens total, which are to be split among investors, community, team, advisors, and a reserve allocation which EPNS refers to as its foundation. As part of the TGE, $PUSH tokens were sold to the public via Polkastarter ($0.12 per $PUSH), and an emission schedule for liquidity rewards was released for UNI-V2 LPs and $PUSH stakers. Of the early seed and strategic investors, 20.5 million tokens (20.5% supply) are to be allocated over 24 months following the TGE, 20% of which unlock 3 months after the TGE while 80% vest linearly over the following 21 months. The team received 16% of the token supply with a cliff 9-months after TGE plus linear vesting for the following 48 months. Advisors received 3.5 million tokens (40% of the supply), meaning the remaining 60% of the supply was reserved for the foundation (7%) and the community (53%). As both the Polkastarter raise and LP rewards represent less than 10% of community tokens, EPNS will retain a significant amount of unallocated community tokens for future distribution, giving it the flexibility to adapt to future community sentiment with novel incentive strategies.\n\n$PUSH tokens were designed to give economic incentive to tokenholders to maintain the EPNS protocol. As such, the token\u2019s key function is for governance decisions related to the protocol, such as the distribution of protocol fees, user incentives, and voting thresholds. $PUSH tokenholders benefit from receiving 70% of platform fees, while the remaining 30% of fees are distributed to an ecosystem development fund meant for onboarding new partners and providing for rewards pools. Tokenholders can delegate their $PUSH to committed community members rather than directly vote on governance issues themselves; a list of current delegates and nominess seeking to become delegates can be found on the EPNS governance dashboard. Governance proposals and votes are organized on Snapshot, with 75,000 $PUSH being required to submit a proposal and the approval threshold per governance decision varying. One recent proposal approved late January 2022, PIP-02: Incentives for Approved Proposals, provides a 200 $PUSH incentive to tokenholders whose proposal receives approval. A further 100 $PUSH is rewarded for proposals with 50% more total votes than the average of the four prior approved proposals. PIP-01: Push Grants Program (PGP) was also approved in January 2022 and is focused on attracting developers to support the further development of EPNS; PGP intends to allocate $1 million from the EPNS treasury to promising projects.\n\nEPNS operates the $PUSH incentives dashboard for its key token metrics, with up-to-date TVL, rewards issuance, and governance, as well as the Rockstars community incentive program. Current TVL sits at just over $9 million with fewer than half of LP rewards already distributed. There is currently over $3.5 million in liquidity for swaps on Uniswap, and the EPNS token ecosystem continues to onboard prominent projects in the space. The existing group of ecosystem partners can be seen in the following overview:\n\nSource: EPNS\n\nKey Partnership, Integrations, and Current Users\n\nSince launching the company in 2020, the EPNS team has established multiple partnerships within the crypto ecosystem, focusing primarily on applications where an EPNS integration can have immediate impact. As expected, most partners are operating in the Ethereum ecosystem. That said, the company is focused on providing services across multiple blockchains and intends to be adaptive to market dynamics long-term (for instance, the company plans to offer non-EVM support as soon as Q4 2022). Readers might be familiar with the company\u2019s existing and ongoing partnership with ENS, in which ENS domain owners can enable notifications of upcoming domain expiration dates. More recent integrations include Digible, an NFT marketplace, and mStable, an Ethereum-based stablecoin AMM. In January, the CEX Huobi Global partnered with EPNS to enable notifications for its users of upcoming token launches. Although a CEX like Huobi typically interacts with its users directly via email or a mobile app, EPNS offers Huobi a secondary touchpoint and opens the exchange to a further set of Web3 users. In a recent blog post covering the protocol\u2019s functionalities, EPNS mentioned MakerDAO, Crypto Volatility Index, Bancor, Oasis, Mover, ENS, Snapshot, and Coindesk \u2013 all as existing users of the EPNS protocol. The total number of projects displayed on the EPNS channel dashboard stands today at 41 (see channel dashboard), but the number of soon-to-be-integrated projects is likely much larger, considering the growing number of partnership announcements.\n\nAccounting for users, the EPNS universal channels, EPNS and EPNS Alerter, show 2,796 and 797 subscribers, respectively (as of March 4, 2022). The largest channel, Ethereum Name Service (ENS), has 4,697 subscribed users; this partnership is a strong signal for EPNS user growth, as users who register ENS domain names are prompted during the registration process to enable notifications in the event their domain expires. Without EPNS, ENS users would have no way of receiving similar alerts. Looking at the number of $PUSH token holders is another approach to assessing total users on the platform today: this number currently sits at 3,926 accounts holding $PUSH tokens.\n\nDirect and Indirect Competitors\n\nThere are numerous push notification service providers operating within Web2. In fact, Facts and Figures projects the global notifications software market to grow to north of $31 billion by 2025. This market is made up of companies like Airship, CleverTap, One Signal, and others, which primarily offer SaaS solutions for the management and automation of push notifications on desktop and mobile. Andrew Chen from a16z wrote on the topic several years back with the help of companies like Leanplum, and reported some interesting data after analyzing over 670 million push notifications. While over 60% of users opt-out of mobile push notifications, certain categories greatly outperform in terms of opt-in and engagement. Moreover, engagement with push notifications is relatively time-sensitive, in that the highest engagement occurs in the evening after work. Financial services applications have been shown to perform the best in terms of push engagement, presumably due to users typically perceiving banking or financial information as critical.\n\nConsidering how early EPNS is to the market, there are no clear direct competitors offering a similar solution. The companies that make up the SaaS push solutions are offering an approach based on a Web2 paradigm, where service providers almost always retain user data such as email addresses, phone numbers, and other identifiers and interact with their users directly via SMS, email, or in-app push. However, these companies do not currently have the capabilities to offer push services to decentralized users in any meaningful way.\n\nEPNS indirectly competes with companies like Zapper and Zerion because they offer multichain dashboard and portfolio management to simplify wallet and account management at scale. As companies like Zapper and Zerion roll out mobile applications, they become more likely to develop their own notification systems without relying on EPNS. Nevertheless, it is unlikely these dashboard platforms ship push notifications for off-chain information in the near future, as aggregating and enabling push channels does not appear to be a key focus.\n\nThe blue ocean that EPNS is operating in flips the stakes by incentivizing users to opt-in, thus driving higher engagement and likely offering more benefit to the end user. Depending on how quickly EPNS can onboard partners, the protocol could quickly acquire significant market share.\n\nFuture Vision and Roadmap\n\nThe company\u2019s roadmap for 2022 dictates a rich set of features that are headed to EPNS users. Multichain support will likely be increasingly critical as user demand continues to disperse across L1s and L2s. The company believes wallet-to-wallet communication will be live via EPNS as soon as Q3 2022. Planned updates to the UI and around channel editing functions will be critical to ensure the product matches user expectations going forward; roll-outs can be expected in the first half of 2022.\n\nWith the exponential growth of OpenSea users over the last year, enabling push notifications on OpenSea might be worth considering for EPNS, especially in light of the amount of confusion that still exists around dormant listings on the platform. Alternatively, horizontal partnerships or integrations into portfolio managers like Zerion, Zapper, or Gnosis Safe seem like a potential win-win, as these services are already beginning to integrate push notifications for trade executions and token receipts. White-labeling is likely less of a consideration since EPNS intends to decentralize its push operations long-term, meaning companies can integrate EPNS services seamlessly without the need for a tailored white-label solution.\n\nThe highest risk to EPNS is likely in its incentive mechanism, as the push business model has traditionally been based on advertising and retargeting, where advertisers pay push service providers who promise increased user engagement and higher conversions. With EPNS, the user incentives are flipped, in the same way that Brave users originally were rewarded for watching advertisements. This is, in turn, the gamble: EPNS channels must continually ensure there is a high enough upside for users who opt in, either through pool incentives or a continual supply of highly critical push notifications.\n\nConclusion\n\nEPNS is operating at the edge of the new Web3 paradigm by taking a decentralized approach to building a familiar Web2 service. With the acceleration of multichain, user will increasingly demand services that simplify UX and enable easy management of multiple accounts across blockchains. Moreover, with the right balance of incentives for companies and users, EPNS is well-positioned to solve challenges related to fragmented communications in Web3 and ultimately enable more secure and engaged ecosystems across blockchains.\n\nThis report was commissioned by EPNS, a member of Protocol Services. All content was produced independently by the author(s) and does not necessarily reflect the opinions of Messari, Inc. or the organization that requested the report. Paid membership in the Hub does not influence editorial decision or content. Author(s) may hold cryptocurrencies named in this report and each author is subject to Messari\u2019s Code of Conduct and Insider Trading Policy. Additionally, employees are required to disclose their holdings, which is updated monthly and published <a href=\"https://www.google.com/url?q=https://messari.io/article/messari-employee-holdings-policy-and-disclosures&source=gmail-imap&ust=1647457925000000&usg=AOvVaw0jwd9uUO4e2D2TzMmDVmb\">here.</a> Crypto projects can commission independent research through Messari Protocol Services. For more details or to join the program, contact hub@messari.io. This report is meant for informational purposes only. It is not meant to serve as investment advice. You should conduct your own research, and consult an independent financial, tax, or legal advisor before making any investment decisions. Past performance of any asset is not indicative of future results. Please see our terms of use for more information.", "references": [{"name": "Davis Bourland", "url": ""}], "published_at": "2022-03-24T13:35:00Z", "author": {"name": "Davis Bourland"}, "tags": ["Web-3"], "url": "https://messari.io/article/push-it-real-good-decentralized-notification-service-in-a-multichain-world"}, {"id": "f03aeddb-7aa4-4010-9818-d1e9b3364065", "title": "Bridging BTC to Harmony's Ethereum Virtual Machine", "content": "Key Takeaways\n\nHarmony has developed a trustless BTC-to-Harmony bridge leveraging XCLAIM as the design framework. The bridge is most closely associated with the light client and relay model as defined by Dmitriy Berenzon.\nBTC is locked in Vaults on the Bitcoin network, with Vault Operators providing collateral in the form of the ONE token. Relayers, who monitor the Vaults for transactions, also must provide ONE collateral.\nFee payments are made to both Relayers and Vault Operators, encouraging broad participation from different entities. Both Relayers and Vault Operators may be slashed if they fail to meet their Service Level Agreements (SLAs).\nIn the future, there is potential for a new token to govern the bridge and its parameters.\n\nWith the release of Harmony\u2019s new trustless BTC bridge comes another opportunity for BTC hodlers to put their BTC to work and participate in DeFi without liquidating any precious sats.\n\nSmart contracts are extremely difficult to build with Bitcoin Script as it is intentionally more limited - helping make Bitcoin a more secure and resilient network. Ethereum, on the other hand, came along and made tradeoffs to achieve greater smart contract functionality and Turing completeness, which is why application development and DeFi originally blossomed there, but also why contract exploits are prevalent. \u2018Turing completeness\u2019 means that creating anything within that system is theoretically possible, as long as you can break it down into logical steps. Smart contracts and the sprawling world of Web3 are an example of this: where we are limited only by our imaginations (and making these bits of code gas efficient). Since Bitcoin does not have smart contracts, it is more challenging to create conditioned and complex transactions. This makes programmatic custody of bitcoin and bridging it to other blockchains trustlessly quite a tall task. Today, the vast majority of BTC used on other chains is via centralized custodians.\n\nThis report will examine a trustless BTC bridge, the Harmony BTC bridge to be exact; a new product within the Harmony ecosystem. It is designed to be secure and completely trustless. The bridge operation, economics, and risks will be evaluated as well as the implications of BTC functioning on an Ethereum Virtual Machine (EVM) compatible network.\n\nA Quick Primer on Harmony\n\nHarmony is a sharded, fully Ethereum Virtual Machine (EVM) compatible blockchain that utilizes an innovative consensus mechanism called Effective Proof-of-Stake (EPoS). Unlike \u2018traditional\u2019 PoS, in which the right to validate the next block is awarded via lottery or bidding, EPoS encourages decentralization by introducing a non-linear relationship between the amount of tokens staked and the chances of mining the next block. In other words, more tokens staked does not equal more rewards. Thus, stakers cannot harness economies of scale.\n\nFor a more in-depth explanation of the mechanism, check out the full EPoS explanation by the Harmony team and <a href=\"https://messari.io/article/at-one-with-harmony\">previous Messari research</a>.\n\nHarmony is also home to a burgeoning DeFi ecosystem, with TVL increasing more than four-fold in the past two months to reach over $1 billion. The majority of the TVL (60%) comes from game/DEX/NFT marketplace DeFi Kingdoms. The next biggest application by TVL is Tranquil Finance, commanding nearly $500 million.\n\nBridges Walked, So That Alt Chains Could Run\n\nThroughout 2021, the rise of L2s and many alternate L1s with liquidity incentives has meant that mercenary capital has moved from and across chains. Over $25B of value bridged across Ethereum is a testament to this.\n\nBridges are the vital piece of the puzzle that facilitate the movement of capital. Different chains are better suited for different uses, and bridges help them become interoperable. Different protocols have different rules and standards, which means tokens you can use on one chain are not usable on another. Bridges allow the use of tokens on new chains. This is achieved via \u2018wrapping\u2019, where a token is burned or locked in escrow on one chain, and an equivalent, \u2018wrapped\u2019 token is issued on the new chain.\n\nThus, if Bob has 10 tokens on the blue blockchain and wishes to move three to the red blockchain, he can lock three of the tokens on the blue blockchain and mint three wrapped tokens on the red blockchain. Bob still has 10 tokens; it's just that three are now wrapped and can be used in a new environment.\n\nHarmoniously Bridging BTC\n\nThe Harmony BTC bridge enables the wrapping of BTC for use on the EVM-compatible Harmony blockchain. Bridging Bitcoin and Harmony has potentially significant implications for the Harmony ecosystem: BTC is a massive asset, with an average market cap of just under $1 trillion over the last six months. If it can be deployed on another chain for yield and other uses, it may mean considerable increases in TVL and network activity.\n\nActivity and use of blockchains is the whole raison d\u2019etre after all; increased usage and the growth of the network is therefore a tremendous victory for any protocol.\n\nAt the time of writing, Harmony TVL stands at over a billion in USD terms. The ability to bridge over an asset worth ~$1 trillion could substantially increase TVL and the value of the Harmony network.\n\nWhat must be mentioned is that a secure bridge to Harmony is a win for all EVM chains and BTC holders. The use of the Ethereum Virtual Machine is, in effect, a standard that many different chains use. This universality dramatically reduces the complexity of using bitcoin on other EVM chains, as sharing standards make bridging tokens easier.\n\nSubsequently, bitcoin hodlers may also benefit from opportunities that lie beyond Harmony, exploring pastures anew on other chains as well.\n\nOne of the main reasons bitcoin hodlers may not wish to use BTC anywhere else is because they do not wish to take on any counterparty risk, and many existing bridges do not operate in a truly trustless way. After all, one of the main theses behind the creation of Bitcoin is the elimination of trust and reliance on third parties. Trustless bridges aim to eliminate these concerns and enable the use of BTC in smart contracts without sacrificing any of the decentralized cypherpunk ethos.\n\nOn paper, the economic incentives of the Harmony BTC bridge do mean it is trustless. Should this be achieved in practice as well as theory, this bridge could be the decentralized gateway for BTC into the EVM world.\n\nAccording to DeFiPulse, the only trustless BTC bridge is tBTC. However, of the ~330,000 BTC deployed on other chains, 79% is done through the custodial wBTC.\n\nSource: DeFi Pulse\n\nThe caveat is that representing this data depends upon an awareness of all active BTC bridges and discerning which UTXOs are locked in various vaults or pools to back bridged coins. However, this is not always possible, as represented by Shinobi, the bridge to Secret Network. The actual number of BTC active on other chains may be higher than reported.\n\nSince bitcoin can be deployed on Harmony, many users may be attracted as the Big Orange Coin can now be deployed for yield on various DeFi protocols.\n\nWhen on Harmony, BTC is represented as 1BTC.\n\nThey are not inherently of equal value. No algorithmic price peg is used; it is simply a supply peg. This means that BTC can always be redeemed 1:1 with 1BTC (plus fees) and vice versa regardless of any price premiums. Thus, game theory dictates that the market will keep the peg by arbitraging any differences.\n\nHow Does the Bridge Work?\n\nOn a very high level, BTC on the Bitcoin blockchain is first locked in a vault. This transaction is verified in a trustless manner through a relayer and enables the minting of 1BTC on the Harmony blockchain. On the way back, the 1BTC is burned - which is verified and gives the right to redeem the originally locked BTC from the vault on the Bitcoin blockchain.\n\nThe XCLAIM protocol is used as a framework for the bridge. It is a protocol that defines functions for wrapped tokens backed by assets on the original chain. Further information on the protocol and its inner workings can be found here.\n\nIn more depth, when BTC is being bridged, it is locked in vaults on the Bitcoin blockchain. Coins are stored until being redeemed. Thus, they act as backing for the newly issued 1BTC and give it its value.\n\nAnyone is supposed to be able to operate a vault should they wish: the process involves registering the vault and running a vault client. This is designed to be easy and profitable to attract more vaults and improve decentralization.\n\nIn order for the bridge to be trustless, the vault operators are required to post collateral in the form of ONE tokens - the collateral required is currently 150%. This ensures that they have a strong enough disincentive to run away with the BTC. If BTC is spent without authorization, or the vault goes offline and cannot provide service temporarily, punishments are enacted.\n\nRelayers monitor the vaults to see if any unauthorized transactions take place. They also monitor the Bitcoin blockchain for proof that UTXOs have been locked in a vault. They store BTC block headers on Harmony and enable the 1BTC issuing contract to see whether an issuer has made the transaction they claim to have made on the BTC blockchain. Relayers, like Vaults, must post collateral in ONE that is liable to be slashed in the event of malicious behavior.\n\nFees are paid to both of these types of actors to incentivize participation from a network of actors to avoid having just one Relayer and Vault operated by the Harmony team. Trustlessness may only be achieved through decentralization after all.\n\nAn oracle is used to determine the price of ONE relative to BTC. This is how the 150% collateral required is monitored. Currently, this source of information is the only component that is not decentralized - the bridge assumes that the oracle is trustworthy. However, the Chainlink integration is now implemented, and the source of price feeds will now be as decentralized as the Chainlink network.\n\nAccording to the Harmony team, further steps are being taken to mitigate price feed risk. The staked relayers can also submit price feeds used to benchmark the oracle price and determine whether there is a difference between them that is greater than 0.5%. If price fluctuations between two price feeds are greater than 10%, additional measures are taken.\n\nDescribing the bridge with a practical example:\n\nBob wishes to use his BTC for yield farming on the Harmony blockchain.\n\nBob selects a vault, sends his BTC to it, and includes his Harmony address.\nOnce this transaction is verified, a relayer submits proof of inclusion in the Bitcoin block to the Harmony chain.\nThis proof allows Bob to mint 1BTC, which is sent to the Harmony address he submitted with the BTC transaction.\nBob can now use his newly issued 1BTC to get some fat, juicy yields.\n\nThe Economics\n\nIf vaults go offline or fail to provide users service, they are slashed between 10% and 30%. The severity of the punishment is determined by each actor's score, or SLA (Service Level Agreements). The SLA is a number between 0 and 100. The score is increased by good behaviors and service and reduced by subpar performance and crashes. The higher score a vault has, the higher rewards it receives, and the less it is penalized if it fails to provide service. Both Vaults and Relayers have SLAs.\n\nThe reasoning for this is because extreme punishments for first-time offenders may deter actors from participating as vaults. Hence this reputation system is used to give vault operators a history and credibility they can use to escape hefty fines should they fail for any reason beyond their control.\u00a0 If Vaults fail to provide adequate service, their collateral is awarded to the depositor who has lost their BTC. If Relayers are slashed, the tokens are sent to the fee pool.\n\nThese fees are distributed to incentivize the vault operators and Staked Relayers to provide this essential service that allows the bridge to operate in a trustless manner.\n\nSource: BTC Bridge Specs - Fee Model\n\nUsers pay a fee of 0.5% for using the bridge and minting/redeeming 1BTC - paid in 1BTC. These fees are paid to fee pools, and distributed across Relayers and Vaults according to their SLA. Furthermore, direct fees are paid to Vaults and Relayers directly for their service. There is also a security deposit paid, regardless of the amount bridged, that is equal to 0.5% of the amount of collateral required to back the requested BTC transfer. In addition, all slashed stakes (penalties for downtime/bad service) are also sent to these pools.\n\nEssentially, using a permissionless network of vaults and relayers means that the bridge can operate in a truly censorship-resistant way. The fee model is the final puzzle piece that makes the bridge work. If all stakeholders act in a game-theoretic way, and if there are enough stakeholders to make it sybil resistant: the bridge functions.\n\nFuture Plans\n\nAs with many projects, certain aspects of the project are fixed initially, and the team reserves control over them to remain agile and make quick decisions. Future plans and developments revolve around the economics and the governance and control of the bridge.\n\nEconomics\n\nThe current security deposit fee for locking BTC in a vault is a single ONE token. This could change to be a percentage of the vault\u2019s collateral.\nMove to a fee market instead of the fixed 0.5% minting and redeeming fees.\n\nGovernance\n\nThere are plans to introduce a token in a future release.\nThis will likely be used for decentralized governance of the bridge and its specs/fees.\nThe release of a token will also probably lead to revised tokeneconomics.\n\nRisks\n\nAs laid forth in an excellent medium article by Dmitriy Berenzon: there are three main categories of bridges. Any given bridge can fall into one of the classifications or combine elements of each.\n\nSource: Dmitriy Berenzon\n\nThe 1BTC bridge is one of light clients and relays. As can be seen on the above graph, it excels in capital efficiency, statefulness, and security. The economic incentives of the bridge ensure that the federation of Staked Relayers maintains connectivity and statefulness. In addition, Vaults are incentivized to provide timely service.\n\nHowever, two areas of weakness are capital (in)efficiency and security.\n\nCapital Efficiency\n\nThe staked tokens by Relayers and Vaults and the BTC collateral posted by users is just that: fixed capital that sits there hostage to disincentivize antisocial behavior. Although a robust mechanism that aligns incentives, this capital is not used for liquidity or put to work in any way.\n\nCapital inefficiency is not a sin per se; it just means that the utilization of resources could be more efficient. In addition to that, it could hamper scalability, as collateral must increase proportionally with value bridged. Since collateral required to bridge BTC is 150%, the amount held in vaults must always be 10% greater than 1BTC in existence. Of course, these are design tradeoffs made in the name of speed and aligned economic incentives.\n\nSecurity\n\nA chain is only as strong as its weakest link. In the world of crypto and blockchain, this usually translates to the layer of the stack that is most centralized. In the case of the bridge, it is the reliance on the price oracle whose trustworthiness is assumed.\n\nThis oracle dictates the price of ONE/BTC. Since ONE is the collateral used by Vaults and Relayers, the price dropping below a certain threshold relative to BTC can trigger liquidations/slashing. Theoretically, should the oracle be manipulated (a common exploit) to give false prices, these conditions may be falsely met.\n\nChainlink Oracles have now been integrated and will provide a price feed not dependent upon a single oracle. Thus the oracle risk will be mitigated by making this link of the chain as censorship resistant as Chainlink\u2019s network.\n\nConcluding Remarks: Chains Existing in Harmony\n\nUltimately, the Harmony BTC bridge uses a network of vaults and relayers. The architecture is decentralized in theory, but it is yet to be seen whether the existing incentives are enough to galvanize different actors into participation to achieve decentralization.\n\nThe merits, as well as the risks of the design, have been examined, and the undeniable importance of bridges mentioned. The multi-chain world is not an idea; it is a reality. Different chains are optimized for different purposes. Numerous blockchains today boast impressive activity and value locked. However, issues arise due to clashing ideologies, standards, and the fragmentation of liquidity and information.\n\nThe future of dapps and UX is not one where users manually select which chain to transact on; it is one where users are unaware of which underlying blockchain is being used to interact with Web3. Users may even be using multiple simultaneously - one for verification, another to sign transactions, and yet another for settlement with finality.\n\nFrictionless bridges and communication between blockchains can enable this vision of the not-so-distant future. The continuing development and decentralization of these services are vital to an internet run on blockchains. The new Harmony-Bitcoin bridge is another step towards this future, where information and value are seamlessly and trustlessly interoperable across chains.\n\nThis report was commissioned by Harmony, a member of Protocol Services. All content was produced independently by the author(s) and does not necessarily reflect the opinions of Messari, Inc. or the organization that requested the report. Paid membership in the Hub does not influence editorial decision or content. Author(s) may hold cryptocurrencies named in this report and each author is subject to Messari\u2019s Code of Conduct and Insider Trading Policy. Additionally, employees are required to disclose their holdings, which is updated monthly and published <a href=\"https://www.google.com/url?q=https://messari.io/article/messari-employee-holdings-policy-and-disclosures&source=gmail-imap&ust=1647457925000000&usg=AOvVaw0jwd9uUO4e2D2TzMmDVmb\">here.</a> Crypto projects can commission independent research through Messari Protocol Services. For more details or to join the program, contact hub@messari.io. This report is meant for informational purposes only. It is not meant to serve as investment advice. You should conduct your own research, and consult an independent financial, tax, or legal advisor before making any investment decisions. Past performance of any asset is not indicative of future results. Please see our terms of use for more information.", "references": [{"name": "Karim Halabi", "url": ""}], "published_at": "2022-03-24T13:30:00Z", "author": {"name": "Karim Halabi"}, "tags": ["Decentralized-Finance"], "url": "https://messari.io/article/bridging-btc-to-harmony-s-ethereum-virtual-machine"}, {"id": "97c21720-e3e4-4caf-b9dc-1b8d839f8a21", "title": "Polygon: A Multi-Sided Approach to ZK Scaling", "content": "Key Highlights:\n\nPolygon is an internet of blockchains company focused on scaling Ethereum through a portfolio of ZK technologies.\nThe company is actively developing seven scaling solutions ranging from various ZK Rollups to side chains to engineering infrastructure such as software development kits (SDKs).\nPolygon will benefit significantly from its 7,000+ dapp ecosystem across DeFi, metaverse, NFTs, and gaming as its ZK based scaling solutions come online in 2022.\nPolygon\u2019s corporate development strategy includes leveraging partnerships with venture funds, managing its own NFT/gaming ecosystem, and operating an internal investment fund tasked with finding promising crypto projects.\nUpcoming milestones for Polygon include more business partnerships with existing protocols and a redesign of the MATIC token to better fit the company\u2019s future initiatives.\nPolygon\u2019s global Web3 ecosystem benefits significantly from the burgeoning Web3 technology talent in India. Polygon offers developer training, partnerships with premier universities like IITs, and hackathons to grow the developer talent base and incubate high-quality Web3 startups in India and abroad.\n\nCrypto made big strides these last two years. In the summer of 2020, DeFi primitives gained prominence in what became known as \u201cDeFi Summer.\u201d The following year, NFTs became popular \u2013 first as profile pictures, then as community tokens, and now with revenue-generating use cases such as music and gaming, among others.\n\nNaturally, the growing interest behind blockchain corresponded with a surge in users. Total value locked (TVL) on smart contract networks rose from $500 million since the start of the pandemic to $170 billion two years later. Even more, with further interest in the metaverse, ownership of assets, and banking the unbanked, crypto\u2019s growth is only expected to continue.\n\nThough investors all benefit from crypto\u2019s maturation, the expansion of the industry hasn\u2019t come without growing pain. Quite infamously, the current blockchain infrastructure struggles to support the rise in users. Transaction throughput has slowed, and network fees have spiked. Ethereum in particular struggles to handle the transaction load submitted to its blockchain. According to Etherscan, average gas costs jumped from 10 gwei in March 2020 to 60 gwei two years later \u2013 without accounting for stretches in 2021 when gas consistently hovered around 150 or even 200 gwei, highlighting the need for improved infrastructure.\n\nThus, an emerging consensus we\u2019re seeing amongst investors is the need for a cross-chain ecosystem. In other words, one monolithic blockchain may not be enough to support everything users need. By distributing the work across multiple entities, the total work required from one singular blockchain would diminish. If investors are right, building a cross-chain world is the way to achieve the type of scale needed to onboard the first billion users.\n\nThis report will highlight a major component of Ethereum\u2019s cross-chain scaling effort: Polygon Technology. Key sections of this report include an overview of the company, a short introduction to ZK Rollups, Polygon\u2019s ecosystem of projects, and the company\u2019s upcoming roadmap.\n\nA Multi-Chain Ethereum World\n\nPolygon Technology, widely known just as Polygon, is building a collection of platforms for blockchain infrastructure \u2013 specifically, for the Ethereum ecosystem. Its products are designed to support the growth of Ethereum as the network ramps up its user and application base. It\u2019s worth noting, Polygon\u2019s particular focus on Ethereum reflects the company\u2019s core belief in the network as the center of the future cross-chain paradigm.\n\nFrom a bigger picture, Polygon competes in what we should call the blockchain-as-a-service industry. Alongside competitors like Starkware, Arbitrum, Loopring, and Matter Labs, these startups create solutions designed to enhance blockchain scalability through increased network throughput and reduced transaction costs.\n\nAt present, blockchain scaling lacks a one-size-fit-all answer, meaning each startup\u2019s solution \u2013 be it Optimistic rollups, Zero Knowledge rollups (ZK Rollups), or some other alternative \u2013 has a place in the current ecosystem. This sort of competitive research effort is what Mihailo Bjelic, co-founder of Polygon, has referred to in the past as \u201cletting one thousand flowers bloom.\u201d\n\nPolygon started in 2018 as a joint effort between Bjelic \u2013 who was experimenting with Plasma rollups \u2013 and Jaynti Kanani, Sandeep Nailwal, and Anurag Arjun, the three of whom had been working on another scaling blockchain, Matic Network. At that time, the joint entity combined with a few products under its belt: (1) The blockchain SDK development framework developed by Bjelic and (2) the Plasma rollup and Matic sidechain, powered by the MATIC token. Unfortunately, blockchain researchers discovered the data availability problem shortly thereafter (discussed further in the report), leading to Plasma being deprecated for other solutions. The resulting period of time left the team focused on the Matic sidechain, the SDK framework (later renamed to Edge), and in search of next steps.\n\nAround February 2021, the team announced the rebrand from Matic Network to its current Polygon name and announced its strategy to become a cross-chain Hub for Ethereum. Its new goal would be to function as a company for a host of multichain services. Offering an emerging suite of products would become the new focus for the company, starting with the user-facing product that had survived since the beginning: Matic Network, now rebranded to Polygon Proof-of-Stake (PoS).\n\nPolygon PoS Sidechain: The First Product\n\nUsers may already be familiar with Polygon PoS. The sidechain has been around for close to two years. It launched just before DeFi Summer and took full advantage of the opportunity in May 2021 when curiosity around decentralized apps exploded.\n\nMuch has been made about Polygon PoS\u2019s technical classification given the company\u2019s efforts around Layer-2 scaling. We think it\u2019s an important distinction to qualify that the current iteration of the PoS Chain is a Layer-1 sidechain, largely attributing to the network not inheriting security from Ethereum nodes and having its own set of validators. Regardless, for users seeking affordable transaction costs, this EVM-compatible network is an option worth exploring; in fact, many of Ethereum's most popular DeFi platforms such as Aave, Curve, and Uniswap provide their services on the PoS Chain at a fraction of the gas cost required by Ethereum.\n\nThe chart above highlights the difference in average transaction costs between Polygon PoS and Ethereum. The data presented is striking. Average costs are only fractions of a dollar on Polygon PoS whereas users are frequently paying $20 or more on Ethereum. If we assume every transaction completed on PoS Chain in the past year was instead made on Ethereum, users would have paid almost $15 billion more in total transaction costs.\n\nNow, it\u2019s important to know this data is skewed by the lower price of MATIC relative to ETH. If the costs presented are adjusted to USD, the absolute cost on PoS Chain is lower than on Ethereum, but measured in gas prices, differences are not stark. Nonetheless, PoS Chain still represents a great option for users wanting to avoid the costs of Ethereum today. And it is a big reason why the sidechain processes more daily transactions than Ethereum \u2013 including hitting a peak 4x more than Ethereum \u2013 and has attracted 100+ million wallets to date.\n\nReaching these numbers is a milestone in itself, but one could argue it\u2019s just an appetizer for Polygon\u2019s larger aspirations. As we saw above, sidechains don\u2019t level up blockchain scaling as well as Layer-2 solutions like rollups. That\u2019s why Polygon is devoting its resources to Layer-2 scaling and ZK Rollups \u2013 to find solutions to improve throughput and reduce the amount of gas needed to make transactions. The thesis strikes a chord across the industry as leading tech and crypto-native investors alike have chosen to grab a seat at the table. In fact, notable names such as Sequoia Capital India, Andreeson Horowitz, Tiger Global, Union Square Ventures, Galaxy Digital, and others have backed the company, signaling faith in the team and alignment with the company\u2019s vision.\n\nPolygon\u2019s roadmap includes the development of the company\u2019s seven product solutions, ranging from the aforementioned PoS sidechain, to L2 Rollups, and to other blockchain infrastructure. In total, Polygon is committing more than $1 billion to acquire promising projects, invest in research, and create an Ethereum scaling ecosystem. Since a significant part of Polygon\u2019s future incorporates ZK technology, it\u2019s important to first understand how it works before getting to the rest of the report.\n\nA Brief Primer to Zero Knowledge Rollups\n\nZK Rollups are one of the two general categories of Layer-2 rollups, alongside their peer, Optimistic rollups. At its core, the idea of ZK Rollups relies on cryptographic proofs to verify changes to the network state before they are bundled into the Ethereum blockchain. As a result, some call ZK Rollups \u2018validity proofs\u2019. This stands in contrast to Optimistic rollups, which \u201coptimistically\u201d assume all transactions are correct and let verifiers on the mainnet check for fraudulent transactions over some course of time. Optimistic rollups are also referred to as \u2018fraud proofs\u2019.\n\nLet\u2019s get a little deeper behind ZK Rollups and see why they\u2019re promising. The basic premise behind ZK Rollups is to have third-party operators batch transactions together instead of verifying each individually \u2013 hence the \u201crolling up\u201d taxonomy \u2013 to increase the total processing capacity of the network. State changes to the blockchain are submitted in the form of ZK Proofs for the verifier on the mainnet to check. The verifier can be convinced of the validity of all the submitted transactions through the proof without \u2013 due to the zero knowledge feature \u2013 having to run each individual transaction.\n\nAn important part of this process is the soundness property of proofs, which ensures malicious provers are unable to deceive verifiers with false statements. Extrapolating this property for rollups is simple: all batched transactions must be valid if they are to be accepted onto the blockchain. And since zero knowledge of each transaction is required by the mainnet for validation, little interaction between the two chains is needed, making gas fees cheaper and the overall rollup scaling easier.\n\nAnother core advantage of ZK Rollups is the network\u2019s ability to validate transactions immediately. Automatic verification leads to numerous benefits for the user. The simplest is the ability to move capital from the rollup chain to the mainnet right away, without needing to wait for others to check for fraudulent data, as is the case when using Optimistic rollups.\n\nThe technology behind ZK Rollups is promising, but for total fairness, it\u2019s also worth mentioning that ZK Rollups have, to this point, not lived up to expectations. This is an important caveat based on the fact no ZK Rollup to date has launched with full EVM-compatibility on Ethereum\u2019s mainnet. That\u2019s why almost all active rollups to date use fraud proofs. However, several research initiatives are close, with a few operating on testnet in H1 2022, including those owned by Polygon. At the risk of sounding like a broken record, it does seem like the much-awaited day is close.\n\nPolygon\u2019s Product Stack\n\nPolygon\u2019s suite of products includes the aforementioned PoS sidechain and six ZK-supported projects. Out of those six, three of them (Hermez, Miden, and Zero) are direct ZK Rollups, another (Nightfall) is a privacy-enabling Optimistic rollup with ZK cryptography, while the remaining two (Avail and Edge) are designed to help build ZK and modular infrastructure. The graphic below lists the full product suite and classifies each in relation to shared Ethereum security. Low security products are akin to standalone chains with independent validators while high shared security products are full Layer-2 rollups entirely dependent on Ethereum. In the next section, we will run through each of the products, starting with the four ZK Rollups.\n\nPolygon Hermez: Decentralized and Active\n\nIn August 2021, Polygon announced it acquired Hermez for $250 million in one of the largest blockchain network M&A deals to date. The transaction was financed through Polygon\u2019s native MATIC tokens from the company\u2019s token treasury. Previous holders of Hermez\u2019s native token (HEZ) were able to redeem their tokens for MATIC at a rate of 3.5 MATIC tokens to 1 HEZ token. The outcome of the acquisition meant Polygon was in charge of the new resulting entity, Polygon Hermez.\n\nOf the four ZK Rollups in Polygon\u2019s suite, Polygon Hermez is the furthest along in use. It\u2019s the first open-source decentralized ZK Rollup to operate on top of Ethereum\u2019s mainnet \u2013 albeit without ZK EVM compatibility \u2013 and has been available to the public since March 2021. Users deploy funds to the rollup network where they can be quickly and cheaply sent between wallets as transfers and payments. Polygon Hermez is able to process up to 2,000 transactions per second, a number that\u2019s expected to rise even higher as Ethereum implements sharding sometime in 2023 after The Merge. Regardless, the end result today is still a more than 90% reduction in transaction costs compared to typical mainnet gas fees.\n\nSource: Polygon Hermez\n\nAs with each of Polygon\u2019s other ZK Rollup products, Hermez has its own research focus. Hermez places a high emphasis on decentralization. It is the only active Layer-2 without a need for a centralized operator. While the use of decentralized sequencers seems trivial, particularly in the early innings of ZK Rollups, the long-term effects could be significant. As cited by the Polygon team, a switch from centralized to decentralized operators may be operationally and technologically challenging down the road, giving Polygon Hermez a head start relative to its competition.\n\nWhat lies ahead for Polygon Hermez is the launch of Polygon Hermez 2.0, a future iteration combining the existing ZK Rollup with an implementation of a ZK EVM. The need for the latter is crucial for scaling Ethereum as non-ZK EVM rollups can only handle token payments and token transfers. A ZK EVM-enabled blockchain will allow the network to handle smart contracts directly on the rollup and open up another avenue of innovation. The final product is expected to closely emulate the 50 - 70 instruction codes available on the original EVM. This decision to stick with similar machine language opcodes allows engineers to port existing applications to the rollup or easily create new ones if needed.\n\nA testnet release is expected sometime in the next three months (Q2 2022). Once testing is over, a full launch of Polygon Hermez 2.0 is anticipated to arrive sometime the following quarter. Should that timeline hold, ZK Rollup enthusiasts will get the opportunity to see this scaling option take shape.\n\nPolygon Zero: Need for Speed\n\nPolygon Zero began as Mir Protocol, a project for decentralized applications powered by recursive ZK Proofs. In December 2021, Polygon announced an acquihire of the Mir Protocol team, seeking to combine synergies between the Mir project and the rest of Polygon\u2019s tech stack. The deal was even larger than the Hermez one. It was announced at around $400mm and financed through a combination of cash and Polygon\u2019s MATIC token.\n\nAs part of the Polygon ecosystem, the Mir team\u2019s goal remains the same: to build the world\u2019s fastest ZK Rollup. Unlike Polygon Hermez \u2013 which devotes the majority of research resources towards decentralization\u00a0 \u2013 Polygon Zero\u2019s target is speed. The optimal solution discovered so far is through scalable ZK-SNARKs, otherwise known as recursive proofs.\n\nRecursive ZK Proofs speed things up by increasing the number of transactions that can be processed at any one time. We can do a comparison here: Existing ZK Rollups often take significant computing resources to generate a proof for batches with a large number of transactions; this is true for ZK Rollups that need to support general-use applications and even more true for those that are slowed down by a need for EVM-compatibility. In contrast, efficient recursive ZK Proofs allow for the distribution of processing into more manageable, concurrent chunks of work. Once each transaction has been verified, a recursive algorithm goes through and aggregates all the proofs until they eventually settle into one proof. The best way to imagine this is using a pyramid shape where the base layer represents all the transactions. As each transaction gets proved, it gets sent upwards until they all culminate at the top. The final proof can be sent to the mainnet at a quicker and more cost-effective rate than current alternatives.\n\nPolygon Zero is able to do this through Plonky2, a recursive ZK Proof generator capable of generating a SNARK proof every 0.17 seconds, making Plonky2 the world\u2019s fastest recursive ZK prover.\n\nInventing this technology has taken years of research. Practical applications behind recursive ZK Proofs only started in 2014. In 2019, two minutes were needed to generate each recursive proof. The slow proof generation clearly rendered the technology useless for blockchain scaling. In 2020, the development of Plonky, combined with a few other techniques, reduced that time to 15 seconds. Plonky2 brought the time down even further to 170 milliseconds, making it the world\u2019s fastest recursive ZK prover.\n\nThat said, further research is needed before Plonky2 goes live. Timelines are yet to be announced, but further information will be provided by the Polygon team as additional prover breakthroughs occur.\n\nPolygon Miden: STARKs not SNARKs\n\nThe next ZK Rollup in Polygon\u2019s arsenal is Miden. Unlike most ZK Rollups, which use ZK-SNARKs, Miden utilizes another proof called ZK-STARKs. STARK stands for \u201cscalable transparent argument of knowledge\u201d while SNARK stands for \u201csuccinct non-interactive argument of knowledge.\u201d It should not be surprising then to learn SNARKs and STARKs share similarities given how closely their names align. At their core, they both function as a privacy and scaling technology, providing applications with the ability to verify proofs at a more secure, faster rate.\n\nWhere they differ is in the details. STARKs traditionally do not require an initial setup process between the prover and validator, though some modern SNARKs have found ways to remove this process as well. What SNARK hasn\u2019t matched is the ability to respond to the threat of quantum computing: SNARKs are vulnerable to quantum computing whereas the leaner cryptographic functions used by STARKs are provably post-quantum secure.\n\nThe tradeoff for using STARKS is the need for a larger proof, resulting in higher gas costs and lack of recursion. Implementing the latter may be possible but it is unproven for the time being. Additional research of both SNARKs and STARKs will continue to open new doors for Layer-2 proofs.\n\nAs the graphic below shows, the transaction rollup procedure is similar to the traditional ZK Rollup with the usual SNARKs replaced with STARKs.\n\nSource: Polygon Miden\n\nMiden\u2019s advantage lies in the creation of Miden VM, a ZK-STARK compatible with EVM. Miden VM is a general-purpose ZK Virtual Machine, which lets developers utilize the full Turing completeness capability of the platform. In addition, multi-language support is offered for developers. These languages, including Solidity, Move, and Vyper, are compiled into Miden Assembly Language to be read by the VM.\n\nMiden VM\u2019s evolution began in 2019 as a library called genSTARK, which allowed developers to create simple STARK provers. Continued improvements, such as full Turing completeness, took shape with Distaff VM (early generation STARK-based VM) and Winterfell (upgraded iteration of genSTARK). The current iteration of Miden VM, a public v0.1 prototype, combines features from both Distaff VM and Winterfell and was launched in November 2021. Developers interested in building with the new virtual machine are able to experiment with the product\u2019s features. A v0.2 prototype is anticipated to be released in Q2 2022. Testnet development should take the project through the end of the year, after which a mainnet deployment is expected to occur sometime in 2023.\n\nPolygon Nightfall: Privacy for Enterprises\n\nAs mentioned in the ZK Rollup introduction, ZK Rollups do not, by default, offer privacy from prying eyes. That\u2019s where Polygon Nightfall comes in. Nightfall is an Optimistic rollup enhanced by the privacy benefits of ZK cryptography. Here, the type of ZK cryptography used in Nightfall differs slightly from generic ZK Rollups; the former is used to foster data privacy while the latter is used for transaction verification. The idea behind the pairing of ZK cryptography with a fraud proof rollup originated from the need to service enterprises with a differentiated product, one that kept the privacy elements of ZK cryptography while maintaining low transaction costs.\n\nNightfall was originally created in 2019 by EY, the Big 4 professional services firm, as a way to conduct private transactions on Ethereum. This was a big milestone as it marked the first time a large enterprise got actively involved with Ethereum\u2019s development. As demand for privacy-secure blockchains increased in the years since, EY began to look for partners to help scale the offering. What occurred as a result became Polygon Nightfall, a collaboration between EY and Polygon to create a public-facing privacy-focused rollup, making it an ideal option for enterprises.\n\nCorporate transactions and operational tools benefit the most from this type of privacy feature. Nightfall will also be legally and KYC-compliant. The goal of the partnership is to create a whitelist of companies who can access the network; when a business makes a transaction, a proof will need to be provided confirming access before the privacy-secure transaction gets completed.\n\nEY\u2019s corporate clients can already connect to Polygon Nightfall through an EY front-end portal. Nightfall is currently exploring further ways to scale the product. No specific timelines have been set for the roadmap, but both EY and Polygon have aspirations to continue their partnership for other enterprise-specific blockchains.\n\nPolygon Avail: Data Availability for Ethereum\n\nPolygon Avail is the first of Polygon\u2019s two architectural products. Avail seeks to address the challenges nodes face when processing malicious or incomplete data. In the blockchain world, these challenges are referred to as the data availability problem, which was the problem mentioned above that caused researchers to sunset Plasma rollup initiatives. Common situations where this problem occurs include when nodes accept blocks where data is incomplete or when nodes are unable to validate the accuracy of transaction data in the network (i.e., blockchain censorship).\n\nPolygon describes Avail as the solution to this problem across the multi-chain Ethereum ecosystem. Avail is a data availability-specific blockchain designed for standalone chains, sidechains, and other scaling technologies \u2013 meaning the entirety of the Avail chain is purposed to store Ethereum \u2018calldata\u2019 tracking changes to the Ethereum state machine. No smart contracts are intended to be deployed on Avail, and no applications can be built on Avail either. Rather, the entire purpose of Avail\u2019s existence is to sequence and store data in order to ensure data remains accessible by a sampling process conducted by light client nodes.\n\nSource: Polygon Avail\n\nCompared to current blockchain architecture, the Avail network will focus on ensuring full transaction data is posted rather than verifying state changes. Unlike full nodes, light nodes do not download the entire block data but instead prioritize sampling a random group of data from each block to evaluate for completeness. This process is known as a data availability check. It\u2019s a technique shared by other data availability platforms and can be completed at a constant resource cost, regardless of data scale.\n\nIn its final form, Polygon envisions a scenario where developers might create their own standalone PoS chain and outsource network security to Avail. Operators on the standalone chain would send the transactions to Avail for ordering and storage. This helps immediately bootstrap network security since complete transaction data is held off-chain for easy access.\n\nAvail currently remains in development with no key roadmap dates yet announced by the Polygon team.\n\nPolygon Edge: Made With Developers in Mind\n\nPreviously known as Polygon SDK, Polygon Edge is an open-source modular blockchain development framework built for engineers who want to create their own blockchains. The framework allows for the creation of both secured chains (Layer-2 blockchains) and standalone Ethereum sidechains.\n\nBoth options have their respective advantages. Secured chains offer two unique features: easy bootstrapping for those with limited resources and enhanced security on a layer separate from the mainnet. New crypto protocols without the resources to bootstrap security or enterprises looking to enhance transaction throughput on their own network may want to utilize the Edge framework to build secured chains. Meanwhile, sidechains require their own validator set, making it a good fit for enterprises looking to maximize independence or for community-based networks capable of supporting their own decentralized blockchain.\n\nSource: Polygon Edge\n\nThe diagram above represents the various components of the development framework. Each component, including known modules such as blockchains and consensus, and more obscure modules, such as\u00a0 Libp2p, GPRC, and JSON RPC, represents functions within the technical architecture. Developers are able to modify these modules to suit their needs, combining them like building blocks to make up the network. Polygon Edge supports both Proof-of-Stake and Proof-of-Authority as consensus algorithms.\n\nRollout of Edge for the standalone chain framework began in May 2021. The second iteration of the framework for secured chains is expected to follow shortly. Aligning closely with Polygon\u2019s thesis of a more advanced multi-chain Ethereum ecosystem, products such as Polygon Edge help solve a pressing need regarding L2 communication and ease of project deployment.\n\nPolygon Corporate Funds\n\nAs mentioned prior, the company also actively encourages protocols to use Polygon-enabled networks. Direct mandates include investing in founder teams, providing support for project token economics, staking, governance, and leveraging the Polygon network for marketing initiatives.\n\nEcosystem Partnerships\n\nOne strategic endeavor is to partner with active venture investors within the crypto community. Polygon maintains relationships with four organizations, though the company does not have the decision-making authority to invest capital.\n\nPolygon x Wintermute: Partnership with a $20 million fund to support project liquidity, business development, and token exchange listing purposes\nPolygon x 776: Collaboration with a $200 million general-purpose fund investing in Web3 and other crypto-native applications\nPolygon x Outlier Ventures: Polygon-based accelerator designed to foster mentorship and collaboration with the venture team at Outlier Ventures\nPolygon x StableNode: Partnership with a blockchain node management operator experienced in providing hands-on services such as staking, governance, and more\n\nPolygon Ecosystem Fund\n\nThe company\u2019s final corporate development team is its Ecosystem Fund. Unlike the partnerships mentioned above, the Ecosystem Fund is Polygon\u2019s own internal investment fund. Capital allocation decisions are strategically designed to boost the adoption of Polygon\u2019s blockchains.\n\nThe $100 million Ecosystem Fund manages all of Polygon\u2019s corporate investments. This includes joint investments with the Polygon Studios team below. So far, $15 million from the fund has been deployed across 50 global projects. The team is still actively searching for investment opportunities.\n\nPolygon Studios\n\nIn summer 2021, Polygon launched Polygon Studios, its internal unit aimed at drawing existing gamers toward blockchain games. Polygon Studios collaborates with ambitious NFT projects and marketplaces to scale user bases across a low-cost platform.\n\nMore than 100,000 gamers and over 500 apps are already onboarded. The team has announced partnerships with both crypto-native projects such as The Sandbox, Decentraland, and OpenSea, along with traditional entertainment brands such as DraftKings, Electronic Arts, and Atari. Capital from the Ecosystem Fund will also be used to make investments in projects beneficial to the company\u2019s NFT/gaming initiatives.\n\nTasked with heading Polygon Studios is Ryan Wyatt, who left his previous role at Google where he served as both the Head of Gaming Partnerships at Google and Head of Gaming at YouTube. Wyatt started his career in professional esports as a gaming commentator, making him uniquely qualified to lead the Polygon Studios effort.\n\nLeadership within the Community\n\nAside from its prominent reputation in the global crypto community, it\u2019s important to also focus on Polygon\u2019s role in the crypto community in India. The company\u2019s status as an Indian-based startup unicorn has helped validate the industry in the eyes of skeptics and encouraged more of the nation\u2019s youth to experiment with crypto. This form of leadership by example has been particularly beneficial to the country\u2019s burgeoning ecosystem given the Indian government\u2019s hot-cold relationship with the industry.\n\nPolygon has also taken an active role in investing in its community. Polygon frequently sponsors, mentors, and judges hackathons in India. It was heavily involved with ETHIndia. In addition, the company also partners with students by offering smart contract application engineering courses and working with blockchain clubs at several of the IIT institutions, IT Mumbai, and other select Indian universities.\n\nTo showcase where Polygon stands as a financial platform, we can benchmark the company\u2019s valuation against the largest Indian banks. By this methodology, Polygon would rank as the seventh-largest financial institution. Of course, there are some major caveats with this type of analysis. For one, Polygon doesn\u2019t offer direct financial services and operates more as a financial payments platform. Moreover, the startup\u2019s ecosystem includes indirect financial use cases such as NFTs and blockchain gaming. That said, this quick-and-easy comparison does highlight how rapidly Polygon has risen and the level of expectations investors have placed on the company moving forward.\n\nRoadmap\n\nMuch of the Polygon\u2019s team\u2019s focus for the upcoming year is corporate, not technological, which could signal how comfortable the team is with the state of its product suite. As each product continues to research, test, or launch its own scaling solution, more emphasis will be placed on finding the right partners and protocols to integrate into Polygon\u2019s network of offerings.\n\nIn public interviews, Polygon has expressed interest in reorganizing the company\u2019s team structure and expanding partnerships with crypto projects, particularly in the NFT and gaming sector. Headcount growth is also expected to continue with the goal of doubling the number of employees by the end of the year. Though the exact details of each team\u2019s organization are unknown, it\u2019s important to note Polygon wants to centralize key leadership while keeping the decentralized autonomy of each team.\n\nFor investors, one of the most exciting updates will be a token redesign. The current MATIC token is a legacy remnant of the old Matic business and works with Matic\u2019s network, Polygon PoS. The future token will have a new ticker and work across all Polygon products. Given what we know today, use cases may include staking to enhance security or selecting blockchain operators. Interestingly, the token will not be mandatory for all users, meaning it will not be necessary to buy, stake, or hold; for many users, it may just be something in the background. Although the timing is unclear, Bjelic has stated there is a desire to complete the token redesign sometime in 2022.\n\nConclusion\n\nThe next few years will be competitive for blockspace. Winners will be decided by determining which has the best ease of use, transaction speed, and transaction cost. This next stage of blockchain evolution means core infrastructure is now more important than ever. Users around the world need a network capable of rivaling Visa and Mastercard, the type of processing that can handle thousands of transactions per second.\n\nPolygon is striving to meet the demand with its suite of rollup solutions. Its aggressive 2021 growth strategy, by acquiring and onboarding different ZK projects, now ensures Polygon\u2019s portfolio offers something for everyone. If a user is wanting faster or more private transactions, there\u2019s Hermez, Miden, or Zero; if an enterprise is seeking privacy, there\u2019s Nightfall; and if a developer is looking for scaling solutions, Avail reduces the burden of data availability while Edge helps build new blockchains entirely.\n\nThe suite of products gives Polygon a significant moat. As long as it can draw projects to its platform, Polygon will continue to remain a big industry participant for years to come.\n\nThis report was commissioned by Polygon, a member of Protocol Services. All content was produced independently by the author(s) and does not necessarily reflect the opinions of Messari, Inc. or the organization that requested the report. Paid membership in the Hub does not influence editorial decision or content. Author(s) may hold cryptocurrencies named in this report and each author is subject to Messari\u2019s Code of Conduct and Insider Trading Policy. Additionally, employees are required to disclose their holdings, which is updated monthly and published <a href=\"https://www.google.com/url?q=https://messari.io/article/messari-employee-holdings-policy-and-disclosures&source=gmail-imap&ust=1647457925000000&usg=AOvVaw0jwd9uUO4e2D2TzMmDVmb\">here.</a> Crypto projects can commission independent research through Messari Protocol Services. For more details or to join the program, contact hub@messari.io. This report is meant for informational purposes only. It is not meant to serve as investment advice. You should conduct your own research, and consult an independent financial, tax, or legal advisor before making any investment decisions. Past performance of any asset is not indicative of future results. Please see our terms of use for more information._", "references": [{"name": "Jerry Sun", "url": ""}], "published_at": "2022-03-23T14:30:00Z", "author": {"name": "Jerry Sun"}, "tags": ["Layer-2"], "url": "https://messari.io/article/polygon-a-multi-sided-approach-to-zk-scaling"}, {"id": "845a0ab9-2ea1-40eb-a277-b7b717d4ec95", "title": "State of Avalanche Q4 Analyst Call Transcript", "content": "If you would like to view the full recording of the live Crowdcast event, you can find it on our Youtube channel. You can also read the full Quarterly Report by Chase Devens and James Trautman <a href=\"https://messari.io/article/state-of-avalanche-q4-2021\">here</a>.\n\nRyan Selkis (0:10): Alright we should be live now. Welcome everyone, thank you for joining us. We've got a ton of folks here for this interactive quarterly update on Avalanche. Our team has spent quite a bit of time working with some of the top DeFi, Layer 1, other protocols, and communities in the past couple of months coming up with a robust quarterly updating framework and we're really excited about the three folks from Ava Labs here to participate in this discussion today. I should note as we kick off that this quarterly report that was built by Messari was authored entirely by the two analysts on this call, James and Chase; they're going to be leading the discussion here. What I think has been really powerful about these sessions so far is it shows just how open and transparent these emerging economies are in that an independent team with no direct affiliation or connection to the underlying protocol is able to come in and and with about a month's worth of work build a really robust framework for making sure that we monitor KPI's, ecosystem developments, governance updates, and a whole slate of material bits of information on a quarterly basis going forward. We're excited to work with the Avalanche community on this. We\u2019re excited to work with the Ava Labs team on coloring in some of the details that these two [Chase and James] uncovered during their analysis. Most importantly, we want to use these [quarterly updates] as a forum for people to ask our analyst team questions about the reports but also be able to interface with some of the leaders within the Avalanche community. Today, as has been typical in some of the initial kickoff calls we have, folks from Ava Labs [are joining us] which is certainly one of the central parties that's been doing great work in advancing the Avalanche ecosystem. In the future we'll also pull in folks from other parts of the community and other, either corporate, or non-corporate entities or just other meaningful individual contributors to the project as well. So, with that said, hopefully the context is in place; as usual, this is not investment advice and do your own research yada-yada but that's why we're here. We're going to try to let Chase and James take it and walk through their analysis, the update on the Avalanche products, and project. We\u2019ll make sure that we have plenty of time to learn more about what's ahead and ask any clarifying questions in the quarter behind; take it away guys.\n\n  \nChase Devens (2:51): Alright, thank you Selkis, so I just dropped the link to this report into the chat if you guys want to follow along. If you guys have been following some of the quarterly reports that Massari has been publishing recently you'll notice that it's mostly Web3 or DeFi related. This Avalanche report was actually our first stab at tackling what a quarterly report for a Layer 1 network could look like. The way that we decided to break it [the report] out is into these three buckets \u2014network usage ecosystem, developer activity and staking and decentralization\u2014before we dive into all the specifics of those I think it would be really great if one of the team members of Ava Labs could talk about what differentiates Avalanche from a consensus perspective from other smart-contract networks and how it fits into this overall Layer 1 game that's being played.\n\n  \nLydia Chiu (3:59): Nick, you want to touch on the consensus piece?\n\n  \nNick Mussallem (4:11): I think there's three areas that we focus on at the core technology layer that are all heavily driven by the consensus algorithm. The first one is speed; so time to finality, and that is really the underlying driver that the consensus algorithm allows us to achieve. It's very fast, it's using an entirely new type of consensus algorithm that was invented by Team Rocket. The second piece is the ability to scale, we'll talk a little bit about this later today but that gets into the concept of subnets and we\u2019re heavily focused on going forward. The last one is just \u2018what is the cost to transact\u2019 so we're constantly making changes to make sure that the network is affordable for projects to build on and for people to transact on.\n\n  \nChase Devens (5:11): Awesome, appreciated.\n\n  \nJohn Nahas (5:12): I\u2019ll tack-on to what Nick said real quick, you know, at the cornerstone of everything that we do and that we've been doing is all dependent on the Avalanche consensus, right, the third ever novel consensus after classical, Nakamoto. Everyone's kind of made edits to those in the past and optimized a little bit, but no one's really brought to the market a new consensus algorithm that actually allows us to scale at the level that you've seen Avalanche do. And what I believe we are going to focus on this call today, and look to the future is Q4 really focused on the EVM, the c-chain that we have, right, that enables Web3, DeFi, NFTs and everything of the sort but that's just the initial thing. The first focus is to show how an EVM can scale and now going forward we'll see how we can continue to build on that through everything else.\n\n  \nChase Devens (6:04): Awesome, really good background for our audience here, I want to go back to something that Nick touched on as we dive into the network usage data. Going through the report we saw Q4 was just a huge explosion in network activity. Active addresses were up to about 70,000 per day, we had transaction activity reaching about 40% of Ethereums. Maybe talk a little bit about the gas spikes that you guys saw in late November, early December and Avalanch\u2019s approach to keeping those down, but also using them as a key source of revenue for the network.\n\n  \nNick Mussallem (6:54): Yeah, I think there's two good points here; one is that gas fees do ensure liveliness and so they were set fixed. When we launched on the c-chain they were 225 so the first thing we did was to drop those dramatically so that the floor now is is at 25 and then there was an implementation on something called dynamic fees as a part of the Apricot releases and so dynamic fees really allows the network to breathe so as there's more congestion or more demand you'll start to see those fees creep up. We keep tweaking on that and keep improving it so that we can keep scaling while managing to keep the fees lower. The fees are actually dramatically lower from when we had that congestion; that's really when we put a lot of effort into making sure that it could scale and that the fees would remain low but we would also have the guarantee of liveness at the same time.\n\n  \nJohn Nahas (7:59): Of course, there were subsequent releases such as Snowman Plus Plus and many other network upgrades. To Nick's point, the ultimate goal here is to focus on liveliness; to ensure that the network is coming along, fees could spike up and down. The fact that the network continues to come along despite these moments of very high network usage has been a testament to the teams\u2019 architecture and follow-up of updates as we go on.\n\n  \nChase Devens (8:27): Awesome, in terms of the largest catalysts to this growth in network adoption do you guys see anything beyond the Avalanche Rush liquidity mining program as large sparks for why everyone's starting to migrate over the network.\n\n  \nJohn Nahas (8:45): So Avalanche Rush definitely was a huge catalyst, but I think previous to that, the team here on this call, as well as the broader team took a step back during those two\u2013three months where things were somewhat slow to strategize as to the next steps. Anybody can throw money at a petty issue, anyone can incentivize but if the necessary cornerstone pieces aren't there, once that liquidity is deployed, and once those users come to utilize it, it's really not going to make that much of a difference. We've seen this across the board, money comes and goes, the first piece of this that I think was the most important and that became a meme is the Avalanche bridge. I think you saw \u2018Good morning, good bridging\u2019; that's a testament to Nick and the product team for building what we believe to be the fastest, best, and easiest bridge to use. Right on the heels of announcing [Avalanche] Rush that bridge was live and it was ready so even before the Rush incentives were deployed we saw exponential growth, usage, and people coming over the bridge because they wanted to come and check it out. That bridge gave people who previously were not into the Avalanche, weren't keeping up, or were wondering what was going on but didn't have as many on-ramps to really jump into the ecosystem and this is previous to c-chain exchange listings. Previous to listings on global exchanges where focused on the x-chain, c-chain integrations were in process such as Coinbase and other major exchanges but the first on-ramp for a lot of people into our DeFi ecosystem was that bridge. That was really kind of the front door and the welcome for people to come in once they came in. Before they got incentives they started to realize the ease of use of the Avalanche platform. What I see on Crypto Twitter is that Avalanche just works; it's faster, it's cheaper, the UI, UX, or just interacting with the network is there and we captured people's attention and it became a fun place to do DeFi again. On top of that the Rush rewards were a boost as well as the exponential amount of partnerships and different applications and platforms that we brought on really fueled this thing to take off.\n\n  \nLydia Chiu (11:11): Just to add to that, if it isn't clear already that the team is very focused on user experience it's something that we spend a lot of time on. Also, we listen to the community to figure out what some pain points are. I think going forward you'll see what that focus looks like when implemented and we'll have new products that make it easy for users to not just enter the DeFi ecosystem, but the Avalanche ecosystem as a whole. There are going to be other sectors that take off on the platform. We're going to see everything grow and we're going to make sure that people just have an easier time getting into crypto, not just the crypto native folks bridging onto Avalanche; we're trying to focus on mainstream adoption as well.\n\n  \nJohn Nahas (11:56): Yeah, to add to Lydia's point, even before the bridge happened, the very core engineering team had to make sure that everything that was underneath it could scale and so the bridge launched in August but that time that John talked about between January and July there was a heavy emphasis in making sure that the underlying platform was going to be able to take on the amount of demand that we that we expected and they really knew that.\n\n  \nChase Devens (12:28): Awesome. Going into the DeFi ecosystem a little bit more here. When I was looking through the data I thought it was really interesting that the TVL dominance of Avalanche was the fastest growing out of any network over the quarter; a lot of people will say that can be attributed to the rising prices but if you strip all that data back out there was just a huge growth in activity that was coming into the network. I think the market cap only grew about 50% relative to 800% in TVL. I think it was early October that Curve and Aave launched onto the network. Do you guys think that these launches were what catalyzed the rest of DeFi's growth on the chain, or do you think it was something else? Maybe a better developer experience that may have brought people over?\n\n  \nJohn Nahas (13:40): So it's a mix of all of those things. To the earlier point, once the bridge brought people over, people started using the platform and interacting with native apps. We had a rich and growing native community of applications which got a great boost from all the new users but we had a user base and we added [to] it. There's a three prong situation here; first and foremost, bringing over those Ethereum blue chips like Aave and Curve did two things; one, they brought a lot of new users. People that hadn't yet come now came because there's credibility, there's a track record, there's a history with Aave and Curve. There's a credibility that they [bluechips] impart so people come with that, and with that you start to see fellow Ethereum applications follow suit. On top of those initial guides you started to see a lot of deployments. First you saw the Ethereum blue chips come, second you saw the rest of the Ethereum applications come and deploy on us, or pour over into play on us but what we've seen in a second stage which has been really interesting like Alpha Labs which has Alpha Hemorrha decided to launch their new product Alpha X on Avalanche first. Third, what we're seeing is that native community development of applications and the number of developers has grown significantly. What you're seeing is a lot of devs that have created really cool and innovative products that simply can't launch on Ethereum or other chains because economically it doesn't make sense with the cost of gas or the times of [block] finality. The speed of Avalanche, the lower fees, and the ease of use, really makes it an ideal place for a lot of these innovative applications that have been in development or been in the back of people's minds to find a new home and to develop and work within native Avalanche applications with the Ethereum blue chips. It kind of all built upon itself by bringing people, developers, applications into a great mix that just benefited from everything. To your point, you know, yes we did see a tremendous rise in TVL and of course there is a rising price but as we've seen recently, prices have been going down across the board. We're still holding our place so if anything daily active users, monthly active users, active wallets continue to grow so at the end of the quarter I believe you mentioned we have 40% of Ethereum's daily transactions; I think we're clocking in anywhere from 70% to 80% on certain days if not even higher. Over the past few weeks we're only seeing continued growth and we're really excited for the pipeline of things that are going to come.\n\n  \nJohn Nahas (16:24): One other quick point is one of these metrics that the product team closely tracks is inflows across the bridge versus outflows; what that tells us is there is a compelling use case once they cross the bridge. People are finding the ability to use; it's three across to one back right now and that fluctuates, it gets up to four but that's telling us, okay, there is a compelling use case on the other side. People are finding that the time to finality, and the low fees are worth sticking around for and then they're discovering other avenues onto it. Maybe they'll start with Aave and Curve but then they discover a Penguin, or a Trader Joe, or a Platypus so there's all that. There's a lot of these native applications that are popping up that are also starting to create their own market share and really do innovative things.\n\n  \nLydia Chiu (17:20): Yeah and one of the other metrics I like to look at personally is the daily active addresses relative to monthly active addresses because you're talking about engagement at that point. We've been growing exponentially in Q4 and December or January, we're at that 800,000 [monthly addresses] mark but the daily active addresses really shows how many people are creating addresses and using the platform every day and that ratio has held constant, the average users per day. I think that's really promising because folks aren't just bridging across and then doing one transaction and not coming back; I think it shows that people are staying, and they're actively participating in the ecosystem.\n\n  \nJohn Nahas (18:07): To Nick\u2019s point real quick on the bridge outflows I think an important thing to keep in mind is up until a point, the only way you could get out of the ecosystem is to go through a centralized exchange. If you want to go into dollars you\u2019d have to go through Avalanche or to bring ETH back over [the bridge], wrap the ETH, and go out that way. Primarily, with USDT and USDC we have wrapped bridge versions right so USDC.E, USDT.E. With the integration of native USDC and USDT on Avalanche, we see exchanges start to support those native stablecoins. You'll start to see less outflows or we anticipate seeing less outflows from the bridge from Avalanche back to Ethereum so that people could bridge their USDC and USDT back to an exchange or to an Nexo or to a Celsius or whatever it is that they might be kind of holding their stables you'll be they'll be able to go straight from the Avalanche ecosystem into an exchange. We anticipate that number to start going down.\n\n  \nChase Devens (19:13): Awesome, um so we've got about like 10 more minutes to talk about the metrics and activity from Q4 before I turn it over to James to focus more on some of the qualitative events and drivers of this growth. We have a question though from Gucci in the chat; they say, \u201cHow will Avalanche plan to keep its user base once Avalanche Rush incentives are depleted or other protocols are offering better incentives?\u201d; and follow-up to that is \u201cHow might subnets play a role in terms of building out the Avalanche ecosystem?\u201d. One additional question from me is: could you also touch on you know how long you guys are planning to have the Avalanche Rush liquidity mining campaign run for?\n\n  \nJohn Nahas (20:03): So, Avalanche Rush was announced for $180 million; I don't have exactly the amount that's been deployed to date but there's still a significant amount left. It's not, as everybody here has noticed, just a dump the money in and see what happens [kind of] approach. We've been very methodical with who we want to support, what projects we want to support in a thoughtful way. Avalanche Rush is still ongoing and we anticipate it going through the rest of this quarter, if not longer. Credit to Gucci for keeping an eye on what's going on in the ecosystem because he definitely can start to see the rumblings of where this is going to go next. Rush was a great program, there are other programs that can come after Rush. We're working through a bunch of that on our end. Without giving out too much there's a lot happening. I think you're already starting to see rumblings around subnets: the ability for the network to continually scale horizontally, GameFi, a million other applications that are in process right now on that side.\n\n  \nLydia Chiu (21:04): In addition to the Rush liquidity mining program there are other pieces in the ecosystem to support growth of projects coming onboard. There is also Blizzard, the ecosystem fund. The funds\u2019 mandate is to promote and accelerate growth and innovation on Avalanche and that means encouraging native projects to build and developers to come here and build out primitives that we're missing. At the end of the day, it's really about having a more holistic approach to the ecosystem and having pieces that keep users here. Users want things to do, that's what drives transactions, that's what drives the activity. If we have a robust ecosystem with the right apps and protocols here then we're going to put all of our resources to promote that growth, that's what's important.\n\n  \nChase Devens (22:02): Got it, so the last section that I want to touch on with you guys is the aspect of decentralization and that always seems to be one of the largest debates on these smart-contract platforms. Everyone has very different definitions of what decentralization is. I'd be curious to get your take on how you would quantify decentralization and how you believe that Avalanche is able to scale while maintaining step-decentralization.\n\n  \nNick Mussallem (22:44): So, I can jump in here and then Lydia, John you can jump in. The number of validators currently running that are supporting the network is one of the key metrics we look at; it's not like there's 10, 15, or 21; we're well over a thousand at this point. The number [of validators] keeps growing so that's a primary metric. The other thing that we look at and how we plan to scale it is through the growth and launching of subnets. Subnets essentially give us theoretically infinite scale. You can take aspects that are currently running on the mainnet and run them on a subnet and have everything interact and interoperate. Subnets are its own chain that's handling that scale that also has the ability to write its own rules around gas fees, emissions, validator rules, who gets to validate, who doesn't, what the native token is so; it really gives a lot of flexibility to be able to scale the network up, you're starting to see that specifically. I think John mentioned GameFi which has different tokenomics and different needs than just what is on the mainnet. They're starting to build these custom subnets to be able to have their own chain that has ownership with the ability to control the scalability of that at the same time and how they're tuning and configuring it.\n\n  \nJohn Nahas (24:05): As of today I just checked, we're at 1,232 validators. The minimum stake there is 2000 a box so there is a future where that threshold could be potentially lowered in which case you can see it continue to explode the number of validators. From the metrics that I see, the Nakamoto coefficient is probably the best indicator of decentralization. From what I saw last week, we have the highest score amongst the other proof of stake chains. I think we have the highest score amongst the rest of the competition in that regard.\n\n  \nChase Devens (24:44): I was looking through the data, it's not like the Nakamoto [coefficient] fluctuates heavily despite you guys averaging in the high 20s low 30s; overall for network security that's really strong. For those of you who might not know what the Nakamoto coefficient is, it's basically a measure of the minimum number of validators that would need to be compromised in order to collude against the network. A lot of these chains have smaller validator groups such as Binance Smartchain, it's only just a small handful that you can count on one hand. You would need to get almost 30 [validators] here. With that, James I will turn it over to you to go into depth more on some of the events and catalysts that really drove this growth that we've been talking about here.\n\n  \nJames Trautman (25:51): Yeah definitely, thanks! First of all, just listening for the first 30 minutes here is all very insightful. Taking a quick step back and thinking about the work that Chase and I did over the last quarter and what we're planning to do going forward. This starts with data driven insights. We start with looking at what the data is telling us and what we basically just discussed here is high growth in every metric that we were evaluating, all the way from number of addresses [to] daily transactions. Some fundamental activity going on in the network. Of course, TVL and revenue to the protocol was growing so once we see that, it begs the question of well what's the drive or why is that right? I think your conversation there touched on a couple of different things and there is really no one single reason or answer but thinking back to what you all just discussed; obviously you were prepared for it before it happened, before this growth occurred. As you were developing the core platform improvements and upgrades through Apricot and then the launch of the bridge led itself up to a perfect timing to just let the floodgates open. We were working through that again with incentives and the Rush program, so as we were looking at it, it's like okay \u201cWell yeah of course the incentive program has a bit to do with it and the bridge has a bit to do with it.\u201d. You still kind of wonder like okay well why so many addresses and why so many more developers developing and deploying unique contracts? Why are there more developers on the core platform? I think that gets back to some of the things that you expressed about user experience. There was a lot for us to try to figure out and find out, like what were the key drivers? It's not as easy as it sounds when there's so much going on, but what I wanted to do is take a little bit of a step back and look at some more macro things that are going on that maybe are showing up in the data but maybe aren't yet. I'd like to talk a little bit about that because we were seeing household names come across the headlines. I collected Tops baseball cards when I was a kid. I still have tons of cardboard boxes with cardboard little cards in them from Tops, so I know that name. When I see that name I get excited, and obviously in partnership with Major League Baseball, Tops is launching an NFT collection of collectibles. What other names, Deloitte, Andretti Formula E, Mastercard, there are so many that the New York Islanders and Banksy came up with this fractionalized NFT of a well-known Banksy piece. There was a mural that formed as an NFT, that's in Chicago where Chase is right now. So, it asks the question of\u00a0 \u201cWhy Avalanche?\u201d. Why launch a one-to-one NFT of Kanye West on Avalanche versus any other chain? Those questions are still out there for us. I'm curious as to what you think about all of that; which out of all of the initiatives and all the partnerships that we saw occur over Q4 actually influence the data? Perhaps they will in the future, which ones are you guys most excited about, and which initiatives that we know about are you the most excited about and see as the greatest opportunity to grow the ecosystem?\n\n  \nJohn Nahas (30:22): So I'll start real quick, first and foremost, credit is due to Ethereum and the Ethereum community. The growth that we've seen happens to be the EVM. Other platforms are using other smart-contract layers. We chose EVM because to us it's the standard smart-contract platform. The benefit that we've had with the Avalanche consensus of course; this is what was conveyed to all of our partners and at a point it's not taking our word for it, it's go and try it for yourself. When people wanted to do things but didn't want insanely high fees to mint NFTs, for instance, on Ethereum but wanted an EVM compatible option, they came to us. We work hand in hand with our products; we're not just a shop that says come build on us and here's some support in some way. Whether it's Nick working hand-in-hand with projects, Lydia working with projects, myself and the entire business development and product marketing teams, we truly treat our partners that are building on us or want to work with us as part of this Avalanche community. When Topps says \u201cHow do we take trading cards into the next century?\u201d, this is a way to do so; so we work with these guys, but on top of the familiarity of Ethereum. The speed and the cost are a big item that's top of mind for everybody, of course, is the environmental impact of blockchain. Today actually of all days we have a report that just went live. Ava Labs commissioned the Cryptocarbon ratings institute; this is Uli Gandalf and Ahristian Stoll from MIT and the University of Technical Institute of Munich to do a study on the carbon footprint of Avalanche in addition to proof-of-stake chains as a whole versus proof-of-work. Bitcoin, I believe, is several million U.S. households worth of carbon, Ethereum's about one and a half million. Some of our competitors in the proof-of-stake chain\u2014and to highlight proof-of-stake, of course, we're in a completely different universe, orders of magnitude less. I think Solana is around a thousand U.S. households, others are like in the high hundreds. Avalanche as a chain, the entirety of which utilizes 46 U.S. households worth of carbon in a year; that is 280 metric tons of which we bought 560 to offset so we're technically carbon negative. We've been working with this team, they did a complete climate controlled study, the report is live today. I urge everybody to go and check [it] out, this [report] is from climate scientists and some of the foremost scholars in this space. Speed matters, cost matters, but sustainability also matters, so when it comes to the sustainability of NFTs that's why you see us growing the licensed product side. Whether it's Tops or Orange Comet that had the Islanders and other NHL properties or the team over at Particle that decided to do a Banksy or all the other artists that we're speaking to who want to do NFTs, it doesn't fit in their ethos to do it in an unsustainable way. The sustainability angle has been a key priority for us and we've been driving that too; on top of all that stuff I think to your point there's also the big names that bring credibility. The partnership with Deloitte to build products on Avalanche, the start path inclusion of Ava Labs with Mastercard. These are things that bring not just users, they bring attention not just from the daily users or the DeFi users, but from the household retail investors from several other enterprises that look for a solution that's familiar to them like Ethereum but takes it a step forward. Avalanche does bring all the things of what a third generation blockchain should be.\n\n  \nNick Mussallem (34:28): I can speak to a few other items here as well. There are other items around that have been very compelling for us. The Deloitte alliance, you saw that come out; you mentioned it and there's been questions like how deep is that alliance? What's really happening, are they building? Yeah they're building, they've launched their first product, it's called Close As You Go; it helps disaster recovery victims, counties, municipalities, cities to go through the process much more quickly to get the assistance they need. That product is live and it's just taking that further because as you start to get into subnets, they have a very sharp technical team headed by Peter Mueller over there who's looking at these use cases and saying okay how can we use subnets? How can we use the semi-public or private subnets in order to meet these government use cases in order to streamline operations at those levels? We keep working through these, we work very closely with them [Peter and team] in order to try to push new use cases out. This all takes a while, this is a lot of new technology but we very much value that relationship and we are very engaged in order to make the subnet use cases work for what their business use cases are as they go to apply them to their clients.\n\n  \nLydia Chiu (35:58): I just wanted, highlight an example of the importance of sustainability and environmental impact. That funny little anecdote, over at Blizzard we speak to a lot of different projects and a lot of the new projects that are popping up are folks that want to do NFT drops with different celebrities\u2014different well-known figures. One of the points that they highlighted today was that these guys can get canceled for being environmentally wasteful. lt's completely in their imperative to pick a chain that is green or greener at least out of the other chains out there that they can choose from; I thought that was a funny anecdote that was timely as well.\n\n  \nJames Trautman (36:50): Yeah, for sure, I was just thinking back to what Nick was saying about the Deloitte initiative. Early on when I was getting more involved in this space I thought \u201cWow, this is a great solution for disaster relief\u201d. We've unfortunately experienced many of those over time. It's problematic, the inefficiencies of any level of government to gather relief is just ridiculous. It's encouraging to see a big four accounting firm, and really, a leader in traditional finance if you want to call it that but in any case spearheading the ability to make that more efficient. When that [Deloitte partnership] came across, I was like \u201cGood for Deloitte, good for Avalanche\u201d; I suspect that will be a relationship that will continue to grow and evolve as we look ahead.\n\n  \nNick Mussallem (38:07): James, I think it's unique too because it's not around cryptocurrency in any way; it's really tackling a workflow and making that workflow more efficient and then trying to reduce the government clawbacks. The processes are extremely complicated and they're complicated for a reason but this makes it a lot easier to go through, everybody's on the same page, everything's on chain. You can see where you are in the process and you can see what's next. If there's any question of how this certain piece happened and the answer who you know, you get into the he said, she said, then you get into clawbacks\u2014that costs everybody money. It's not an efficient process so they're using the blockchain to create efficient solutions for governments that aren't necessarily finance related and don't have the use of cryptocurrencies, that's very unique.\n\nJohn Nahas (38:53): One last thing, you made a good point. This is great for Deloitte, it's massive for Avalanche but more so than that, it's great for the broader blockchain crypto community and economy. It's a validation for the technology and for all the FUD that we see out there about crypto this, and blockchain that, it's unsustainable every day. There's a new narrative that they try to smear or hold us back as an industry; I think this is validation at one of the highest levels, especially when it gets into municipalities, states, and the federal level. Blockchain technology is here to be used and it's here to stay. There's multiple use cases, aside wherever Ethereum is at, the use cases are here, the growth is here, and we're continuing to grow and build not just on Avalanche but with the broader ecosystem as well.\n\n  \nJames Trautman (39:48): Got it, yeah again I think some of this Deloitte initiative and some of these other partnerships and events that occurred, there\u2019s a lot here. In the report we covered like 24 different major events all the way from major exchange listings which I think is important; it's healthy for the ecosystem but not necessarily going to drive the fundamental activity that we can see in the metric like number of addresses perhaps. It goes back to the developer growth and revenue to the network, and TVL. In any case, a lot of what occurred is showing up in the data, but a lot hasn't yet. I think Deloitte is probably an example of that and some of these other initiatives; another one that stuck out to me was Blizzard. We think about potential catalysts or sustainability, if the incentive program exhausts itself at some point over the next quarter, there are other initiatives in the works. One that stuck out to me was Blizzard and I know you spoke about it briefly, could you just tell us a little bit about how that came to be? Like, what it is and what it's aimed at and how you think it will go going forward? What's the strategy when it comes to the mandates you touched on? I was just hoping you could expand on that a little bit more when it comes to Blizzard.\n\n  \nLydia Chiu (41:29): Yeah happy too, the team looked at the different ways that the ecosystem is being supported and one of the things it was missing was an ecosystem fund. An ecosystem fund is a very vital role because in terms of supporting developer growth, oftentimes what you need to get something started is capital. We felt it was appropriate to fill in one of the gaps and the mandate for Blizzard is to accelerate the digitization of the world's assets and what that means is helping people bring things online, and using Avalanche obviously. That covers DeFi, gaming, NFTs\u2014anything under the Web3 umbrella for member networks and DAOs. The mandate is to also deploy capital quickly so that the ecosystem is growing and growing very quickly. Right now we obviously need to support that growth with capital in high quality teams and projects. Over time I think we'll see the thesis at Blizzard evolve. The fund is still very young; it closed and launched in November. Right now we're seeing a lot of DeFi activity, we're definitely seeing a lot more gaming, a lot of infrastructure as well. In the near future we're definitely excited about how the next vertical on Avalanche is going to grow. It looks like gaming to me and then obviously infrastructure will enable cross-chain communication, across subnet communication potentially just interoperability and really taking advantage of the composability of blockchain.\n\n  \nJames Trautman (43:22): Makes sense, yeah it's also something that we'll be keeping an eye on over the next quarter. Come next quarter we can check-in on it and see how it's progressing. With so much activity this quarter I'd like to bring it back to the transaction activity in those momentary spikes of transaction fees; it's really interesting to think about. When we look at the visual of daily active transactions, the fees actually declined quite rapidly as transactions were increasing. At the all-time high of daily transactions we actually saw quite a decline in gas fees; that is a result of a couple of things but I'd like to hear a little bit more about the development of the core platform. I think that was heavily the reason for that decline\u2014as a result of an implementation of Apricot which I think was phase five point, you know, I can't remember the exact number. When we saw the unleashing of Apricot and updates is when we saw a decline; to me, that is some evidence of a solution actually working. Thinking ahead, there are certain initiatives that you guys have internally and on the development front. Outside of the partnerships and outside of building the ecosystem, what is top of mind for Ava Labs team and just the community as a whole when we think about what's next? I know, Nick, we've discussed this in the past, I think it's important to touch on because a lot of it does revolve around technical developments and solutions that just aren't there yet. What I'm getting at is again core development; subnets and governance. We have yet to see on-chain governance and I know that's going to be something that we can follow over the course of 2022. In summary, tell us a little bit about the solutions that were implemented and how that fits into the vision for 2022.\n\n  \nNick Mussallem (46:03): I could spend an entire hour just on this. There's so many cool things going on. First of all, hats off to our platform team; they do the Avalanche Go Node, they're the ones making all these changes and refining things at such a rapid pace. That team was set up by Patrick O'Grady, Steve, Dan, and Aaron. That's exactly right; they looked at what was happening and they knew they needed to tackle those three core areas. We needed to be fast, there needed to have fast time to finality, we needed to scale, and transaction costs needed to remain low. When those spikes happened, it actually was right at the end of a release cycle when they were working on dynamic fees; dynamic fees came out right after that\u2014it was just in time. We're trying to anticipate what is happening and then figure out where we need to focus these deep engineering resources. These [the engineering resources] are like the giant heads in the team, they got dynamic fees out, then got Snowman Plus Plus out which dealt with congestion which also made things much faster and reduced MEV on the chain so there's all this. Like you said there's five phases to Apricot, I can go through all five of them, and then there's all these really deep things in them which is, you know, Snowman Plus Plus and looking at block based fees and changing the way blocks are structured and how the state management behind this growing chain is handled. To keep it at a high level, they're just looking at how to do exactly that, which is how to optimize performance and how to make cross-chain interoperability work better because it does become more important as we get into subnets. This last phase of Apricot has [been] pruning a lot around state management because it is getting quite big. There's some fast sink-in there and they're really getting into making the x-chain and optimizing that. As it [x-chain] becomes a bigger part of the ecosystem will get more usage and then after that it's just subnets. At this deep tech level you've seen Patrick's been releasing spaces which was an example for developers to reference. The way we look at it, we organize our roadmap into four core areas; at the back of it is that core tech one, then and as you go up a layer from that you get into the core properties, and the core properties are those things that allow users to leverage this technology. While the platform engineering team is deep in the weeds there's another team that's just focusing on how does the user best interact with that, and that's when you start to get into the wallets and their various incarnations, bridges, the explorer. There's a ton to focus on that right now, and you will see multiple releases along those lines of creating a better core properties experience. We don't call it a wallet experience because what we're doing is we're taking all the aspects of these core properties and combining them into this curated experience to try to abstract a lot of the technology away. We don't want people to think \u201cOh hey I'm using blockchain right now!\u201d, we want them to think \u201cI'm trying to do \u2018x\u2019 and \u2018y\u2019 is helping me do that.\u201d. And to create an experience that allows them to see you shouldn't have to go to an explorer to see your most recent transaction, it should just be right in your face as it's doing and you should be able to see the state of it sending, transferring, buying, swapping, all those things should be right at your fingertips rather than having to go to these disparate places. We're working on these curated experiences to keep the user interaction and the user workflows to something that people are familiar with rather than something that feels very foreign to them. As you go up a step from that we kind of get into the builder world like you said it, the developers and the builders and the people bringing projects to the platform are critical. We have a whole team focused on building modules that are going to help them get up to speed faster. If you're a game developer we want you to be able to focus on the game, not the blockchain infrastructure, not the tokenomics; you can focus on the game and you'll be able to pull from these modules to get to market more quickly than if you had to do all those things yourself. This goes into push button node deployment, push button validator, easy to access APIs; this list just keeps going on and on and then at the end of that there's the external projects themselves. We have a whole team that supports those projects and really makes sure that they do have questions, especially as they get into the usage of subnets and things that are now. We\u2019re there to help them along [on] the way to get to market quickly with the best product possible. Also, they're informing us on like; \u201cHey! Subnets need to be able to do this\u201d, we might be like \u201cOh we didn't really think of that!\u201d; so you know we add that into the backlog. We do these prioritizations and then we're churning out this work based on where the demand is.\n\n  \nJames Trautman (51:37): Excellent, just recapping that in different layers, I'll probably get them out of order, but as we're looking again looking ahead what's top of mind is the core platform, developing Go, and EVM development for chain optimization, making node launches faster building out infrastructure to make it easier for users to access the ecosystem development, subnets that will allow for builders to go to market quicker. I think you mentioned before segmenting off into, I like the use of the word, cultures; that's mentioned in the Blizzard announcement. That's maybe a shift from something like NFTs to gaming, like Lydia had mentioned maybe is an area of focus now as we look ahead. I think that kind of captures all the different pieces but what we'll probably pay attention to though is, like yeah, let's take a look at that over the next quarter and beyond; how is the user experience evolving and can we see that in the data that we continue to collect and evaluate. That's very interesting and very insightful, so I appreciate you guys sharing what's top of mind without diving too far into it and disclosing some of the proprietary things I\u2019m sure you're working on. I appreciate that, I think we're coming up on time here, any closing thoughts?\n\n  \nChase Devens (53:22): Selkis, did you have anything for them to add? Otherwise we can take a couple of these community questions.\n\n  \nRyan Selkis (53:28): This is great, I just want to thank you all again for joining. We do have five minutes left for a set of lightning round questions so we can funnel those. Chase you can pick from them and we'll see how many we can get in the next four minutes 30 seconds.\n\n  \nChase Devens (53:47): Awesome, I'm just going to go down the list from most upvotes, if you guys don't want to answer them just feel free to skip it. The first one is: \u201cAvalanche will compete against ETH (Ethereum) L2 and that could eventually cost less than one cent per transaction, what is Avalanche's scaling strategy against that? Subnets will likely cost more gas fees in comparison to ZK roll ups.\u201d.\n\n  \nJohn Nahas (54:13): Happy to go head to head with those once they're live and actually performing but we'll see what happens when they come.\n\n  \nNick Mussallem (54:25): Yeah I think L2s have their own set of challenges. We're not gonna get into all of the differences right now. In subnets you can actually set your own gas fees so you could keep them extremely low if you wanted to. If you're a builder you will be able to establish the subnet and you can set the rules on how that blockchain works. Now, there is we're going to advise you like \u201cHey, that's not going to be a very secure way of doing it.\u201d. The L2s are doing some very interesting things and a lot of this technology is still evolving as we go through so it's kind of like a wait and see. We just focus on what we think is very important and work with those goals.\n\n  \nJohn Nahas (55:10): I just think it's just apples and oranges. An L2 is an L2, Avalanche could be considered an L1 or even an L0, so I don't think there's really a head-to-head competition or comparison that is fair. In the future, stuff, well, I guess we'll wait and see when that comes.\n\n  \nNick Mussallem (55:28): lt relies on the L1, so, if the L1 has problems, the L2 is going to have problems. You can get into levels of technical details further than that but that's just one of the struggles. All the technologies have their own challenges and there's a lot of smart people trying to solve those problems. Again, I think we'll see how it plays out.\n\n  \nChase Devens (55:51): It's truly an industry of trade-offs, next question has to do with regulation and there's like three different questions in here so I guess broadly, \u201cHas Avalanche been working with regulators, how are you guys approaching that space?\u201d\n\n  \nNick Mussallem (56:17): The main thing here is our general counsel, Lee Schneider, he's fantastic. He's very connected into this space, he's one of the oldest attorneys in the business. He's formerly at EOS, and he's very connected into the regulatory circles. He's always paying attention [and] constantly reading and sending us updates and summaries with his team on what's happening. In the most recent reports an executive summary goes out to everybody; it says here's what's going on, here's what we're learning, and then they give a point of view on what's happening.There's certainly relationships behind that, too, I know Goon has specific relationships with regulators. We're always trying to kind of stay on the cusp of what's happening, it's definitely a changing landscape and so you know we just try to see what the latest information is and then make decisions based on that.\n\n  \nJohn Nahas (57:12): I think to the next point, whether on the legal side, or on the leadership side we're not a lot of people in this space. You're always playing catch up to what regulations come, if and when they do. We tend to kind of skate where we think the puck is going. We're always being proactive, looking ahead, wondering what if and what could happen, and positioning ourselves in a more compliant way in the future and working with regulators to educate them. I think Ryan does a great job of this daily on Twitter, whether they read it or not is a different question. Regulators for the most part love the sound bytes. Policy makers love the sound bytes but aren't aren't really putting in the time and effort to learn, so part of our job more than just being compliant or hoping to or kind of skating to where the pucks going in terms of compliance is also sitting down working with regulators, teaching them, and educating them, and to their credit some are very proactive and helpful, champions of the industry. Lydia.\n\n  \nLydia Chiu (58:18) We spend a lot of time thinking about how we can best educate and get the regulators to better understand all of the different use cases without throwing out a blanket statement saying that all cryptocurrencies are securities or all cryptocurrencies are commodities. There\u2019s obviously nuances so we definitely want to make sure that we're putting our best foot forward as representatives of the industry to provide them with all the resources that they need. Ultimately it comes down to working together to grow the space as opposed to trying to constrict the growth of blockchain as a whole just because we could have done a better job educating everyone.\n\n  \nChase Devens (59:04): Yeah, I love that point, all of us working together you know, it's not necessarily one network versus another network. We're all playing this game trying to get regulators to understand what all this is ultimately about; as Selkis always does on Twitter for us.\n\n  \nJohn Nahas (59:22): I want to jump on this because this is something that we try to focus on. Look within Crypto Twitter, we're all fiercely competitive, as we should be\u2014like steel sharpened steel, all that great stuff. We should compete against others and everything else but at a core level, you know, I like to use this analogy, it's probably not the best one but, were like mice feeding off little crumbs when there's an entire kitchen out there. What we're building, what all of us in this industry are doing, is trying to move this industry forward. If people are too busy fighting amongst themselves on the basic things that we need to work together on, as an industry to move forward, we're trying to go after the incumbents. We're trying to go after TradFi, we're trying to change the way that these systems are right now and make it more accessible, faster, cheaper, easier, less opaque, more transparent, every other buzzword you can set. If we're too busy saying \u201cNo, ETH. No, AVAX. No, BTC.\u201d. Whatever it is, we're fighting each other instead of at some level working together to move all of us forward against the way that we're trying to fight.\n\n  \nChase Devens (1:00:32): Totally, couldn't have said it better myself, it looks like we're at the top of the hour now. Thank you to everyone who tuned in, asked questions, and participated in the chat. I thought this was a really great conversation. If anyone has additional ideas or metrics that they'd like to see in future quarterly reports please feel free to pass them our way. Find us on Twitter, or go through the Messari website, we'd love to chat with you. Selkis, you got any parting words?\n\n  \nRyan Selkis (1:01:08): Thank you, and we'll do it again next quarter.\n\n  \nJohn Nahas (1:01:10): One thing real quick guys, we're having the Avalanche Barcelona summit 22nd to 29th, we'd love to have everybody on this call or all this cast join us in Barcelona to learn more about the Avalanche ecosystem, meet partners; Ryan, we'd love to have you up on stage, on a panel or something. This is an official invitation, we'll follow up with you and the rest of the team. We look forward to seeing you there too.\n\n  \nRyan Selkis (1:01:35_): I appreciate that and I'm sure we'll have at least some representation there. I basically just go where my team tells me, so we will see what the calendar looks like. A lot of great people on our team as you can see from this report and this call itself, thank you everyone and we'll be in touch soon, hope everybody enjoyed this latest quarterly call. If you have any comments on the report itself, the substance of this call, what would you do better, what we could automate and what we could ultimately do to scale this, we are all ears. We're early on in this beta for Massari's quarterly initiative, so thanks again everyone and really excited to run it back in April. Thanks so much, thanks everyone, everyone take care.", "references": [{"name": "Chase Devens", "url": ""}, {"name": "James Trautman", "url": ""}], "published_at": "2022-03-22T18:42:00Z", "author": {"name": "Chase Devens, James Trautman"}, "tags": ["Layer-1", "Quarterly-Reports"], "url": "https://messari.io/article/state-of-avalanche-q4-analyst-call-transcript"}, {"id": "04ef1aa0-ab20-4fc6-aae8-ea9ff300c2b6", "title": "State of Compound Q4 Analyst Call Transcript", "content": "If you would like to view the full recording of the live Crowdcast event, you can find it on our Youtube channel. You can also read the full Quarterly Report by Dustin Teander and Sami Kassab <a href=\"https://messari.io/article/state-of-compound-q4-2021\">here</a> or Ryan Watkins' Q3 Quarterly Report <a href=\"https://messari.io/article/state-of-compound-q3-2021\">here</a>.\n\nDustin Teander (00:04): All right, I think we\u2019re live! GM, GM. We're here for the Compound Q4 analyst call. If you're not familiar, we've done one, and this is our second iteration actually. We did one back in Q3 with Watkins and some other people. This is our second iteration. And, my name is Dustin, we have Sami here as well. We're both from Messari and we kind of co-authored the report together and we have Getty Hill here from GFX Labs, a really prominent member inside of the Compound community. But you know what we're going to be covering today is very similar to kind of if you've ever been familiar with equities calls and kind of Q4 results, that's what we're looking into. So it\u2019s the health of Compound, the metrics that matter and truly trying to peel back, just what went over Q4. Before we do all that, Getty, why don\u2019t you walk us through your background, GFX Labs and the role that you guys play within Compound?\n\n  \nGetty Hill (01:10): Yeah, sure thing. Hi everyone and thanks for having me here. A huge fan of Compound and have been dabbling in the protocol for a long time. My background comes from three years of trading and running delta neutral strategies at Grapefruit Trading and then myself and my buddy on the trading desk decided to leave and start GFX Labs and we've been involved in Compound for a very long time. Loved it when the protocol launched COMP tokens and gave this opportunity for individuals to come into the protocol and interact and improve the protocol and do fun things. So we've done things like update the price oracle, add new assets to the protocol, all sorts of fun things and just real big fans of money markets and Compound in general.\n\n  \nDustin Teander (01:53): Awesome man, all right let's just jump into it. Sammy, you want to give us the 30,000 foot level and give us the macro results?\n\n  \nSami Kassab (02:08): Yeah sure thing, let me just go ahead and share my screen here. Is everything all good, can you see it on your end?\n\n  \nDustin Teander (02:17): Yep.\n\n  \nSami Kassab (02:18): All right, so we're gonna go ahead, get things kicked off, and start with a little macro overview. So we know that Compound is a financial service business and this matters because they're influenced to an extent by the broader crypto market and the macro environment. There's a lot of action that went on in Q4: we saw two breakouts in bitcoin leading to new all-time highs and we also saw a breakout in total crypto market cap with a new all-time high there as well. Due to this, we saw Q4 ending with quarter ending highs in several key categories. So we'll step through this macro chart that's on the screen, walk through the key performance indicators as well as the financials, but one thing I want to preface with is just looking at this Q3 data. So at the end of Q3 there was a COMP distribution bug that was introduced into the protocol. We'll go into this deeper later on but why this matters is that\u2026 So this bug was introduced on the last day of Q3, so September 30th, and the bug caused some panic, caused some fear, there's some uncertainty, and so about $3 billion of closed loans and withdrawn deposits affected the Compound market. So the Q3 metrics came in basically a lot lower than what they would have been for example if that bug was introduced the next day. I just want everybody to keep that in mind while we're walking through this because when we look at the percent growth of Q4 it can seem high for what it really is. But if that's a little bit confusing, it's a lot easier to visualize once we go on to the next slides where you can see the liquidity and the capital moving throughout the Compound markets. So starting out with the outstanding loans for Q4 we're at about $6 billion, that's about 7.5% growth compared to Q3. Outstanding deposits were at $14.3 billion, pretty much stayed flat compared to Q3, very low growth there at 1%. Quarterly originations, also known as borrowing volume, came in at $11.4 billion. This was down compared to the last quarter. And then deposit volume was up quite significantly to $63 billion. Liquidations were at $34 million, this was a slight increase from the last quarter, and then we had aggregate utilization that is sitting at 41.7%. Pretty much for the past year we've just been ranging between the high 30s and and low 40s. Moving on to financials, total interest income for the protocol was $90 million. When we look at the interest, when we take out the interest paid to depositors which was $80 million, we are left with a net interest income of $10 million. That's a pretty decent growth from last quarter where you're looking at 11.1%. There were no grants paid out this quarter. The grant program ended I believe in September of last year but the Compound grants team is currently working on the second iteration which should be out in 2022. Currently no date has been set yet. But that led to the net income of $10 million still, close to 20% growth, we're running a net margin of 11% on the protocol, and when you take out the token incentives paid which was about $55 million, the adjusted net income for Q4 was a negative $45 million. That was a significant improvement from Q3: about 41% growth. Now before we move on, Getty, here's a question for you: what do you find to be one of the most important metrics or KPIs that you like to keep your eye on?\n\n  \nGetty Hill (06:43): Yeah great question, I think as these protocols have transitioned, especially compound out of its total infancy and have been around now for a bit over a year, really one of the more interesting things to begin to think about is that net interest income line there and the growth and the steady progression of the protocol over the last four quarters coming out to about a little over $40 million on the year is really impressive considering the amount of resources that are being deployed to earn that income. It really demonstrates that these protocols are being able to run themselves and generate some nice income in doing so.\n\n  \nSami Kassab (07:22): Great, yeah, I agree. Dustin, do you want to take this one?\n\n  \nDustin Teander (07:35): Yeah. So what we're looking at here is our outstanding loans for Compound. It is really going to illustrate a lot of what Sami is talking about particularly around the COMP distribution bug. So if you look at the right quarter of that screen, you can see the almost rectangular trough, that's that period of the COMP distribution bug. From that point on, we quickly resumed loan levels pretty much, obviously a little bit lower than where we were at the end of Q3, but stayed pretty flat until December. So what's happening there? You have to remember that Compound is driven by the borrow or the demand for leverage. During that time we had bitcoin hit essentially two new all-time highs at the end of October and then end November as well. So that's kind of fueling a lot of that growth there or at least during that period. We've mentioned the COMP distribution bug a couple of times. Getty, do you want to just explain real quick what is it, what does it mean when we say that, and walk us through a little bit of that timeline in that early October period?\n\n  \nGetty Hill (08:47): Sure thing, so for everyone who might not be super familiar with Compound, Compound when it was started came up with the COMP token as part of incentivizing participants to deposit liquidity in the protocol and distribute the COMP tokens in a decentralized fashion. The Labs team decided that it would be an interesting idea to distribute the COMP tokens for market participation. For example if you were to deposit some USDC in Compound, you would earn your pro rata share of the amount of USDC deposited and some COMP tokens that were being distributed to that pool. For the longest time since the inception of the protocol and that feature, it was distributed in a 50/50 split where the same amount of COMP, let's just say it was like 20 COMP per block, just making up a number right here. 20 COMP per block, obviously it's not that number, is getting distributed half to all the suppliers and half to all the borrowers and the thought was: hey, it would be really neat if we could adjust those parameters individually. So if we want to give 15 to the suppliers and 5 to the borrowers, we should be able to do that. So Proposal 62, originally, the premise was to introduce this new piece of code that would allow the parameters to be adjusted individually. Unfortunately, there was a small error in the code that was literally resulting in a greater than or equal to sign that was missing. The greater than sign was missing in the code and it ultimately introduced a bug into the code in calculating some of the supported assets and how they're essentially indexing these rewards and how the math was being done. What happened essentially was a bunch of people who had assets in the protocol that were earning yields all of a sudden earned substantially more than they should have otherwise been able to and were able to claim a significant amount of COMP. In some cases it was more COMP than was even in the existence of the protocol so those were automatically failing transactions. In other cases users were able to claim 10,000 or 50,000 COMP from the protocol\u2019s incentive pool. Luckily, it didn't hurt any of the users\u2019 participation in the protocol. Really what it was here is it was an unfortunate event for the protocol itself and all the COMP holders as it entered a significant amount of COMP into circulation that wouldn't have otherwise all been immediately entered into circulation, but everyone's loans and positions in the protocol were entirely safe and no one had to be concerned about their coins being at risk or being stolen or any of that. It was really just an unfortunate event for the protocol distributing a lot of money to individuals in an unfortunate fashion. Luckily, there was a lot of great effort amongst the community to figure out exactly what had occurred and went wrong and to react to it to the best we can. Now this is where it gets interesting, in the way of how governance functions and feel free to cut me off here because I can probably talk about this forever but what ended up occurring here, because compound is in fact entirely run by governance, the only way to change any code ever is to introduce a governance proposal and the governance proposal timeline is about seven days. So once the change was introduced to the protocol, the protocol\u2019s hands were tied. Governance can't actually rush to its aid, there is no multi-sig, Robert Leshner doesn't have a special key somewhere that allows him to run in there and fix everything up. It is truly decentralized here, in a painful fashion in this instance where the protocol was bleeding funds. So long story short we managed to get the fix in place and once that governance cycle had gone through everything was back to normal, and then it became \u2018how do we prevent this bug in the future\u2019, which I think we'll get into more later in this call. But that should be a quick synopsis on what occurred there on the back of that event.\n\n  \nDustin Teander (12:54): No that was great. Yeah, very good detail. So once that was resolved, that was like mid-October by that time, the proposal resolved it and got enacted. From then on it was almost more or less business as usual. But a couple of key things that we can look at in this chart that I thought was interesting is that: one, it is pretty clear that the light blue and the dark blues are both stablecoins so stablecoin borrowing obviously dominates because people want their cash denominated in stable assets. So the mix between these two is actually kind of interesting. This is the first quarter that we've seen DAI almost outpace USDC so DAI came in initially to the quarter as not the most borrowed asset (that was USDC) and then over time, it's a little bit harder to see in the chart but you see USDC with a slight decline while DAI is basically increasing. I think DAI increased outstanding loans roughly like 34% while USDC was slowly down 7%. I think that's going to be an interesting narrative that we talk about. I don't know what your opinions are Getty, about the growing importance of DAI in the protocol relative to USDC.\n\n  \nGetty Hill (14:10): Yeah, what's interesting is that throughout DeFi summer it was seemingly evident that a lot of funds in crypto were very fluid and that money was moving at a rapid pace and what we've seen now on the back after a year plus time is that there's actually a substantial amount of funds that are actually quite sticky and that have a preference to certain protocols and certain assets when it comes to what they want to borrow with, what they want to leverage themselves on, and where they want to leverage themselves. I think a lot of the data throughout this report and a lot of data in general supports that there's a significant amount of funds that are interested in simply supplying ETH in a protocol they're very familiar with and borrowing a coin that they're very familiar with in the ecosystem, DAI. Similarly, there's a lot of DAI interest on the other side supporting rates, stabilizing them and keeping them low to make it more attractive in many cases than USDC borrowing thanks to the quite colossal size that DAI is in the Ethereum ecosystem.\n\n  \nDustin Teander (15:14): Yeah, no I agree. I think it is interesting that we are starting to see that it is almost more adopted as time goes on. You brought up the interest rates which is a good point. So the interest rates typically follow the market correlation. So as bitcoin starts breaking out there in November, you see in the right half of the chart that the interest rates start to spike for the protocol. Back to it, USDC and DAI are the two most borrowed stablecoins. USDC is really driving that average borrowing interest rate spike. If you look at the DAI chart, it's almost flat to your point, and that's really driving a lot more demand on the borrowing side.\n\n  \nGetty Hill (16:05): Yeah I think it provides certainty for people when all the DAI that's in existence is all essentially these dynamic fixed rate loans as MakerDAO governance picks a rate for individuals to borrow DAI at and it provides a steady hand of like \u2018hey, this is what the cost of DAI is at its source\u2019, and that kind of sets the pace for everyone else where the dollar rates, dollars are king ultimately and are fluctuating wildly and typically are driven by the the cost of capital at some of the big lenders and then particularly in the leverage markets we look at perpetual markets and whatnot. That's perhaps where the big dollar driver is in crypto.\n\n  \nDustin Teander (16:49): Yeah, it's a great point. I'm glad it's almost becoming more prevalent and more recognized. Because like that's what we really saw this quarter is that DAI became more adopted within Compound and being a decentralized stablecoin, it gets more into the ethos of DeFi in general. Another side of this is the supply and Sami you're going to get into this a little bit. I think in December, Coinbase announced their DAI DeFi yield program, which if you look at the day they announced, which was I think December 8th or 9th, at that point on, 75% of all the DAI that was deposited during the quarter was in that time period. So you're getting a lot more DAI influx into the protocol during this period and in the future we're probably going to see a little bit more. Getty I know you've done some work on the Maker side to get direct DAI injection, so there's just a lot happening on the supply side as well.\n\n  \nGetty Hill (17:56): Yeah, absolutely. The direct deposit module that we've been working on with MakerDAO is currently functional on Aave, and essentially the idea is that \u2018Hey, the protocol has a lot of capital and they are sufficiently overcollateralized, why not print some new DAI, put it into circulation, the protocol gets to earn a nice yield and they also can keep a steady hand on interest rates throughout the world\u2019. So they want to make it such that DAI really becomes a prevalent asset and while Circle might not necessarily be out there injecting hundreds of millions of dollars into protocols directly, it certainly shares some influence through some of the big trading desks and lending partners that they have. But MakerDAO really going out of their way to set up direct collaborations with protocols is a really neat way of DeFi supporting DeFi and providing liquidity in a win-win scenario where Compound gets a lot of liquidity and these protocols that they are going to plug into, in this case it could be hundreds of millions of dollars worth of DAI at a non-existent cost of the protocol. MakerDAO also gets to put more of their currency in circulation and keep rates low to make them the preferred borrower asset for individuals who are seeking leverage and it's just a win-win for everyone. So we're really excited about bringing that direct deposit module to Compound. That's something we've been working hard on and I think it will provide a significant amount of value.\n\n  \nDustin Teander (19:31): Yeah I totally agree, I think that's huge. All right Sami, why don't you jump in and since we've been talking about deposits here, could you give us an overview of the quarterly deposits?\n\n  \nSami Kassab (19:44): Yeah, so I was saying that deposits is largely a similar story to what we saw in outstanding loans. You see that the effect of the Compound distribution bug in October like Dustin was saying, you're really starting to notice DAI take over as one of the most, well it is actually the most, borrowed asset. It's also becoming a more popular asset to deposit and one of the main reasons that Dustin already touched on was due to this Coinbase DeFi yield product integration. So they allowed their users to basically submit their DAI and then gain yield on it. I think this really goes back to what Getty was saying about getting that sticky liquidity into the protocol and helping out both the Compound protocol as well as helping out Coinbase and their users. Because of this integration, you saw DAI flip well\u2026 So let's start with wrapped ether. So wrapped ether has always stayed as the largest deposited asset on Compound and historically the second most popular deposited asset was USDC. What we saw in Q4 was DAI taking over as that second most important or most popular deposited asset. One thing to notice is that wrapped ether makes up such a large percentage of the overall outstanding deposits but in the previous quarters it began to flatten a little bit and there's probably a lot of reasons for this. One of them could be the whole Ethereum 2.0 staking option. I don't know if you have any thoughts on this Getty, but another thing to note is the growth in outstanding deposits from Q3 to Q4 was relatively low. It was about 1%. But this chart is in US dollars and so if you were to remove the asset price increase from bitcoin and ether from Q3 to Q4, you'd actually get a negative growth rate for outstanding deposits. So you're starting to see deposits slow down into the Compound ecosystem but again it could just be because the general macro markets got a little bit heated towards the end of the last year and then you can see there's a little bit of a sell-off that happened in the end of December and you see deposits start to taper off as well.\n\n  \nGetty Hill (22:43): Yeah, I think in the Q4 period and especially after the Compound error\u2026 You know one of the claims to fame for Compound was that it's the safest protocol and the safest money market that exists: longest running, never had an error, and while 62 was an error to users, either way it's something that scares people the fact that such a thing could have occurred is frightening without a doubt. While it didn't hurt anyone, it's hard to change that perspective. I think that certainly didn't do the protocol any favors and that's why we've done stuff like having OpenZeppelin come on and be the full-time auditor for the protocol and audit every single governance change that's made from here on out. In addition, some of the larger participants and voters in the protocol are taking their position as large governance token holders a bit more seriously on the back of that. I think those two things will make a big difference in light of the error that occurred on that COMP distribution bug. As far as other things go, it's definitely a competitive environment these days when it comes to money markets. Aave definitely has done some clever things to really put themselves as a dominant participant along with MakerDAO and so in addition to Compound competing then with MakerDAO and Aave, at the end of the day Compound\u2019s bread and butter is margin leverage. Users are posting up coins like ETH and go long with cash stables and we've seen the likes of FTX and Binance really surge up in their leveraged product offerings, particularly their perpetual products, throughout the world. At the end of the day we are competing for the same market share: users who are interested in getting levered long in their assets. With the domination that's occurring at FTX and others, those are all competing products that we have to take into account as we continue to build out Compound.\n\n  \nSami Kassab (24:47): Yeah, I think that's a really good point that you added. The market is competitive and you\u2019ve really got to rely on adding new features and continuing to build that trust. I think you touched on the OpenZeppelin partnership which is a really important tool especially because Compound is, I would say, correct me if I'm wrong, one of the only protocols or one of the first protocols specifically to go down the route of decentralized governance and decentralized development as well. So they're pretty much paving the way and setting an example for other protocols, and of course the first mover is going to encounter a few difficulties here and there but it's all about the community learning from that and adapting and continuing to make improvements.\n\n  \nGetty Hill (25:37): Yeah exactly, that hits the nail right there on the head. We're the ones who are experiencing a lot of the growing pains being the father of DAO governance and the governor bravo contract and alpha contract now being so widely used in this space. I think MakerDAO is a great example of a protocol that had a lot of its own challenges being the first and foremost DAO that exists in the space. We're similarly going through a lot of those growing pains when it comes to \u2018how do you incentivize participation, improvements in the protocol, security and risk management in the protocol?\u2019 So the likes of OpenZeppelin getting contracted and getting paid millions of dollars to come in here and do great work and have full-time individuals dedicated to the protocol, I think is going to be immensely helpful for participants and for the protocol\u2019s progression in general. And then also the likes of innovating on risk parameters and trying to do risk management. These are all super new interesting things that are certainly not perfect today, but everyone is doing their best to figure it out and ultimately that's the beauty of DeFi: solving these weird problems that you won't really find elsewhere. Luckily there's a lot of incentives in many cases to drive that, and everyone's willing to have the hard conversations to drive that progress.\n\n  \nSami Kassab (26:58): Yeah, and I think we can touch on the kind of that incentivisation process as well later on but moving on to depositor interest rates, Q3 saw all-time lows as far as depositor interest rates go and the Q4 interest rates were relatively in line with that as well. So if you take an average of the annualized deposit rate for Q3 it was around 1.8% and that average for Q4 was about 2%, so a slight increase there, but I think these rate stabilizations indicate the product maturity at Compound and there's a consistent demand for deposits and that demand is constantly met with the borrowed demand as well. I believe that's really best highlighted with this utilization chart. So one thing to notice is that this utilization ratio has been trending down since around the end of 2020 and that highlights that you have depositor growth continuing to outpace loan growth which is bringing down borrow rates for borrowers, especially with the rapidly maturing stablecoin market. We've seen the stablecoin market go exponential in 2021. It has just skyrocketed. So the utilization rate is going to decrease especially as supply starts to meet demand.\n\n  \nDustin Teander (28:50): Awesome, alright so what we're looking at here is protocol income and Getty, like going back, you picked my favorite metric as well on the macro chart. To me, this is the culmination of what we're going after. You can have a bunch of liquidity in the protocol, you can have a bunch of borrowers, but it depends on the take rate or the reserve factor that we're charging here. This is specifically an interesting thing. So that's the name of the game for Compound. What matters at the end of the day in my opinion. So I want to spend a decent amount of time on this chart picking apart not just what happened and the results but also looking forward and how we think about the revenue mix in general and directing certain levers we have to pull in a strategic manner in order to optimize revenue growth.\u00a0 First, just to give a quick\u00a0 narrative of what we're looking at here, we see from Q3 to Q4 about 10% growth but factoring in grants costs, it\u2019s roughly 20% growth in net interest earnings. Going back to my little DAI vs. USDC talk, we are again seeing DAI increase relative to USDC in terms of protocol importance. So it's driving, in this image, roughly 50% of Compound\u2019s income in Q4 and that is due to a couple of reasons. For example, its reserve factor is higher than USDC so on a per loan basis it's more income for the protocol. So Getty, let's talk just a touch about what you think about when you are looking at this kind of data and what levers do you think we should be pulling in order to incentivize different revenue mixes and stuff like that. How do you approach the revenue mixer of Compound and how do you think about it?\n\n  \nGetty Hill (30:50): Yeah, so there's two big components to revenue today. That is one, the primary driving factor and especially the one in the long run that drives income for the protocol. That is assets to borrow from the protocol and the protocol takes its cut of that reserve factor in the form of these assets. So at the end of the day, we need people to not only supply assets to the protocol but most importantly borrow assets. And that's what we see here on this protocol income slide, usually seeing DAI denominated things people at the end of the day are most interested in leveraging long in their assets. The market, I think, thankfully for my positions, is very interested in borrowing tons of ETH and going the other direction. So what we see here is a lot of the protocol revenues are going to be denominated in stablecoins. So what that means as far as growth and how we increase these numbers over time, I mean supporting more assets that individuals are interested in using as collateral to borrow then you know more dollars are going to seek that margin long. So whether it be supporting Eth2 assets like Lido's staked ETH product or other similar staked ETH products or supporting LP tokens, as we look towards the future, those are the things that will be the most pressing developments to drive protocol income up and general TVL up in a very natural fashion. Now, the other half of that coin, which is the not so pretty part, is the COMP incentives that we distribute to the protocol right now. The portion up here, while we made $10 million in Q4, I don't know the exact number of top my head, but if I had to ballpark it from the research I've done, we probably spent 10, 50, 70, or 80 million COMP incentives over that period at the same time and so a lot of the income that we're earning is in many cases the symptom of a lot of those incentives as we're incentivizing people to deposit assets in the protocol, we're also similarly incentivizing them to borrow assets from the protocol and we're earning a small percentage of the money that we're paying them to borrow in the form of stablecoins. So the other side of the coin is not so pretty but then again I think we might talk a bit more later in the call about how we use these incentives in an efficient fashion to reduce the protocols annualized spend of COMP incentives, which is now a little bit north of $100 million a year.\n\n  \nDustin Teander (33:28): Yeah, no I mean it's definitely a discussion I want to have\u00a0 because I find it pretty interesting as well because it obviously makes sense when you're a newer protocol and you're starting up liquidity and stuff like that. But it almost loses its effect because\u2026 It's a big statement, but if the borrowed assets are stablecoins, then we're putting all this essentially sell pressure on the COMP token and you're keeping COMP flat, or the COMP emissions, roughly, then you're losing a per dollar impact for the supply. So the reward rate that I get, let's say it was 4% flat, no incentives for depositing, as time goes on we're seeing that juice get to be four and a half as opposed to previously when the token is higher, it's a higher margin there. If you could see it, we got a slide on COMP emissions there.\n\n  \nSami Kassab (34:29): COMP emissions. Here.\n\n  \nDustin Teander (34:33): Yeah, okay I believe it is that. So across this period Q3 to Q4, that's 30%-ish less in US dollar terms that we're emitting in COMP tokens but it's only 5% less or so in actual COMP tokens, so it means we're getting less bang for the buck more or less.\n\n  \nGetty Hill (34:53): Yeah exactly, the protocol is distributing largely a fixed amount of COMP. The amount of COMP that we're distributing has really not changed significantly over the period. It occasionally has as we've introduced assets or taken assets out of that mix, but it really has remained the same. But at the end of the day a lot of the protocol\u2019s participants, whether they be individuals or trading firms or funds, whatever it may be, a lot of them are denominated in dollars. They report back their P&L in terms of dollars and so they look and see \u2018okay well while the COMP tokens are remaining a fixed number of tokens, ultimately what we care about is what's my bang for my buck\u2019. So if COMP is trading at 800, the protocol is distributing notionally significantly more dollar value than if it's trading at a hundred dollars. So what's interesting is we've done a lot of research on this and similarly if you were to compare here the amount of participation in the protocol with COMP token incentives paid, it presents a huge decrease from over Q2 to Q4. That is 101 million to 55 million but you're not seeing the protocol's participation similarly half in value and that I think is a great representation that \u2018hey while there is a lot of participation here that's interested in these COMP incentives, there's way more that is actually naturally here\u2019 and that is the stuff that we want to hang on to.\n\n  \nDustin Teander (36:18): I think that's a good point. To think about it even more strategically, take it one step further, it's like \u2018all right, we're kind of paying out COMP rewards across the board on different assets as well, but by going back to our revenue, it was DAI that made up 50%\u2019. We've got constant partnerships or integrations at least driving a lot of DAI supplies so it doesn't make sense to incentivize DAI supply longer or do we direct COMP emissions towards assets that do drive more revenue in order to focus on what matters to the protocol.\n\n  \nGetty Hill (36:53): Yeah absolutely, I think COMP incentives came about from the original idea of the COMP Labs team that kept a good portion of the tokens for themselves and their investors and they said \u2018okay, well let's give the rest of them away to the users of the protocol\u2019. So the original idea was \u2018what better way to give them away to the participants in the protocol?\u2019, and this is, mind everyone who is listening who is now familiar with the crazy world of airdrops that exists, this is really before airdrops had really become a thing. Uniswap\u2019s airdrop was something like six or seven months after this occurred in the fall whereas this was back in May. That idea didn't really exist. It seemed sensible to distribute tokens to participants and so that was really the impetus of this and that's where it gets a bit more philosophical about \u2018do we want to end incentives or do we not?\u2019. It hurts current holders but also the original mandate from the team was \u2018hey, these were meant to be distributed to a lot of the users\u2019, and so we've seen a lot of interesting debate develop around what's the best way to allocate COMP tokens most effectively so that it is distributed and decentralized but also such that we don't needless spending. In my opinion, that is kind of what's occurring today.\n\n  \nSami Kassab (38:14): Yeah, I think it's a good point too because there's different strategies you could take to\u2026 rather than just tapering all COMP rewards to zero you could potentially use that to maybe kickstart new markets, to incentivize people to provide liquidity for that specific market. What are your thoughts? Where do you see this going? Do you see it more strategically being planned and if that's the case does it just have to be\u2026 you guys have to create some type of parameters that have to be set? Because it seems like a really difficult topic to discuss and because it's very subjective right?\n\n  \nGetty Hill (38:59): Yes, it's all it's all quite subjective when I originally went down a rabbit hole being like \u2018hey, is there a way now in the back of 62 once we got all the dust settled and we have these new tools, is there a way to materially improve the amount of money that we spend on the protocol and more efficiently spend that cash on the protocol to increase participation and get incentives in a targeted fashion?\u2019, and it really boiled down to being a very subjective process. I think at the end of the day, the most realistic point for what COMP rewards are supposed to be doing is for incentivizing liquidity and markets that do not have liquidity. At the end of the day, the protocol's mission is to provide a venue for individuals who come and borrow tokens and if we don't have tokens for these individuals to borrow, then we're failing our mission there. And that can be quite difficult as we onboard some new markets as the protocol has been doing over the last several months, and turning on COMP incentives for those, starting up some type of regular program where it's say, \u2018hey month one you get this number of rewards or month two you get this number of rewards and it staggers off over a three month scale back down to zero\u2019, and we have a fair amount of evidence now to suggest that a lot of these funds are sticky, and that users will come to the protocol and leave their funds on the protocol. Certainly some will leave but there will be a substantial amount that will provide that liquidity that the protocol needs to function and I think in my mind that's the direction we're headed when it comes to COMP incentives. We're not going to entirely phase them out all together because they certainly play a purpose in strategically improving new markets, but I think at the same time we do need to significantly cut back on the amount of tokens that are entering circulation or at least the style in which they are entering circulation today.\n\n  \nSami Kassab (40:45): Yeah great point.\n\n  \nDustin Teander (40:56): What other levers do you think you would be pulling in order to increase revenue? I'm thinking of interest curves. Is there any sort of management of interest curves or anything that you're looking at there to say like\u2026 I know DAI has got a little bit of a different one, but it's still driving a lot of revenue. Do you look at something like that for USDC or is that even applicable? What do you think?\n\n  \nGetty Hill (41:20): Yeah, it's a great question. In the grand scheme of the protocol, and since literally back to day one, all the innovation has been underlying the invention of the COMP token, the invention of these interest rate curves, dynamic interest rates, a lot of energy and time and effort has gone into the fundamentals of the protocol and not necessarily the interest rate curves that are chosen, the reserve factors that drive revenue for the protocol, some of the smaller details have fallen to the to the wayside behind the massive improvements in the fundamental protocol that exists. So I think shedding some more time and effort particularly on those issues at the end of the day the protocol is a borrow-lend market and for a borrow-lend market we spend an awful small amount of time improving or researching interest rate curves and setting those up is really important I think to driving the maximum amount of revenue and providing the best rates that we can possibly provide to the market in addition to those reserve factors which ultimately drives revenue to the protocol.\n\n  \nDustin Teander (42:27): Yeah I know, I totally agree. That's kind of the next wave of like\u2026 \u2018Okay, we've got something that's obviously got some market traction, how do we now optimize and fine-tune particularly from a revenue perspective?\u2019. It was definitely one thing that came to my mind as I was putting some of this together. So Sami has kind of prompted me here, so obviously another thing in revenue is liquidations. It has obviously become less of a factor here over Q3 and Q4. You want to give us any insights you got there?\n\n  \nGetty Hill (43:01): Yeah, so I think it was back in Q3, the protocol introduced an improved liquidation system that was brought about I think by the the core team and that was to decrease the liquidation incentive for liquidators and introduce part of that liquidation incentive for the protocol itself so in the case of when a user unfortunately gets liquidated on the protocol, it's something about an 8% penalty that is put on them, in their portfolio, whatever they are borrowing. About 5% of that goes towards liquidators incentive and essentially that just gives them a 5% improvement on whatever the market weight was at that time to get them to come in and perform that liquidation. I think it's about 2.8% or so that goes to the protocol, so that's been an interesting new line of revenue for the protocol. Personally I'm not a huge fan of it, I think it introduces maybe a bit of an interesting incentive for the protocol that doesn't really need to exist, but at the same time it's also something that users haven't really seem to care too much about. So if you want to go the other direction, it's in theory something you could crank up a fair amount more to drive revenue to the protocol as we've seen at MakerDAO liquidation revenues are a substantial amount of income for the protocol over there, especially over the back of what's occurred over the last month or so, the recent liquidations.\n\n  \nDustin Teander (44:30): Yep no, it's definitely a good insight to have. It's not something that's long term. You won't want to be\u2026 Like FTX I think has actually done, in terms of the exchange, they have retooled their liquidation engine to attract more traders and for Compound, long term you don't want to be just liquidating your users because they're not your users after they get liquidated.\n\n  \nGetty Hill (44:53): Exactly, the protocol is substantially more incentivized to keep the users around and keep them healthy and try to keep them informed of the risk that they're taking rather than profiting off of their demise.\n\n  \nDustin Teander (45:08): Right, right. Alright, cool. So that wraps up the financial section we've got going on. I want to peel into more of the governance and what's happening in the governance world as well as looking forward to what the roadmap looks like and things like that. Before we jump in there, I know you gave a little brief overview of what GFX does. Can you paint a picture of who else is in the community, what roles are they playing? We mentioned OpenZeppelin.\n\n  \nGetty Hill (45:41): Yeah, so the Compound community is a fantastic one since it's one of the older ones in the community so you have both the older crowd who has a ton of experience and seen a lot of the hardships that DeFi has gone through. The folks like Robert and crew and some of the others in the community that go by anon names like Blck and Dennis Bowling and others who have been on discord hanging out long before the COMP token even existed and a lot of those individuals that have seen the protocol go from having tens of millions of dollars to now having six billion dollars in TVL, having liquidations being predominantly performed by individuals and trading firms now being predominantly performed by algorithmic systems that are all entirely on chain. So the landscape has changed significantly which is really cool to see. We've got awesome more recent additions to the team and more recently like Tyler Ether in the protocol and we have certainly got some older ones like Arr00 in the protocol who do some great work. So there's a great collection of individuals who make up the protocol. They are the ones who are day-in-day-out. I'm sure I\u2019m forgetting a few that I should be mentioning, and then there's also the more recent additions of Don and OpenZeppelin in the mix. They provide a bit more of a strategic steady hand on the protocol and are highly incentivized to participate in a meaningful fashion as well so it's a nice dichotomy that is constantly developing. It isn't always super functional and there's certainly shortfalls regularly, but ultimately it's a nice and caring community for the protocol and it's improving that protocol over a long period of time.\n\n  \nSami Kassab (47:27): Yep, so touching on that, I know that there's this DAI direct deposit module that is basically a partnership between MakerDAO and Compound and then when you also think about the Coinbase DeFi yield product integration. How do you incentivize people to go out and get partnerships like that? Because those are such important partnerships for the protocol but it seems hard when you don't have some type of centralized business development team that's working on forming these partnerships and connections. So how do you really push the community into constantly looking for new opportunities to grow the protocol?\n\n  \nGetty Hill (48:20): The nicest way you can put it is that it's very challenging. There's not a lot of incentives so a lot of the participation that does come about in Compound and lots of DeFi is just from people's genuine interest in the protocols and perhaps from the notoriety that comes with participating in these protocols. Similarly there's very few things in the world where someone with a keyboard and some smart ideas can affect billions of dollars in capital and that allure I think is quite seductive to a lot of individuals and that's one of the reasons I certainly got involved in finance and trading, and then in protocol governance. Ultimately, is the fact that anyone can do anything really in this space as long as you just write a good logical argument about it, you can get pretty far just repeatedly performing that strategy. I think in the long run though, unfortunately that doesn't really work out forever. That's a nice way to get jump started and lean on the community in the early days but in the long run I think we're going to see DeFi not morph into what exists in the corporate world but certainly lean on some of the progress that they've made. There's certainly a tried and tested model in corporate governance and just in general how companies function. I think we'll begin to see some more of that. GFX Labs has our own proposal up right now that were that we are in talks with the community about becoming more of a core contributor from the outside of the protocol, introducing some interesting ideas like KPIs and what not to incentivize our participation to make sure it's worth our time and similarly the protocol gets what they want from the relationship and everyone can dedicate meaningful resources to improve these massive protocols. But ultimately it's a lot of interesting challenging conversations that are being had that are slowly driving the whole DAO space forward.\n\n  \nSami Kassab (50:13): Yeah, thanks for sharing your views on that. Now, we're kind of running out of time, so maybe we can wrap up with talking about gateway for a bit so I know gateway was announced in March 2021 and it was supposed to be this independent blockchain that would serve as the infrastructure for cross-chain interest rate markets. So you'd have various start ports on different blockchains and they would all report back to the shared liquidity, and there are talks about using a cash stablecoin and I believe Compound Labs came out with an update a few weeks ago. As we all know in crypto time moves 10 times faster and so a lot has developed in the cross chain ecosystem and I'm assuming the team has woken up possibly to the new challenges, especially the the cross chain problems that we've been witnessing lately, when you think about like the Thor chain hacks and the wormhole hacks that were going on, but can you give us a little bit of a summary on the new approach that Compound Labs is\n\nplanning for? The v3 of Compound?\n\n  \nGetty Hill (51:29): Yeah, absolutely. So they took a lot of the feedback from participants over the period. While gateway was a really credible idea, it was also a very big and hard to execute idea. As to your point we've seen with some of these protocols trying to do cross chain things. It is a ton of work, extremely risky, and it spreads out the code base substantially. So I think the team decided to take a more iterative approach to developing gateway and saying \u2018okay well, what are the things that we need most right now, what are the good ideas from the protocol?\u2019, because there's a lot going on at gateway that was fantastic apart from the cross chain implementation, there were a lot of really great features regarding capital efficiency and assets in participation and leverage. One of the really great things I think particularly, retail is going to enjoy the new protocol. It's substantially simpler. It's a one-way market in the sense that there is a list of assets that are supported as collateral assets and then there is a single defined asset that users can borrow. So unlike today where you can borrow and supply anything and it's very much a generalized money market, the protocol decided\u2026 Seemingly Labs decided to make a bet and I'm not going to say words for them so this is my impression of the decision making here was \u2018if the vast majority of the capital in DeFi and these money markets is interested in going levered long, let's build a protocol that is optimal for levering long\u2019. So let's set it up in such a way where \u2018hey, there's a single asset here that you were borrowing and that is dollars or it can be any stablecoin and then\u00a0 governance can add assets on the collateral side and say these are your supporting\u2019. Let's remove all the logic from borrowing any asset, let's simplify it down to only supplying assets as collateral, they can't be rehypothecated, and it makes the code base substantially simpler, substantially more gas efficient, which I think retail is going to appreciate because to use compound today is not inexpensive. In the long run it's going to make it also that, back to the gateway point, substantially easier to deploy and process and run on other chains. So it's very much an iterative approach and definitely certainly a tad different from what gateway was proposed as back in last March, but it's one that Labs feels confident they can deliver and that everyone is very excited to see and use.\n\n  \nSami Kassab (53:52): Yeah, I found the idea of just one borrow asset pretty interesting, because when you look at the current Compound protocol, most of the borrow demand is for stablecoins. So if you just had one stablecoin that was worth borrowing, it would just significantly reduce your code base and complexity required for going cross-chain. So overall I thought it was a very interesting idea and approach.\n\n  \nGetty Hill (54:20): Yeah, it should be good fun. I'm really looking forward to having it and the numerous tools in it regarding capital efficiency are certainly improved as well. So I think, who wouldn't want to use essentially cross margin MakerDAO? A big reason why I personally don't use MakerDAO is the fact that while I own multiple things, to have separate margin accounts for every single asset that I have to maintain is a bit of a pain. I'd much rather use a system that allows me to put that all underneath one roof, in my mind, mitigate some risk that way when it comes to liquidation, and that's exactly what they're delivering.\n\n  \nSami Kassab (55:00): Yeah DeFi is already complex enough, so reducing that complexity and keeping it as simple as possible for retail is just as important I think, like you highlighted.\n\n  \nGetty Hill (55:14): Yeah, and the nice part too is there will be a good opportunity here for v2, the current protocol that exists, to run in tandem for a long time as v3 exists. There's a lot of room for a generalized money market that exists as we've seen and there's also a lot of room for just a specifically margin-long version of Compound. So I think these things will operate well in tandem. I certainly think v3 will end up being the most popular one because people ultimately love being levered long like myself, but it should be good fun.\n\n  \nSami Kassab (55:47): Yeah, I'm excited. Dustin, any last questions you can think of before we lose Getty?\n\n  \nDustin Teander (55:53): You know what? I think we should probably ask the chat or the community if they have any questions. Feel free to drop it in there. We\u2019ll stay on for the next minute or two. Get anything answered.\n\n  \nGetty Hill (56:07): Well it's been a lot of fun talking about Compound. I could honestly go on endlessly about this protocol and a lot of the other protocols that exist. I think it's a really interesting time to be in DeFi, in the money market. While there is this kind of quiet bear market occurring in DeFi, there's a lot of really bright people that are putting their heads down and developing some novel protocols that are going to continue to progress at the forefront of DeFi.\n\n  \nSami Kassab (56:35): Yeah, I think the Compound community owes you and GFX Labs a big thank you for all the effort that you guys are putting in. I got a chance to read through your proposal, your GFX Labs proposal, as well and I really like the topics that you guys are wanting to focus on for the new changes of Compound. I'm looking forward to seeing GFX Labs play a bigger role as a contributor in the Compound ecosystem.\n\n  \nGetty Hill (57:07): Appreciate that. Thank you very much.\n\n  \nSami Kassab (57:11): Yeah, well it looks like no questions really. So we'll go ahead\n\nand just wrap up. Thank you so much again for being here, it was a pleasure speaking with you.\n\n  \nDustin Teander (57:24): Yep, appreciate it Getty.\n\nGetty Hill (57:27): Cheers, everyone have a nice rest of their Thursday.", "references": [{"name": "Dustin Teander", "url": ""}, {"name": "Sami Kassab", "url": ""}], "published_at": "2022-03-19T19:15:00Z", "author": {"name": "Dustin Teander, Sami Kassab"}, "tags": ["Quarterly-Reports", "Decentralized-Finance"], "url": "https://messari.io/article/state-of-compound-q4-analyst-call-transcript"}, {"id": "0a1fd027-bc16-42d9-b5af-ad5ac4c02670", "title": "Weekly Recap Ending March 17", "content": "Notable Messari Intel Updates\n\nTim Beiko of the Ethereum Foundation announced that the transition from proof of work to proof of stake occurred on the Kiln testnet. More information can be found <a href=\"https://messari.io/intel/event/a9d65ec5-fd7d-47fb-9f5b-9b83b1a6fce9\">here</a>.\nThe Mina Foundation announced that the Mina Ecosystem <a href=\"https://messari.io/intel/event/10f0f7c0-2617-4e58-bdca-efeb9ed4c14c\">secured $92 million</a> in strategic and private sales of MINA, led by FTX Ventures and Three Arrows Capital.\nThe <a href=\"https://messari.io/intel/event/8c40e66c-59e6-43ca-9d7a-e2d4cad7575a\">second batch of parachains</a> has been deployed on the Polkadot network. The newly onboarded parachains include Composable Finance, Efinity, Nodle, Centrifuge, Interlay, and HydraDX.\nSynthetix Layer 1 and Layer 2 debt pools are <a href=\"https://messari.io/intel/event/7402ae57-c97e-4b20-9c68-589955bd1892\">scheduled to merge</a> the week of Mar. 14 - 20, 2022. SNX inflationary rewards will be provided proportional to stakers on Optimism and Mainnet Ethereum once the pools have merged.\nApeCoin (APE) is <a href=\"https://messari.io/intel/event/3a0c5d16-df16-41c6-9bb0-d972658c6d0c\">now on coinbase.com</a> and the Coinbase Android and iOS apps.\n\nNotable Messari Governor Updates\n\nThe Gnosis DAO <a href=\"https://messari.io/governor/proposal/23476cd5-9fcb-4c6b-8652-ac1deaea5f45\">submitted a proposal</a> that aims to enable GNO tokens locked in smart contracts or liquidity pools to vote. Voting is currently active.\nThe Balancer DAO has <a href=\"https://messari.io/governor/proposal/3f5eaaa0-60ad-49e7-af7e-f187b42bf936\">submitted a proposal</a> drafted by the Partnership subDAO and aims to introduce a multi-functional platform, called Hexagon Finance. Hexagon will serve as a joint project between BalancerDAO, Ava Labs, and Terra Labs focused on bringing Balancer products and infrastructure (via a smart contract fork) to the Avalanche crypto community. Preliminary discussions are ongoing.\nThe Uniswap DAO has <a href=\"https://messari.io/governor/proposal/1b536e61-d995-4503-acbc-5a2020694e41\">submitted a proposal</a> that aims to deploy Uniswap V3 onto Celo, an EVM compatible blockchain. Voting is currently active.\nThe Protocol DAO <a href=\"https://messari.io/governor/proposal/49cb8c6f-5eec-471e-b494-e8e5491531dc\">succeeded</a> in passing a proposal that aims to replace the existing Snapshot election process used by Synthetix DAOs with the first component of its V3 Governance Module - the Election Module.\nThe QuickSwap DAO <a href=\"https://messari.io/governor/proposal/0967b3a3-5194-4565-ac89-12a886de5f3a\">submitted a proposal</a> that aims to determine if the QUICK Token Split should be by 1:100 or 1:1000 tokens to determine the maximum supply of QUICK.\n\nSector Returns\n\nFor the fourth week in a row, the sectors covered have seen a 180\u00b0 reversal. This trend has further solidified the fact that the markets are experiencing a consolidation phase. This week, the DeFi sector came out on top as the best performer (8.58%). It is a much-needed relief given that the sector has endured significant losses since the start of the year, with some of the DeFi 2.0 assets having seen +90% declines since ATH. The second spot was taken by the gaming sector, bringing in 7.85% for the week.\n\nFrom a technical analysis perspective (seen below), the total cryptocurrency market cap has been consolidating within a pennant pattern which means that breaking this trend could lead to significant moves in the direction it breaks from it.\n\nTop Assets\n\nLast week, Terra (LUNA)\u2019s momentum was questioned after its consecutive three week double-digit return spree amidst adverse market conditions. It\u2019s worth noting that these same market conditions discourage investors from borrowing the stablecoin (UST) it relies on. This week, it was the worst performer amongst top assets by market capitalization and the only asset to finish in the red, declining 12.8%. Polkadot had the highest return with 10.8%.\n\nDeFi Assets\n\nThe DeFi sector had the widest range of returns recorded since bringing back Weekly Recaps, spanning 77% across. Leading the sector this week was THORChain (RUNE) with a substantial 52.4% return. The catalyst behind RUNE\u2019s rally can be attributed to the cross-chain liquidity protocol\u2019s recent feature introductions which include the launch of synthetics, coupled with the current positive sentiment within investors towards Cosmos-based projects. Another notable performer was Aave, which saw its AAVE token price grow by 32.4% this week, securing the second spot. After Anchor Protocol\u2019s (ANC) recent rise to ATH earlier this month, the decentralized money market built on Terra has lost more than 55% of its value, and this week, it has secured the last spot in the sector, recording a 24.6% loss. DeFi TVL is sitting at $156.21 billion, down less than $2 billion from the previous week.\n\nSmart Contract Platforms\n\nThe smart contract platform sector had a dispersed set of returns for the week, with assets hardly trading in the more commonly seen synchronous pattern. Polkadot (DOT) led the sector this week, closely followed by Avalanche (AVAX) and Ethereum (ETH) which brought in returns of 10.8%, 9.0%, and 8.7%, respectively. Aside from Terra\u2019s LUNA asset, NEAR Protocol (NEAR) was the only other asset within the list that brought in a negative return (-0.3%).\n\nCurrencies\n\nThe currencies sector had a similarly dispersed set of returns for the week, with assets sharing almost no synchrony in their trading. Monero (XMR) was the best performer within the top currencies sector this week, recording a 9.8% gain. Next up were Litecoin (LTC) and Stellar (XLM) tied with returns of 8.1%. Following closely was Ripple (XRP), which yielded 8.0% for the week. Dash (DASH) was the laggard of the group with a 6.2% decline.\n\nWeb3\n\nThe Web3 sector had two clear outperformers this week starting with The Graph (GRT) and Basic Attention Token (BAT), each returning 28.6% and 27.1%, respectively. There are various ongoing developments around The Graph that are driving the asset\u2019s rally. These include the recent migration of its subgraphs onto its own decentralized mainnet, the launch of a grant program to help streamline the migration, and the upcoming Graph Day 2022, an event featuring leading protocol and dApp developers along with a hackathon. Stacks (STX) was humbled by the rest of the group and returned a 9.2% loss.\n\nGaming\n\nThe Sandbox (SAND) was the clear winner of the sector and the only top gaming aset with a double-digit gain on the week. The virtual world project recorded a 15.8% return, enough to separate it from the rest of the sector by almost a 7% margin. It was followed by the native token of the Axie Infinity virtual world ecosystem AXS, which saw gains of 9.0% this week. Trailing the sector was Ultra (UOS) as it was the only top gaming asset to end the week with a loss, returning -2.7%.\n\n", "references": [{"name": "Guillermo Avil\u00e9s", "url": ""}], "published_at": "2022-03-18T14:41:00Z", "author": {"name": "Guillermo Avil\u00e9s"}, "tags": ["Macro"], "url": "https://messari.io/article/weekly-recap-ending-march-17"}, {"id": "8e226a3a-d878-4e8a-a393-a05a881abfa1", "title": "Euler Finance: A Fresh Approach to Risk Management in Lending and Borrowing Markets", "content": "Lending and borrowing protocols form one of the cornerstones of the crypto financial markets. As DeFi has matured, these protocols are typically found at the bottom layer of the \u201cmoney lego\u201d stack, creating a foundation for building more complex financial instruments. In their simplest form, these protocols serve as a mechanism for retail investors to deposit funds and earn yield on them. Two of the largest lending and borrowing protocols on Ethereum, Compound and Aave, boast a combined ~$21 billion in deposits and have a 35% and 30% utilization rate, respectively. Other protocols tap into these platforms too, with the yield aggregator Yearn Finance, for example, holding ~27% of Compound\u2019s cDai as of this writing.\n\nSince these protocols serve as a foundational layer to the wider ecosystem, it should come as no surprise that these platforms are primarily concerned with risk management. To illustrate this fact, Compound and Aave have partnered with Gauntlet to ensure the risk parameters across their various markets are properly managed. Gauntlet simulates and models a variety of scenarios within DeFi and then proposes updates to parameters (such as an asset\u2019s collateral factor) based on their analysis. The goal is to strike a balance between creating a capital-efficient protocol and mitigating any potential losses for depositors.\n\nGovernance plays an important role in these protocols, as risk parameter updates and new asset listings must go through their respective governance process. While this methodology helps ensure the protocol is protected from potential bad debt, it also creates a permissioned process for listing new assets. Long-tail assets effectively have no place in these protocols as they\u2019d be deemed too risky to include in the shared collateral pool.\n\nRari Capital implemented Fuse pools to cater to these long-tail assets. Fuse pools can be thought of as isolated instances of Compound markets, allowing anyone to spin up and parametrize their own lending and borrowing markets. These Fuse pools have largely been a success, attracting over $900 million in supplied assets, as they\u2019ve allowed larger token holders and DAOs to create markets for their governance tokens.\n\nAlthough isolated markets like Fuse pools create a buffer between individual lending and borrowing markets and the wider protocol, there is still risk within each market. In January 2022, participants in Rari\u2019s Fuse pool 90 experienced this risk firsthand. The pool uses the FLOAT/USDC Uniswap V3 oracle to retrieve price data for the FLOAT token. An exploiter was able to move the FLOAT price outside of the narrow liquidity band on Uniswap, severely inflating the value of the FLOAT token. With the highly inflated FLOAT value, the exploiter used FLOAT as collateral and was able to drain the majority of the pool's tokens.\n\nThe designs of the aforementioned lending and borrowing platforms demonstrate the trade-offs when creating these markets. Compound and Aave can achieve a higher capital efficiency due to their underlying shared capital pool structure, and to counteract the risks associated with this approach, they must be diligent with their asset listings, relying on governance processes to achieve this. Rari and their Fuse pools isolate risks to individual markets, trading a loss in capital efficiency for a reduction in systemic risks. The FLOAT example, however, serves to reinforce the risks associated with unconstrained collateral usage.\n\nThe central problem for a lending and borrowing protocol is to effectively design mechanisms to maximize capital efficiency and provide markets for long-tail assets, all while protecting itself and its users from potential bad debt.\n\nEuler Finance\n\nEuler Finance leverages Uniswap V3\u2019s time-weighted average price (TWAPs) coupled with a unique risk management framework in hopes of tackling the challenges described above. It is currently backed by Paradigm, Lemniscap, and angel investors such as Anthony Sassano, Kain Warwick, and Hasu. The Euler lending and borrowing protocol recently deployed in December 2021 to the Ethereum mainnet and has attracted ~$85 million in deposits, with USDC accounting for ~75% of total deposits.\n\nPermissionless Asset Listings and Risk Management\n\nLending and borrowing protocols use different approaches to manage assets. Compound and Aave rely on governance to determine which new assets can be added to their protocols, while protocols such as Rari allow the creator of the market to determine the allowed collateral. Euler allows anyone to create a lending market for an asset as long as it has a WETH pair on Uniswap V3, due to the fact that Euler leverages Uniswap\u2019s TWAPs for asset pricing. Utilizing TWAPs for asset pricing implies that Euler markets will be less responsive to and impacted by volatile price movements in the wider market. While this does mean TWAPs are a lagging indicator and can thus be out of sync with certain spot market prices, it also means it will be much more difficult and expensive to manipulate prices.\n\nAllowing anyone to create a lending market around an asset benefits holders of long-tail assets, but it also introduces protocol-wide risks if that asset is exploited, as Euler has implemented a shared capital pool framework similar to Compound. To combat these risks, Euler has designed a tiered risk management framework which assigns each asset to a particular tier.\n\nThe majority of assets currently fall into the isolated tier. If a user borrows one of these assets against a certain collateral, then that\u2019s the only asset which they can borrow against that collateral. Currently no assets are listed as cross tier; nonetheless, these assets cannot be used as collateral (this also applies to isolation-tiered assets), but they can be borrowed in tandem with other assets. Collateral-tiered assets garner the most functionality, and they can of course be used as collateral and also borrowed alongside other assets. Assets can be moved from tier to tier via governance proposals.\n\nTo further manage the risks within the platform, Euler implements both collateral and borrow factors. Compound, for example, associates a collateral factor with each asset, and this determines the maximum value which can be borrowed against that asset. This collateral factor is independent of the asset being borrowed, ignoring any risks associated with the borrowed asset. With both collateral and borrow factors, Euler is able to account upfront for price action in either direction for borrowed assets.\n\nThe FLOAT exploit example not only highlights the risk around collateral allowances, but also shows the risk associated with price oracles. Euler leverages Uniswap V3 TWAPs as an oracle for asset pricing. Currently, for each market setup on Euler, an associated \u201cOracle Rating'' will be calculated and displayed. The framework focuses primarily on the depth and concentration of liquidity for the asset/WETH pair on Uniswap V3.\n\nThis methodology will eventually be replaced with a more robust solution. Euler has already developed an oracle tool, which is also open sourced. At its core, the oracle tool simulates how costly it is to manipulate a given token/WETH pair on Uniswap V3. It allows for simulating a variety of scenarios by tweaking parameters such as the TWAP time internal (e.g., 30 minutes) and the target price of the token. Overall, this will provide a much more precise and robust methodology of computing an oracle\u2019s grade.\n\nLiquidation Mechanics\n\nDepending on who is asked, the sentiment around liquidations will likely vary. For traders and borrowers, liquidations can be detrimental to their portfolio and a source of ultimate pain. But liquidations also play an integral role in keeping lending and borrowing markets healthy. If incentives for liquidations are not properly structured, then the worst-case scenario may lead to a protocol accumulating massive amounts of bad debt and potentially never recovering.\n\nIn protocols such as Aave and Compound, a position can become subject to liquidation if it drops below a certain health factor. For Compound, this is a function of the defined collateral factor for an asset, and in Aave, users are given a bit of cushion (between 5\u201320% depending on the asset) once their position passes the acceptable loan-to-value ratio. When a position qualifies for liquidation, up to 50% of the borrowed value can be repaid by a liquidator (this 50% is also known as the \u201cclose factor\u201d). By taking on 50% of a user's liabilities, that liquidator also has a claim to the same amount of collateral value plus a protocol-defined liquidation incentive/discount (a flat 8% in Compound and a range from 4-10% in Aave). This indeed can be a pain point for borrowers, as they can see a substantial amount of their position wiped away in a single transaction. These fixed-rate liquidation incentives and close factors carry the benefit of a more predictable liquidation outcome, but this liquidation design doesn\u2019t allow for the market to have a voice regarding the liquidation dynamics.\n\nEuler has implemented what are referred to as \u201csoft liquidations.\u201d Rather than setting a flat close factor across all markets, liquidators can only remove enough debt and collateral in order to adjust a user's health factor to 1.25. The health factor is calculated as the ratio of risk-adjusted collateral value to risk-adjusted liabilities. As with Compound and Aave, Euler also has a liquidation incentive/discount. Rather than set these rates at a protocol or market level, Euler leverages a Dutch-auction style mechanism which allows the market to express itself in determining what the appropriate liquidation discount needs to be. The further away a user\u2019s health factor drifts below 1, the larger the liquidation discount becomes (the liquidation discount is capped at 20%). Liquidators therefore can decide when it makes economic sense to carry out a liquidation transaction. Normally, liquidation bots compete with one another in hopes of having their respective liquidation transactions included in the next block, this typically results in contributing to maximal extractable value (MEV). Liquidation bots continue to increase the fees tied to their transactions, resulting in network congestion and increased transaction costs for the average user. Euler\u2019s liquidation design philosophy should help avoid these scenarios where liquidators battle it out in the mempool via priority gas auctions.\n\nLiquidators can also leverage stability pools within Euler which are associated with each market. Instead of outsourcing the upfront capital required for a liquidation event, liquidators can supply funds to a stability pool which can later be used to carry out liquidations. From the liquidators\u2019 perspective, this should generally lower the total transaction costs for liquidations as the capital is sourced within the protocol itself, and there is only an internal price feed to be considered, compared with the scenario of sourcing capital from an external exchange. Additionally, liquidators who provide liquidity to these pools gain the benefit of a \u201cliquidation discount booster,\u201d which effectively increases the profit margins when calculating the total liquidation discount.\n\nDeferred Liquidity Checks\n\nTypically when a user creates a transaction in a lending and borrowing protocol, the system will first perform a health check on the user's position. If the proposed transaction (for a simple example, this could be borrowing a certain token) would leave their position undercollateralized, then the transaction would not be allowed. This is necessary, of course, to keep the protocol solvent and healthy.\n\nBut, imagine being able to bundle a set of actions such that the end result is ultimately a healthy position, but a particular action in the set may not be feasible on its own (e.g., attempting to borrow a token without proper collateralization). The savvy reader may recognize this (potentially complex) transaction description as a flash loan, popularized by Aave. In Euler, the notion of a deferred liquidity check is somewhat of a generalization of the flash loan concept. At a high level, a user is able to build up a transaction and defer the liquidity check on their position until the last action is taken. In protocols such as Aave, a flash loan comes with a small fee (currently set at 0.09%). Euler takes the position that these complex transactions should be free for users, so there is no associated fee when leveraging the deferred liquidity check functionality. Overall, this is a somewhat complex and abstract functionality, but since there are fewer limitations within Euler (i.e., no associated fee structure), users and developers will generally only be restricted by their own creativity.\n\nEUL Tokeneconomics\n\nThe protocol\u2019s native token is EUL, which has yet to be released. EUL holders will have the ability to vote on governance proposals (in Euler\u2019s recently announced governance forum), manage the protocol-owned liquidity, reserves, and treasury. There will also be the ability for EUL holders to stake their tokens, which will earn rewards and also serve as a backstop to the protocol. \n\nThe max supply of EUL is 27,182,818.284590452353602874, which can be further adjusted after the initial 4 year distribution schedule via governance. The max supply of EUL is of course not an arbitrary value; it\u2019s a symbol and hat tip to Euler\u2019s number which is a widely used constant in many areas of mathematics. The allocation of the tokens will be split between investors, founders and team members, a community treasury, and an initial community distribution mechanism.\n\nSource: Euler XYZ Team\n\nInvestor allocations have an 18 month linear vesting schedule with no cliff, and founders have a 48 month linear vesting schedule with no cliff. Team members have a non-linear vesting schedule which follows the pattern of 10% vest after 1 year, 20% of the remaining allocation vests after 2 years, 30% of the remaining allocation vests after 3 years, and the remaining vests after 4 years.\n\nEuler has put together an interesting initial distribution scheme for the community to participate in. The EUL token will be distributed every 100,000 blocks across a variety of markets on the Euler platform. In particular, the distribution will only be on the borrowing side, there will be no distribution for solely supplying assets. The Euler core team will determine the initial set of markets which will be included in this distribution scheme, including USDC, WETH, DAI, and WBTC. The distribution rate will be non-linear over 4 years, with the initial inflation rate set at ~3%, peaking around ~14% after 18 months, then flattening out around ~2.718% at the 4 year mark.\n\nEuler\u2019s distribution scheme will leverage the gauge concept in order to determine the flow of EUL tokens across the various involved markets. EUL holders can stake their EUL against their preferred market in order to drive EUL distribution there, and stakers are not subject to lock-up periods that protocols such as Curve utilize. The gauges will be designed such that EUL tokens are distributed in proportion to the square root of the amount of EUL staked for that market. This function will allow the EUL distribution within a particular market to smooth out once it\u2019s weighted heavier relative to the other markets and will then also disincentivize staking in over-saturated markets.\n\nThis approach serves as a more targeted method of EUL token distribution rather than simply distributing EUL to both lenders and borrowers in every market. While lenders won\u2019t be eligible to participate in this EUL distribution, they\u2019ll receive indirect benefits. Borrowing will essentially be subsidized by the EUL distribution, which should increase overall borrowing demand on the platform, leading to increased yield for lenders.\n\nToday and the Road Ahead\n\nEuler currently has ~$85 million total in deposits, ~$34 million in outstanding loans, and has accumulated ~$66 thousand in protocol revenue since its launch in mid-December 2021. If Euler can successfully increase deposits, then this will lower the interest rates for the marginal borrower, ultimately resulting in more protocol revenue. Regarding interest rate models, Euler currently uses the traditional kink model found in both Aave and Compound but has plans to move towards a more algorithmically reactive interest rate framework which will leverage control theory concepts.\n\nAs Euler continues to grow, it will also look to diversify both the supply and borrow sides of the protocol. USDC is by far the most supplied and borrowed asset, accounting for ~75% of both the total supplied and borrowed assets. On the USDC supply side, the top 10 suppliers account for ~50% of the total USDC supply, and the top 10 borrowers account for ~66% of borrowed USDC. After USDC, WETH is the most supplied and borrowed asset, making up ~13% on the total supply side and ~18% on the borrow side. The top two WETH suppliers account for ~45% of the total supplied WETH, and the top two borrowers account for ~55% of borrowed WETH.\n\nBeing a nascent protocol, Euler will likely look to grow by going after the marginal lender/borrower of longer tail assets, and also by developing integrations with other DeFi protocols. Euler has designed its platform to tokenize supplied assets (i.e., eTokens) as well as debt, in the form of dTokens. Tokenizing debt and allowing it to be transferable is a subtle feature, but it should allow for complex, leveraged positions to be built up which users and protocols may take advantage of. Naturally, Euler will continue competing with protocols such as Rari, Aave, and Compound, and also with new lending and borrowing protocols which are sprouting up across other L1s.\n\nThe incumbents will also look to expand their portion of the lending and borrowing market. To this end, Aave V3 was announced towards the end of 2021 and has now been deployed across six networks. While there are numerous new features introduced, the portal and isolation mode additions appear to be most relevant when analyzing the overall design architecture between Aave and Euler. The portal feature will allow Aave to increase its capital efficiency across the various implementations of the protocol. Aave will look to integrate with select bridges, allowing their aTokens to be transferred seamlessly from network to network. In short, this should allow value within Aave to flow more freely between different networks, unifying what is typically considered fragmented liquidity. Aave\u2019s isolation mode effectively combines some of the components of Euler\u2019s asset tier functionality. As new assets are onboarded into Aave, they can be listed in isolation mode. Unlike in Euler, assets in Aave\u2019s isolation mode can be leveraged as collateral, but governance-approved stablecoins are the only borrowable assets and they will also have associated borrow caps.\n\nAlthough using Uniswap V3 TWAPs for asset pricing allows Euler to develop a logical risk management framework, it also creates a technical dependency on Uniswap V3. Euler currently is only deployed on Ethereum mainnet, which has become increasingly unusable for the average individual due to high transaction costs. Uniswap on the other hand has instances on Ethereum mainnet, Arbitrum, Optimism, and Polygon. Therefore, as Euler grows as a protocol and expands its footprint across other networks, it will already have a critical component of its system in place. Importantly, Euler will not only have to consider where Uniswap V3 is deployed, but there also needs to be significant traction and proper liquidity profiles for assets on these networks.\n\nIn order to continue protocol growth, Euler will look to deploy on networks where Uniswap V3 exists and where it is deployed in the future, giving it a first-mover advantage over competing protocols. Given this advantage, Euler may see significant growth, especially because the project launched during a period of rapid decrease in leverage demand. In addition, borrowing will be subsidized when the initial EUL token is distributed. In any case, Euler will continue to develop its product and work towards growing its user base as it seeks to find its place within the lending and borrowing space.\n\nThis report was commissioned by Euler, a member of Protocol Services. All content was produced independently by the author(s) and does not necessarily reflect the opinions of Messari, Inc. or the organization that requested the report. Paid membership in the Hub does not influence editorial decision or content. Author(s) may hold cryptocurrencies named in this report and each author is subject to Messari\u2019s Code of Conduct and Insider Trading Policy. Additionally, employees are required to disclose their holdings, which is updated monthly and published <a href=\"https://www.google.com/url?q=https://messari.io/article/messari-employee-holdings-policy-and-disclosures&source=gmail-imap&ust=1647457925000000&usg=AOvVaw0jwd9uUO4e2D2TzMmDVmb\">here.</a> Crypto projects can commission independent research through Messari Protocol Services. For more details or to join the program, contact hub@messari.io. This report is meant for informational purposes only. It is not meant to serve as investment advice. You should conduct your own research, and consult an independent financial, tax, or legal advisor before making any investment decisions. Past performance of any asset is not indicative of future results. Please see our terms of use for more information._", "references": [{"name": "Seth Bloomberg", "url": ""}], "published_at": "2022-03-18T13:30:00Z", "author": {"name": "Seth Bloomberg"}, "tags": ["Decentralized-Finance"], "url": "https://messari.io/article/euler-finance"}, {"id": "a35af386-6cb2-40f8-a39f-14ac5b7fa8a4", "title": "Look to the Stars: Navigating the Urbit", "content": "Key Insights\n\nUrbit is a private, digital homestead for all-around Web3 usage; its peer-to-peer OS offers cloud and community-based services.\nIt's built from the ground up and runs on almost any phone, tablet, laptop\u2014or anything with Unix and an internet connection.\nThe real test for Urbit is building a sustainable user community and leveraging infrastructure as a business model.\n\nInternet users often rely on third-party services to stream, store, or create content. Be it Netflix, Spotify, Youtube, or Notion, these third-party services often monetize user time or data. So why do most users continue to over-rely on third-party services? According to the founder of Signal messaging app, a potential explanation is that users 'do not want to run their own servers' because it\u2019s technically complicated. So most users end up using what their peers also use. But there are viable solutions to this problem: Urbit is a prominent example of a protocol that allows anyone to run their own private server and interact with peers. Add to this a suite of  cloud services and seamless usage without ads, tracking, or any data capture.\n\nWhat Is Urbit? Digital Homestead\n\nImagine an extensible, open source version of WeChat: Urbit is a one-stop-shop for cloud and community-based services. It offers user-focused functionalities for collaboration, communication, and commerce. Urbit is designed to give users digital autonomy. It\u2019s like decorating a digital homestead from scratch with built-in privacy: Urbit allows users to privately store their own data, digital assets, and directly communicate with peers without any third-party interference. Urbit can run on almost any phone, tablet, laptop, server\u2014or anything with Unix and an internet connection. Urbit aims to be more personal, customizable, and durable than other existing computing platforms.\n\nSource: urbit.org\n\nCustomization is King\n\nEach Urbit service can be tailored to individual user needs; this is in contrast to the walled-garden experience of many Web2 apps: often easy to use, but less often customized to individual needs. Anyone may create tailored Urbit services based on their own vision of how Urbit should be developed. To enable custom communication and collaboration, one of the main Urbit GitHub contributors - Tlon - has created the Landscape interface, which serves as a robust toolkit for allround Web3 use. To interact with other users, Landscape enables direct chats, posting notebook entries, sharing links in reddit-style, and forming sub-communities. Project Uqbar has recently forked Landscape, offering a simple way to organize groups and an updated user interface. Other notable contributors to Urbit's kernel include: the Tirrel Corporation, an Urbit-focused payments processor; urbit.live, a marketplace for Urbit IDs; urbithost, a server hosting provider; and dcSpark, a product-focused startup building on Urbit.\n\nTechnology in a Nutshell\n\nAt its core, Urbit is a peer-to-peer computer network that runs an operating system (OS). In a nutshell, Urbit comprises two pieces of technology:\n\nPeer-to-Peer Computer Network (Urbit ID): is a distributed identity and public key infrastructure (PKI) for general-purpose authentication. An Urbit ID is like a login, network address, and Web3 wallet all in one. While Urbit IDs are instantiated as ERC-721 non-fungible tokens on the Ethereum smart contract platform, they could be secured by any other smart contract platform or even by a future Urbit Layer 1. Urbit IDs can be cryptographically owned and used as login to the Urbit network, in a similar way Blockscan and Kepler leverage 'Log-in With Ethereum'. This removes the need for login data to be provisioned by a third-party.\n\nUrbit ID enables distributed ownership of the network by its users. It\u2019s somewhat like owning a piece of a Web3 version of TCP/IP, except that Urbit ID gives users control over their data and privacy. Based on their roles on the network, Urbit IDs are organized through a hierarchy: at the top are governance nodes (called galaxies); below galaxies are infrastructure nodes (called stars), responsible for packet routing and peer discovery. Below stars are individual nodes (called planets), that enable network access for everyday use. Any Urbit node is given full flexibility to run any version of Urbit software they choose to.\n\nOperating System (Urbit OS): is a virtual computing platform built from the ground up. It is completely sealed from the system it runs on, somewhat like Web Assembly (WASM) or the Java Virtual Machine (JVM). The Urbit OS is best described as an 'overlay OS,\u2019 in that it runs on top of other environments. Landscape offers a simple interface and community-based services that enable direct, encrypted communication between authenticated users. Every message from a source Urbit ID is encrypted and sent directly to the destination Urbit ID without any interference. Urbit allows users to flexibly deploy any version of the Urbit software to a server of choice. For users who value being in full control, Urbit can be hosted on a local machine. For users who value convenience, Urbit can be hosted via a cloud provider of choice.\n\nThe peer-to-peer network, identity system, and the virtual computing stack can be further explored here.\n\nResearch and Development Journey\n\nA niche research project aimed to re-engineer computing from first principles almost two decades ago. This research was the origin of the development of the Urbit network, which has been operational since 2013. Urbit software releases are inherently decentralized: they are determined by consensus of the core developers, primarily through planning, proposals, and discussions on the Urbit GitHub repository. The Galactic Senate, composed of Urbit's governance nodes (galaxies), may vote on any change proposal. Forks incentivize governance and infrastructure nodes to be reliable service providers for individual nodes.\n\nThe chart below indicates the most notable GitHub software releases. The pace of Urbit development has been intensifying as Urbit ID went live on Ethereum in 2019 and released the first version of Urbit OS in 2020. Urbit subsequently underwent an independent security audit and released a Bitcoin wallet in 2021. Today, Urbit is a mature system that offers stable infrastructure. Urbit engineered and recently released a Layer 2 rollup, making everyday use more affordable for anyone. Transactions are performed on Urbit, submitted to a roller, which then get processed on-chain in batches. An overview of the main software releases from Urbit inception is available <a href=\"https://messari.io/asset/urbit/profile/roadmap\">here</a>.\n\nDeeper Dive: Distributed Identity\n\nThe immediate use case for Urbit ID is authentication into Urbit OS: the Urbit identity protocol is used to uniquely differentiate between Urbit OS users. Put simply, it determines that the person who is talking to you is who they say they are: by signing their messages cryptographically, users are attesting their identity. But there\u2019s more than that: the Urbit ID system provides a set of identities as cryptographic assets.\n\nCryptographic Asset\n\nAn Urbit ID is an ERC-721 non-fungible token\u2014a single 32-bit number\u2014translated into a pronounceable, unique name and a visual icon (referred to as a sigil). For instance, the Urbit ID ~tinbel-picpel and the sigil below have been uniquely mapped to the number 3,500,433,403.\n\nSource: https://urbit.live/~tinbel-picpel\n\nThe combination of ~tinbel-picpel (public key) and ~winter-paches-palfun-foslup (private key) allows a user to log into Urbit OS. The ownership registry that stores the mappings between public keys and their corresponding private keys has been live on the Ethereum blockchain since 2019.\n\nFrom Urbit IDs to Network Nodes\n\nBesides being NFTs, Urbit IDs correspond to nodes on the Urbit network. One can distinguish three classes of Urbit nodes based on their role: governance nodes (galaxies), infrastructure nodes (called stars), and personal nodes (planets). In practice, personal nodes (planets) use services provided by infrastructure nodes (stars). In simplified terms, stars can be regarded as Internet Service Providers (ISPs) for planets. For example, a star might offer hosting, while another might offer add-on services like content delivery network (CDN) or Bitcoin-related nodal services. Other services include: software updates, data packet routing, and peer discovery. Conversely, governance nodes (galaxies) can be regarded as DNS root nodes that provide services to infrastructure nodes (stars).\n\nGalaxies provide services to stars, while stars provide services to planets. Additionally, galaxies form the Galactic Senate that governs the suite of smart contracts on Ethereum that secure the Urbit ID system. When it comes to software updates and releases, any galaxy can propose any vote at any time and choose to run any version of Urbit software. While there is no requirement to adhere to a particular version, simply choosing to run the latest version makes it easier for everyday usage.\n\nUrbit Tree Doesn't Grow to the Sky\n\nGiven this hierarchical division of roles on the Urbit network, the natural way to visualize galaxies, stars, and planets is using a hierarchical tree. That is, three layers stacked on top of each other: at the top layer are the governance nodes (galaxies); at the middle layer are the infrastructure nodes (stars); whereas at the bottom layer are the personal nodes (planets).\n\nThe number of Urbit IDs is bound by design: there will only ever be 2^8 galaxies. Each galaxy can distribute 2^8-1 = 255 stars. There will only ever be a maximum 2^16 stars. Each star can distribute 2^16-1 = 65,535 planets. There will only ever be a maximum 2^32 planets. Summing up, this makes a total of less than 4.3 billion galaxies, stars, and planets combined. Below is a snapshot of the hierarchical tree of Urbit nodes.\n\nToken Economics\n\nAll Urbit IDs were created simultaneously upon the initiation of the Urbit network. Some of the Urbit addresses remain locked in smart contracts that prevent any transferring of the IDs. These Urbit IDs are <a href=\"https://messari.io/asset/urbit/profile/supply-schedule\">scheduled</a> to unlock linearly until 2025: urbit.org and early prize awardees unlock linearly from 2019 until 2021; early contributors, code developers, and employees unlock linearly from 2020 until 2023; private buyers unlock over one or three years based on terms of their respective contracts. Live Urbit network activity can be explored here.\n\nBy January 2024, all stars will be unlocked and available for trading. Unlocked stars are subject to spawning limits, meaning there are limits to how many planets a star can generate, which prolongs the lockup period for planets until the following year. Thus, planets will finish unlocking by January 2025.\n\nAs the scarcest of Urbit network nodes, galaxies are primarily available on over-the-counter (OTC) desks, and rarely appear for sale on open markets. Stars and planets trade regularly on various platforms such as: urbit.live, OpenSea, planet.market, urbit.me, urth systems, urbithost, urbitex.io, or Urbit Marketplace. \n\nOn one hand, planet sales transactions have been relatively steady over time: 5,255 transactions with an average price: $50 USD and one notable exception - planet ~fasmut-worner has been sold on 11/25/2021 for close to $16,000 USD. As each Urbit ID is unique, they tend to be purchased by users for their specific characteristics: names that rhyme or resemble English words are particularly appealing. Planets whose icons have circular sigils often sell for significantly more than the average price. As an example, planet ~parret-barret sold for about $1,000 USD at a time when most planets were selling for $10-20.\n\nOn the other hand, star sales have been gaining in transaction value recently - the most expensive star ~samfeb has been sold on 9/4/2021 for more than $31,000 USD. In total, there have been 1,067 transactions involving stars on urbit.live with an average price of approx. $7,300 USD per star. Wrapped stars (WSTR) trade against ETH on Uniswap as of November 2021.\n\nSource: https://urbit.live/stats\n\nA portion of Urbit IDs (15,935 items) are currently being listed on OpenSea:\n\nIs Urbit Spam-Proof?\n\nUrbit ID\u2019s scarcity, persistent reputation and flexible design may have second-order effects in terms of incentivizing good behavior on the Urbit network.\n\nIdentity scarcity: The number of Urbit IDs is finite which engenders a natural scarcity - there will ever be just less than 4.3 billion unique Urbit IDs and each has a price tag. This means that when a user interacts with a stranger on the Urbit network, they both have skin in the game. Because Urbit IDs are scarce, the more actively used the Urbit system is, the more valuable Urbit IDs are likely to become. This may further discourage \"risk-free\" exploits of Urbit IDs.\n\nPersistent reputation: As a public key infrastructure (PKI), Urbit ID has been designed to promote Urbit's values: an identity needs to be persistent, self-sovereign, and globally consistent (uniquely identifiable). The value of permanent identity translates into accruing a persistent reputation based on the activity of each Urbit ID. Any potential adversarial behavior on the network is added to the persistent reputation. Because reputation follows each individual Urbit ID, good network behavior is inherently incentivized.\n\nFlexible design: The Urbit system is designed to account for flexibility: any galaxy, star, or planet can run any version of Urbit software they choose to. Another example is: planets can choose their stars and galaxies based on software functionalities, user communities, or any criteria that suit their needs. Planets can easily move around the Urbit network to find a new sponsor star in the Urbit tree. This design choice incentivizes galaxies and planets to be reliable service providers for planets. Conversely, stars and galaxies can essentially block planets from spamming the network or from exercising any bad behavior.\n\nThus, an important second-order implication of identity scarcity, permanent reputation, and modular design is that the Urbit system may become spam-proof: if an Urbit ID behaves as a bad actor, it damages their persistent reputation on the network. Higher value of Urbit IDs may discourage spam, bots, scams, or spreading malware: if Urbit ID NFTs become valuable enough, it would be too expensive for users trying to spam the Urbit network by creating multiple addresses or by essentially compromising the persistent reputation of individual Urbit IDs. This is in contrast to being able to cheaply create email addresses used for spamming.\n\nOpportunities: The Sky\u2019s the Limit\n\nToday, the Urbit network is a stable, secure software that runs on most cloud servers, laptops, and mobile phones as an 'overlay OS\u2019. Through interface implementations such as Landscape, Urbit strives to become more personal, private, and durable than any existing computing platform.\n\nUrbit Usage\n\nUrbit is a space meant for communities of users who may want to creatively customize and have control over their digital environment. Today, Urbit is primarily used by developers, and by communities of privacy enthusiasts, tinkerers, and hobbyists. But for Urbit to get a chance of living up to its aspirations, it needs to expand its user base beyond communities of tech-savvy explorers. As the Urbit network transitions from a community of early adopters to digital communities, the increasing market value of Urbit IDs may provide more resources for developers to advance code development. This, in turn, may lead to increased network utility for everyday use and may further stimulate Urbit\u2019s expansion.\n\nSo how can Urbit increase its user adoption? According to the technology acceptance model (TAM), the two most important factors contributing to increased user adoption are: ease of use and usefulness. Let\u2019s explore how this translates to Urbit.\n\nIn terms of ease of use, Urbit aims to lower the entry barriers for regular, non-technical users: Urbit OS can be used conveniently via a hosting service. In this sense, some stars act as hosting service providers for users who want to run their planet in the cloud, as opposed to running it locally. To ease up user life, some stars offer service bundles consisting of planet acquisition, set-up, hosting, alongside packet routing and peer discovery. Add to that a simple and intuitive user interface.\n\nIn terms of usefulness, Urbit aims to tailor its services to the needs of user communities. Urbit aims to continue iterating on the infrastructure, while, at the same time, allowing communities themselves to identify, create, and expand on useful features based on their needs.\n\nSource: urbit.org\n\nCommunity of Communities: Look to the Stars\n\nBe it posting blog entries or sharing links in reddit-style: Urbit is designed for communities to interact with each other. Planets have full flexibility over how they choose to connect with other planets. Each planet can decide how much personal information to share with whom.\n\nStars act as <a href=\"https://messari.io/article/schelling-point\">Schelling points</a> for their planets, being the natural point of spanning sub-communities of planets. Stars enable individual communities to customize their experiences, design their own software for their own usage, while being privacy-protected from the outside world. To date, a total of 7,802 stars have been activated on the Urbit network and this number is expected to grow as communities are getting onboarded into Urbit.\n\nIn this sense, stars may represent the starting point of forming durable ties in a flourishing ecosystem: a community of communities. Within the Urbit target are communities of communities, such as Dalten Collective, point DAO, OtherLife, dcSpark, or dOrg, in need of flexible collaboration tools that can be tailored to specific community needs.\n\ndOrg is a prominent example of a developer collective that supports various Web3 projects. The dOrg community is self-managed: it consists of Web3 developers coming together to coordinate and collaborate on dApp development. This happens organically, based on common goals and affinities with developer communities such as Dxdao, Compound, DAOstack, Aragon, and Near Protocol, to name a few. dOrg is one of the first decentralized autonomous organizations (DAO) that has found a working business model: as per January 2022, dOrg generates $2.5 million USD in annual revenue from bleeding-edge Web3 projects from 50 different clients. dOrg DAO consists of 60 active developers, out of which 20 are full-time.\n\nSource: dorg.tech\n\nWhile dOrg is an excellent Web3 showcase, the model of self-organizing worker communities has been validated in peer-to-peer collaboration long before the emergence of Web3. However, what was usually missing in Web2 was an underlying business model for peer-to-peer collaboration at scale. Take, for instance, the example of WikiProjects, where sub-communities of Wikipedia contributors got together to voluntarily collaborate on a topic area spanning across multiple Wikipedia articles. The common interests and the strong ties among peer contributors have been the backbone of Wikipedia\u2019s community of communities. Ultimately, this has led to Wikipedia being at least on-par with well-established products such as Britannica. With the emergence of Web3, Urbit could become a tool that supports flourishing communities with sound business models for their collaboration and time investment to be rewarded.\n\nAssessing Urbit\u2019s Value: Network Effects\n\nBeing able to serve emerging communities and DAOs will potentially be a key success factor for Urbit in the long-term. Upon forming a community of communities, the value of the Urbit network is set to increase with the number of Urbit communities interacting with each other. According to Reed\u2019s law, by adding up all the possible two-person groups, three-person groups, and so on, the maximum value of the Urbit network composed of N users is 2^N. In practice, this number will depend on the number of communities each user chooses to participate in. In the context of a service like Urbit, the more connections and communities each user actively participates in, the more valuable the entire network is.\n\nLeveraging Infrastructure as Business Model\n\nUrbit does not leverage user data or time. It does not show any ads. So how can Urbit generate revenue from giving users access to the network? Urbit address space is like land that can be put to work: galaxies and stars can be regarded as network infrastructure providers to planets. Both galaxies and stars are directly incentivized to create cash flow-generating services for planets, such as: hosting, packet routing, peer discovery, task management, and payment services. One can think of these services in a similar fashion as services provided by Internet Service Providers (ISPs), Virtual Private Network Providers (VPNs), or payment/transaction processing companies. For galaxies and stars, business opportunities arise by retaining a fee as a portion of the value provided to planets.\n\nChallenges and Competition\n\nWhen attempting to realize its vision, Urbit needs to overcome several challenges and potential competition.\n\nFirst, at this early stage of adoption, Urbit is mostly used by communities of tech-savvy users. Over the long-term, Urbit may need to get broader communities onboarded. Its value proposition - decentralized personal computer with simplest possible Web3 interface - needs to convince users that it is worth switching away from the conventional computing stack.\n\nSecond, there are several paths for Urbit to leverage infrastructure as a business model. Finding the right incentives for infrastructure providers to offer value-added services is going to be key to onboarding flourishing communities. One potential path forward could be offering consumer services such as music and video streaming to gauge broader community interests.\n\nThird, since Urbit is an inherently complex technology, its development incurs execution risk. Some skeptics may find that Urbit resembles more to an obscure art project, rather to a new technology. It is essential for Urbit to be able to steadily deliver value-added services; while, at the same time, not compromise on Urbit\u2019s core values.\n\nFinally, while Urbit is a unique project, one should not rule out direct and non-direct competition. To begin with, SpruceID, Kepler, and Blockscan are prominent examples of self-sovereign identity and data services that leverage \u201cLog-in With Ethereum''. In this sense, one could further think of personal server services offered by any emerging Layer 1s and Layer 2s that do not compromise on scalability and privacy. Existing solutions such as Project Galaxy and Bisq could potentially turn into competitors to Urbit OS, provided that they increase the ease of use and a one-stop-shop for various functionalities. Other potential competitors for Urbit ID may include Microsoft\u2019s ION and 1KOSMOS to name a few. When aggregating all the services Urbit intends to provide, conglomerates such as WeChat, KakaoTalk or any similar services could presumably be counted as Urbit competitors, provided they may follow a path towards progressive decentralization in the long-run.\n\nConclusion\n\nUrbit\u2019s ambitions are wide-ranging, with the potential to have meaningful implications for the future of peer-to-peer Web3 infrastructure and community-based services. With Urbit OS being stable, now is the right time to onboard larger communities onto the Urbit network. While being an unarguably unique and solid project, there are challenges under way. The real test for Urbit\u2019s long term viability is building a sustainable community of communities and leveraging infrastructure as a business model. Being able to quickly pivot and adopt the most suitable business strategy will be key for Urbit to thrive. It all comes down to executing flawlessly and gaining wide-scale community adoption.\n\nThis report was commissioned by Urbit, a member of Protocol Services. All content was produced independently by the author(s) and does not necessarily reflect the opinions of Messari, Inc. or the organization that requested the report. Paid membership in the Hub does not influence editorial decision or content. Author(s) may hold cryptocurrencies named in this report and each author is subject to Messari\u2019s Code of Conduct and Insider Trading Policy. Additionally, employees are required to disclose their holdings, which is updated monthly and published <a href=\"https://www.google.com/url?q=https://messari.io/article/messari-employee-holdings-policy-and-disclosures&source=gmail-imap&ust=1647457925000000&usg=AOvVaw0jwd9uUO4e2D2TzMmDVmb\">here.</a> Crypto projects can commission independent research through Messari Protocol Services. For more details or to join the program, contact hub@messari.io. This report is meant for informational purposes only. It is not meant to serve as investment advice. You should conduct your own research, and consult an independent financial, tax, or legal advisor before making any investment decisions. Past performance of any asset is not indicative of future results. Please see our terms of use for more information.", "references": [{"name": "Mihai Grigore ", "url": ""}], "published_at": "2022-03-14T13:30:00Z", "author": {"name": "Mihai Grigore "}, "tags": ["Web-3", "Layer-2"], "url": "https://messari.io/article/look-to-the-stars-navigating-the-urbit"}, {"id": "847e0552-c39a-4eca-ba30-65786cd6f736", "title": "Weekly Recap Ending March 10", "content": "Notable Messari Intel Updates\n\nThe Polygon PoS chain <a href=\"https://messari.io/intel/event/46e6eb2e-db0a-456a-993d-d03191f1a4da\">halted</a> at block 25,811,386. The Heimdall validator chain stopped producing blocks due to an AppHash mismatch, and the Bor chain halted as well. The Polygon team announced that block production has resumed on the PoS chain after a hot fix was released. The team shared that they are working on implementing a long-term fix to address the issues that led to the chain halt.\nThe Evmos team shared a post mortem about the recent <a href=\"https://messari.io/intel/event/b2d90885-6972-4ce0-989b-8bec64e77751\">chain halt incident</a>. The chain halt is being attributed to a highly complex upgrade that was pushed out too quickly in response to a critical security vulnerability.\nThe Block announced a 4M AVAX (worth roughly $290M USD) <a href=\"https://messari.io/intel/event/2ef2ef2d-6343-4ca7-9110-d6b5deaa35c4\">subnet incentive program</a> called Avalanche Multiverse. The Multiverse program will allocate rewards to subsidize the AVAX staking requirement for subnet operators, reward early users, and distribute liquidity mining incentives.\nAndre Cronje, a technical advisor to the Fantom Foundation and prominent DeFi developer, <a href=\"https://messari.io/intel/event/b818039c-4cfd-4fa5-870e-588a694a9a97\">has stepped down</a> from his role at the Foundation. User interface maintenance in approximately 25 applications  and services (including Yearn Finance, Keep3r Network, Multichain, and the Solidly exchange websites) will be handed over to the existing teams.\nThe Interchain Foundation has shared details about the <a href=\"https://messari.io/intel/event/3cde3ab8-19d3-44fc-9e47-1d7f745f7c51\">upcoming Cosmos Hub Theta testnet</a>. Developers plan to simulate the upgrade process on testnet around Mar. 17, 2022.\n\nNotable Messari Governor Updates\n\nThe Origin DAO has <a href=\"https://messari.io/governor/proposal/7152aa94-4905-4aa7-9a1c-8b1a4bf5af30\">submitted a proposal</a> that aims to introduce the launch of a new governance token, OGV, for the Origin Dollar (OUSD). The new governance token will create a clear distinction between Origin products by separating Origin Story, the platform's NFT platform, and Origin Dollar. Voting is now active.\nThe Yearn Multisig has <a href=\"https://messari.io/governor/proposal/ce7f3033-3e60-4771-9dcf-29d817347be5\">submitted a proposal</a> that seeks to provide a $400k donation to the Nomic Foundation to support its mission to empower developers to decentralize the world. Voting is now active.\nThe SpookySwap DAO <a href=\"https://messari.io/governor/proposal/fefc9b80-c1a4-4f47-91b0-842b65e2daa0\">passed</a> a proposal that aims to approve a budget to support the listing of BOO on a Tier 1 Centralized Exchange and approve Kronos Research as the market maker.\nThe Balancer DAO has <a href=\"https://messari.io/governor/proposal/d1188c2e-8eb9-499d-8bed-d77fb422cdc1\">submitted a proposal</a> that aims to approve a payment of $125,000 USDC to Messari in exchange for quarterly financial reports from the Messari Hub. Reports will be produced in the 2 weeks following the end of the next 4 quarters starting with a Q1 report released in April. Voting is now active.\nThe Frax DAO <a href=\"https://messari.io/governor/proposal/01425bf7-efce-4963-8d0a-891716fa5260\">passed</a> a proposal that aims to approve a 10M FRAX loan, at 5% interest (paid in PERP), to Perpetual Protocol for market making for Curie, its V2 decentralized futures exchange on Optimism.\n\nSector Returns\n\nFor the third week in a row, markets have continued to see reversals. A trend like this hints at the possibility that this is a consolidation phase. The gaming sector was the hardest hit this week, posting a 10.47% loss\u2014this week\u2019s only double-digit negative return. DeFi also had a rough week, finishing second to last with a -8.61% return. The sector with the least decline was top assets, returning -2.69%.\n\nTop Assets\n\nTerra (LUNA) has not ceased to impress as the alternate Layer-1 platform has continued outperforming amidst a global conflict. It is the third week in a row that LUNA has secured double-digit positive returns, prompting investors to wonder how sustainable this rally is. However, LUNA is at a critical point, now that it has briefly reached all-time-high territory. It remains to be seen whether this will mark a double top (and potential freefall) or if the $100 price line will become support for new price discovery. LUNA finished the week with a 15.4% gain while Ripple (XRP) was the only other asset within the top ten assets by market capitalization that ended the week in the green (1.7%).\n\nDeFi Assets\n\nNo DeFi top assets made it above water this week. One of last week\u2019s top two performers, Anchor (ANC) saw its price reach an all-time-high of $6.19 during the first half of the week in anticipation of the upcoming Arca and Polychain anchor proposals and potential future tokenomic changes. ANC saw heavy upwards price action earlier week followed by abating price towards the end of the week, marking the money market protocol asset\u2019s largest recorded decline. The magnitude of the loss was enough to shift it from the top spot down to last, finishing the week with a -18.2% return. True DeFi TVL (no double count TVL of certain protocols) is sitting at a stable $158.9 billion.\n\nSmart Contract Platforms\n\nFor the third week in a row, Terra (LUNA) has led the smart contract platform sector by a wide margin. Although this week was no different, it seems as if its momentum might be slowing down for the moment after posting a more conservative (compared to previous weeks) return of 15.4%. The Cosmos-based IBC chain\u2019s recent rally is a testament to how deeply tied its performance is to the issuance of new UST, which recently reached its peak issuance limits driven by a massive demand for decentralized stablecoins. Only two other smart contract platform assets finished the week in the green: NEAR Protocol (NEAR) and Tron (TRX) with 4.9% and 1.2%, respectively.\n\nCurrencies\n\nPrivacy coins have had notable performances lately, mainly driven by the events surrounding the Russia-Ukraine conflict and the recent executive order signed by President Joe Biden on cryptocurrencies. Although both Monero (XMR) and Zcash (ZEC) found themselves in double-digit territory towards the end of the week, only ZEC was able to maintain its momentum. ZEC secured a 12.6% gain while XMR took the third spot with a 2.2% return.\n\nWeb3\n\nWhile Stacks (STX) has not been demonstrating much positive price performance, a green candle yesterday saw its price wick up to 72% following news that Okcoin pledged $165 million to support Bitcoin-related projects. While STX finished the week with a 26.6% gain, Arweave (AR) was the only other asset within the top Web3 assets that ended the week with a positive return (3.9%).\n\nGaming\n\nAavegotchi (GHST) was the only top gaming asset that closed the week with a positive return, bringing in 0.1%. The low figure was expected due to the asset\u2019s comparatively low volatility. Losses for the other top gaming assets by market capitalization ranged from -6.2% to -14.8% corresponding to Enjin (ENJ) and Alice (ALICE), respectively.\n\n", "references": [{"name": "Guillermo Avil\u00e9s", "url": ""}], "published_at": "2022-03-11T15:55:00Z", "author": {"name": "Guillermo Avil\u00e9s"}, "tags": ["Macro"], "url": "https://messari.io/article/weekly-recap-ending-march-10"}]}